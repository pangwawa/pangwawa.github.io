[{"categories":["技术博客"],"content":"Netty线程模型 Netty主要是基于主从Reactors多线程模型(如下图)做了一些修改，其中主从reactor多线程模型有多个reactor：\nMainReactor负责客户端的连接请求，并将请求转交给SubReactor SubReactor负责相应通道的IO读写请求 非IO请求(具体逻辑处理)的任务则会直接进入写入队列，等到worker threads进行处理\n特别说明的是：虽然Netty的线程模型基于主从Reactor多线程，借用了MainReactor和SubReactor的结构。但是实际实现上SubReactor和Worker线程在同一个线程池中\nbossGroup线程池则只是在bind某个端口后，获得其中一个线程作为MainReactor，专门处理端口的Accept事件，每个端口对应一个boss线程 workerGroup线程池会被各个SubReactor和Worker线程充分利用\n异常处理\n异步的概念和同步相对。当一个异步过程调用发出后，调用者不能立刻得到结果。实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者 Netty中的IO操作是异步的，包括Bind、Write、Connect等操作会简单的返回一个channelFuture 调用者并不能立刻获得结果，而是通过Future-Listener机制，用户可以方便的主动获取或通过通知机制来获得IO操作结果 当future对象刚刚创建时，处于非完成状态，调用者可以通过返回的ChannelFuture来获取操作执行的状态，注册监听函数来执行完成后的操作\nChannelHandler的方法 通过ChannelHandler处理IO操作\nChannelPipeline可以动态添加、删除、替换其中的ChannelHandler，这样的机制可以提高灵活性。\nChannelInitializer用来初始化ChannelHandler，将自定义的各种ChannelHandler添加到ChannelPipeline中。\nChannelPipeline提供的方法\n• addFirst(\u0026hellip;)，添加ChannelHandler在ChannelPipeline的第一个位置 • addBefore(\u0026hellip;)，在ChannelPipeline中指定的ChannelHandler名称之前添加ChannelHandler • addAfter(\u0026hellip;)，在ChannelPipeline中指定的ChannelHandler名称之后添加ChannelHandler • addLast(ChannelHandler\u0026hellip;)，在ChannelPipeline的末尾添加ChannelHandler • remove(\u0026hellip;)，删除ChannelPipeline中指定的ChannelHandler • replace(\u0026hellip;)，替换ChannelPipeline中指定的ChannelHandler\nNetty中有3个实现了ChannelHandler接口的类，其中2个是接口（ChannelInboundHandler用来处理入站数据也就是接收数据、ChannelOutboundHandler用来处理出站数据也就是写数据），一个是抽象类ChannelHandlerAdapter类。 ChannelHandler提供了在它的生命周期内添加或从ChannelPipeline中删除的方法： 1.handlerAdded:ChannelHandler添加到实际上下文中准备处理事件。 2.handlerRemoved：将ChannelHandler从实际上下文中删除，不再处理事件。 3.exceptionCaught：处理跑出的异常。\nChannelInboundHandler类的用法 它提供了一些方法来接收数据或Channel状态改变时被调用，下面是一些常用方法： 1.channelRegistered:ChannelHandlerContext的Channel被注册到EventLoop中。 2.channelUnregistered：ChannelHandlerContext的channel从eventloop中注销。 3.channelActive方法：ChannelHandlerContext的channel已被激活。 4.channelInactive方法：ChannelHandlerContext的channel结束生命周期。 5.channelRead方法：从当前Channel的对端读取消息。 6.channelReadComplete方法：消息读取完毕有执行。 7.userEventTriggered方法：一个用户事件被触发。 8.channelWritabilityChanned方法：改变通道的可写状态，可以使用Channel.isWritable检查。 9.exceptionCaught，重写父类ChannelHandler的方法，处理异常.\nNetty自带 Handler SslHandler:负责对请求进行加密和解密，是放在ChannelPipeline中的第一个ChannelHandler\nHttpClientCodec和HttpServerCodec:HttpClientCodec负责将请求字节解码为HttpRequest、HttpContent和LastHttpContent消息，以及对应的转为字节；HttpServerCodec负责服务端中将字节码解析成HttpResponse、HttpContent和LastHttpContent消息，以及对应的将它转为字节 HttpServerCodec 里面组合了HttpResponseEncoder和HttpRequestDecoder\nHttpClientCodec 里面组合了HttpRequestEncoder和HttpResponseDecoder\nHttpObjectAggregator: 负责将http聚合成完整的消息，而不是原始的多个部分 HttpContentCompressor和HttpContentDecompressor:HttpContentCompressor用于服务器压缩数据，HttpContentDecompressor用于客户端解压数据 IdleStateHandler:连接空闲时间过长，触发IdleStateEvent事件 ReadTimeoutHandler:指定时间内没有收到任何的入站数据，抛出ReadTimeoutException异常,并关闭channel WriteTimeoutHandler:指定时间内没有任何出站数据写入，抛出WriteTimeoutException异常，并关闭channel DelimiterBasedFrameDecoder:使用任何用户提供的分隔符来提取帧的通用解码器 FixedLengthFrameDecoder:提取在调用构造函数时的定长帧 ChunkedWriteHandler：将大型文件从文件系统复制到内存【DefaultFileRegion进行大型文件传输】 WebSocketServerProtocolHandler：处理websocket协议，将HttpServerCodec转为websocketFrame,处理websocket握手\n线程的工作模式：\n在此类中，有两种类型的线程，一种是boss线程，另一种是worker线程\nBoss线程：\n每个server服务器都会有一个boss线程，每绑定一个InetSocketAddress都会产生一个boss线程，比如：我们开启了两个服务器端口80和443，则我们会有两个boss线程。一个boss线程在端口绑定后，会接收传进来的连接，一旦连接接收成功，boss线程会指派一个worker线程处理连接。\nWorker线程：\n一个NioServerSocketChannelFactory会有一个或者多个worker线程。一个worker线程在非阻塞模式下为一个或多个Channels提供非阻塞 读或写\n线程的生命周期和优雅的关闭\n在NioServerSocketChannelFactory被创建的时候，所有的线程都会从指定的Executors中获取。Boss线程从bossExecutor中获取，worker线程从workerExecutor中获取。因此，我们应该准确的指定Executors可以提供足够数量的线程，最好的选择就是指定一个cached线程池（It is the best bet to specify a cached thread pool）。\n此处发现所有源码中的例子(example)中均设置为Executors.newCachedThreadPool()\nBoss线程和worker线程都是懒加载，没有程序使用的时候要释放掉。当boss线程和worker线程释放掉的时候，所有的相关资源如Selector也要释放掉。因此，如果想要优雅的关闭一个服务，需要做一下事情：\n对factory创建的channels执行解绑（unbind）操作 关闭所有的由解绑的channels处理的子channels（这两步目前通常通过ChannelGroup.close()来操作） 调用releaseExternalResources()方法 请确保在所有的channels都关闭前不要关闭executor，否则，会报RejectedExecutionException异常而且相关资源可能不会被释放掉。\nNetty ChannelFutureListener 添加异步回调事件\n","date":"2020-11-26","permalink":"/zh-cn/posts/netty/netty_reactor_model/","series":null,"tags":["Netty"],"title":"Netty_reactor_model"},{"categories":["技术博客"],"content":"Bootstrap or ServerBootstrap\nEventLoop\nEventLoopGroup\nChannelPipeline\nChannel\nFture or ChannelFuture\nChannelInitializer\nChannelHandler\n详解：\nBootstrap，一个Netty应用通常由一个Bootstrap开始，它主要作用是配置整个Netty程序，串联起各个组件。\nHandler，为了支持各种协议和处理数据的方式，便诞生了Handler组件。Handler主要用来处理各种事件，这里的事件很广泛，比如可以是连接、数据接收、异常、数据转换等。\nChannelInboundHandler，一个最常用的Handler。这个Handler的作用就是处理接收到数据时的事件，也就是说，我们的业务逻辑一般就是写在这个Handler里面的，ChannelInboundHandler就是用来处理我们的核心业务逻辑。\nChannelInitializer，当一个链接建立时，我们需要知道怎么来接收或者发送数据，当然，我们有各种各样的Handler实现来处理它，那么ChannelInitializer便是用来配置这些Handler，它会提供一ChannelPipeline，并把Handler加入到ChannelPipeline。ChannelPipeline，一个Netty应用基于ChannelPipeline机制，这种机制需要依赖于EventLoop和EventLoopGroup，因为它们三个都和事件或者事件处理相关。 ChannelPipeline负责安排Handler的顺序及其执行EventLoops的目的是为Channel处理IO操作，一个EventLoop可以为多个Channel服务。EventLoopGroup会包含多个EventLoop。\nChannel代表了一个Socket链接，或者其它和IO操作相关的组件，它和EventLoop一起用来参与IO处理。\nFuture，在Netty中所有的IO操作都是异步的，因此，你不能立刻得知消息是否被正确处理，但是我们可以过一会等它执行完成或者直接注册一个监听，具体的实现就是通过Future和ChannelFutures,他们可以注册一个监听，当操作执行成功或失败时监听会自动触发。总之，所有的操作都会返回一个ChannelFuture。\n我们来看看如何配置一个Netty应用？ – BootsStrapping我们利用BootsStrapping来配置netty 应用，它有两种类型，一种用于Client端：BootsStrap，另一种用于Server端：ServerBootstrap，要想区别如何使用它们，你仅需要记住一个用在Client端，一个用在Server端。下面我们来详细介绍一下这两种类型的区别：1.第一个最明显的区别是，ServerBootstrap用于Server端，通过调用bind()方法来绑定到一个端口监听连接；Bootstrap用于Client端，需要调用connect()方法来连接服务器端，但我们也可以通过调用bind()方法返回的ChannelFuture中获取Channel去connect服务器端。\n一个Netty 简单Echo服务端程序实例 public class EchoServer { public static void main(String[] args) throws InterruptedException { /** * Bootstrap是应用程序的开始，作用是配置整个netty程序，串联各个组件 */ ServerBootstrap serverBootstrap=new ServerBootstrap(); NioEventLoopGroup nioEventLoopGroup=new NioEventLoopGroup(); serverBootstrap .group(nioEventLoopGroup) /** * Channel 代表一个Socket连接，或者其他和IO操作相关的组件，它和EventLoop一起参加IO处理 */ .channel(NioServerSocketChannel.class) .localAddress(new InetSocketAddress(9999)) /** * Handler 是为了支持各种协议和处理数据的方式; 主要是处理连接、数据接收、异常、数据转换等事件 * * ChannelInitializer 用于配置Handler， 它提供ChannelPipeline,并把设置的Handler加到ChannelPipeline */ .childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel socketChannel) throws Exception { /** * ChannelPipeline 一个Netty应用基于ChannelPipeline机制，这种机制依赖于EventLoop和EventLoopGroup */ socketChannel.pipeline().addLast(new EchoServerHandler()); } }); try { /** * Future和ChannelFuture ，注册监听，当操作成功或失败时自动触发，所有的操作都会返回一个ChannelFuture */ ChannelFuture channelFuture= serverBootstrap.bind().sync(); channelFuture.channel().closeFuture().sync(); } finally { /** * 关闭连接 */ nioEventLoopGroup.shutdownGracefully().sync(); } } } 一个Netty简单Echo客户端程序实例 public class EchoClient { public static void main(String[] args) throws InterruptedException { NioEventLoopGroup nioEventLoopGroup=new NioEventLoopGroup(); Bootstrap bootstrap=new Bootstrap(); bootstrap .group(nioEventLoopGroup) .channel(NioSocketChannel.class) /** * 与服务端的localAddress不同，这里是remoteAddress，配置远程连接 服务器地址和端口 */ .remoteAddress(new InetSocketAddress(9999)) .handler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel socketChannel) throws Exception { /** * 这里配置的Handler是客户端需要使用的Handler */ socketChannel.pipeline().addLast(new EchoClientHandler()); } }); try { ChannelFuture channelFuture=bootstrap.connect().sync(); channelFuture.channel().closeFuture().sync(); } finally { nioEventLoopGroup.shutdownGracefully().sync(); } } } ","date":"2020-11-26","permalink":"/zh-cn/posts/netty/netty_echo_sample/","series":null,"tags":["Netty"],"title":"Netty基础——从简单Echo程序分析Netty组件"},{"categories":["技术博客"],"content":"整理下思路\n1、客户端向服务端注册客户端 registerClient(String ClientName, String groupName, EsunClient client)\n2、客户端定期向服务端发送心跳消息、\n3、服务端接收心跳消息，并更新客户端注册列表的心跳时间\n4、服务端定期检查注册列表，对心跳超时未超过三次的的客户端发送心跳消息\n5、客户端启动后会自动重连\n6、服务端启动后会自动重连\n简单实现\nclient端\npublic class HeartBeatClientHandler extends ChannelInboundHandlerAdapter {\rprivate long reconnectTime=5L;\r@Autowired\rClient client;\r@Override\rpublic void channelRegistered(ChannelHandlerContext ctx) throws Exception {\rsuper.channelRegistered(ctx);\r}\r@Override\rpublic void channelUnregistered(ChannelHandlerContext ctx) throws Exception {\r//重连\rctx.channel().eventLoop().schedule(new Runnable() {\r@Override\rpublic void run() {\rtry {\rclient.connect();\r} catch (InterruptedException e) {\rlog.error(\u0026quot;连接服务端出现异常，message:{}\u0026quot;,e.getMessage());\r}\r}\r},reconnectTime, TimeUnit.SECONDS);\rsuper.channelUnregistered(ctx);\r}\r@Override\rpublic void channelActive(ChannelHandlerContext ctx) throws Exception {\rCustomMessageProto.CustomMessage.Builder heartBeatMsg=CustomMessageProto.CustomMessage.newBuilder()\r.setHeader(\rCustomMessageProto.CustomMessage.CustomHeader.newBuilder()\r.setTypeValue(0xABEF)\r.setType(CustomMessageProto.CustomMessage.CustomHeader.MessgeType.PING)\r);\rctx.channel().writeAndFlush(heartBeatMsg);\r}\r@Override\rpublic void channelInactive(ChannelHandlerContext ctx) throws Exception {\rlog.warn(\u0026quot;连接断开，channelInactive() call \u0026quot;);\rsuper.channelInactive(ctx);\r}\r@Override\rpublic void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {\rCustomMessageProto.CustomMessage message= (CustomMessageProto.CustomMessage) msg;\rif (message.getHeader().getType().equals(CustomMessageProto.CustomMessage.CustomHeader.MessgeType.PONG)){\rlog.info(\u0026quot;接收到心跳消息：{}\u0026quot;,message);\r}\rsuper.channelRead(ctx, msg);\r}\r@Override\rpublic void channelReadComplete(ChannelHandlerContext ctx) throws Exception {\rsuper.channelReadComplete(ctx);\r}\r@Override\rpublic void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception {\rif (evt instanceof IdleStateEvent){\rlog.info(\u0026quot;心跳检测触发了\u0026quot;);\rIdleStateEvent idleStateEvent= (IdleStateEvent) evt;\rif (idleStateEvent.state().equals(IdleState.WRITER_IDLE)){\rlog.warn(\u0026quot;已经5秒钟没有写操作了，发个心跳消息检测下\u0026quot;);\rCustomMessageProto.CustomMessage.Builder heartBeatReqMsg=CustomMessageProto.CustomMessage.newBuilder()\r.setHeader(\rCustomMessageProto.CustomMessage.CustomHeader.newBuilder()\r.setTypeValue(0xABEF)\r.setType(CustomMessageProto.CustomMessage.CustomHeader.MessgeType.PING)\r);\rctx.channel().writeAndFlush(heartBeatReqMsg);\r}\r}\r}\r@Override\rpublic void channelWritabilityChanged(ChannelHandlerContext ctx) throws Exception {\rsuper.channelWritabilityChanged(ctx);\r}\r@Override\rpublic void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {\rlog.error(\u0026quot;程序异常，{}\u0026quot;,cause.getMessage());\rctx.channel().close();\r}\r}\rpublic class CustomClientChannelInitializer extends ChannelInitializer\u0026lt;SocketChannel\u0026gt; {\r@Autowired\rHeartBeatClientHandler heartBeatClientHandler;\r@Override\rprotected void initChannel(SocketChannel socketChannel) throws Exception {\rsocketChannel\r.pipeline()\r.addLast(new IdleStateHandler(0,5,0, TimeUnit.SECONDS))\r.addLast(new ProtobufVarint32FrameDecoder())\r.addLast(new ProtobufDecoder(CustomMessageProto.CustomMessage.getDefaultInstance()))\r.addLast(new ProtobufVarint32LengthFieldPrepender())\r.addLast(new ProtobufEncoder())\r.addLast(heartBeatClientHandler);\r}\r}\rserver端\npublic class HeartBeatServerHandler extends ChannelInboundHandlerAdapter {\r@Override\rpublic void channelRegistered(ChannelHandlerContext ctx) throws Exception {\rsuper.channelRegistered(ctx);\r}\r@Override\rpublic void channelUnregistered(ChannelHandlerContext ctx) throws Exception {\rsuper.channelUnregistered(ctx);\r}\r@Override\rpublic void channelActive(ChannelHandlerContext ctx) throws Exception {\rsuper.channelActive(ctx);\r}\r@Override\rpublic void channelInactive(ChannelHandlerContext ctx) throws Exception {\rsuper.channelInactive(ctx);\r}\r@Override\rpublic void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {\rCustomMessageProto.CustomMessage message= (CustomMessageProto.CustomMessage) msg;\rif (message.getHeader().getType().getNumber()== CustomMessageProto.CustomMessage.CustomHeader.MessgeType.PING_VALUE){\rlog.info(\u0026quot;接收心跳消息：{}\u0026quot;,message);\rCustomMessageProto.CustomMessage.Builder heartBeatRespMsg=CustomMessageProto.CustomMessage.newBuilder()\r.setHeader(\rCustomMessageProto.CustomMessage.CustomHeader.newBuilder()\r.setTypeValue(0xABEF)\r.setType(CustomMessageProto.CustomMessage.CustomHeader.MessgeType.PONG)\r);\rctx.channel().writeAndFlush(heartBeatRespMsg);\r}else {\rlog.warn(\u0026quot;消息未处理：{}\u0026quot;,message);\r}\r}\r@Override\rpublic void channelReadComplete(ChannelHandlerContext ctx) throws Exception {\rsuper.channelReadComplete(ctx);\r}\r@Override\rpublic void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception {\r//超过40s没接收心跳消息则强制断开连接，从列表移除\rif (evt instanceof IdleStateEvent){\rIdleStateEvent event= (IdleStateEvent) evt;\rif (event.state().equals(IdleState.READER_IDLE)){\r//判断上一次心跳时间，如果超过40s则直接断开连接\r//否则尝试发送心跳\rlog.info(\u0026quot;已经5秒没有收到客户端心跳消息了，发送心跳检测给客户端\u0026quot;);\rCustomMessageProto.CustomMessage.Builder heartBeatRespMsg=CustomMessageProto.CustomMessage.newBuilder()\r.setHeader(\rCustomMessageProto.CustomMessage.CustomHeader.newBuilder()\r.setTypeValue(0xABEF)\r.setType(CustomMessageProto.CustomMessage.CustomHeader.MessgeType.PONG)\r);\rctx.channel().writeAndFlush(heartBeatRespMsg);\r}\r}\rsuper.userEventTriggered(ctx, evt);\r}\r@Override\rpublic void channelWritabilityChanged(ChannelHandlerContext ctx) throws Exception {\rsuper.channelWritabilityChanged(ctx);\r}\r@Override\rpublic void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {\rlog.error(\u0026quot;发生异常，message：{}\u0026quot;,cause.getMessage());\rsuper.exceptionCaught(ctx, cause);\r}\r}\rpublic class CustomServerChannelInitializer extends ChannelInitializer\u0026lt;SocketChannel\u0026gt; {\r@Autowired\rHeartBeatServerHandler heartBeatServerHandler;\r@Override\rprotected void initChannel(SocketChannel socketChannel) throws Exception {\rsocketChannel.pipeline()\r.addLast(new IdleStateHandler(5,0,0, TimeUnit.SECONDS))\r.addLast(new ProtobufVarint32FrameDecoder())\r.addLast(new ProtobufDecoder(CustomMessageProto.CustomMessage.getDefaultInstance()))\r.addLast(new ProtobufVarint32LengthFieldPrepender())\r.addLast(new ProtobufEncoder())\r.addLast(heartBeatServerHandler);\r}\r}\r","date":"2020-11-26","permalink":"/zh-cn/posts/netty/netty_heartbeat/","series":null,"tags":["Netty"],"title":"Netty实战——基于netty实现心跳检测、消息编解码和断连重连"},{"categories":["技术博客"],"content":"##Netty 一个NIO Java框架，对NIO底层进行了很好的封装 Netty提供异步的、事件驱动的网络应用程序框架和工具，用以快速开发高性能、高可靠性的网络服务器和客户端程序。 快速和简单的开发出一个网络应用，例如实现了某种协议的客户、服务端应用。Netty相当于简化和流线化了网络应用的编程开发过程，例如：基于TCP和UDP的socket服务开发。 etty 是一个吸收了多种协议（包括FTP、SMTP、HTTP等各种二进制文本协议）的实现经验，并经过相当精心设计的项目。最终，Netty 成功的找到了一种方式，在保证易于开发的同时还保证了其应用的性能，稳定性和伸缩性\n为什么使用Netty 有了Netty，你可以实现自己的HTTP服务器，FTP服务器，UDP服务器，RPC服务器，WebSocket服务器，Redis的Proxy服务器，MySQL的Proxy服务器等等。如果你想知道Nginx是怎么写出来的， 如果你想知道Tomcat和Jetty是如何实现的，如果你也想实现一个简单的Redis服务器，那都应该好好理解一下Netty，它们高性能的原理都是类似的\nNetty组成 核心组件包括：\nBootstrap 和 ServerBootstrap 、 Channel、 ChannelHandler、 ChannelPipeline、 EventLoop、 ChannelFuture\n.Bootstrap，ServerBootstrap bootstrap意思是引导，一个Netty应用通常由一个Bootstrap开始，主要作用是配置整个netty程序，串联各个组件。ServerBootstrap是服务端启动引导类，Bootstrap是客户端启动引导类。该类提供了一个 用于应用程序网络层配置的容器\nBootstrap: 用于客户端 示例：Bootstrap bootstrap=new Bootstrap(); ServerBootstrap：用于服务器端 示例： ServerBootstrap serverBootstrap=new ServerBootstrap();\nChannel Channel是Netty网络通信的通道，通过该通道可以执行网络I/O操作。主要作用是：\n维护当前网络连接的通道的状态（例如是否打开?是否已连接） 网络连接的配置参数（例如接收和发送缓冲区的大小） 提供异步的网络I/O操作（如建立连接，读写，绑定端口），异步意味着任何I/O操作都会立即返回，可以通过注册一个监听器来自定义操作结果的事件处理。 支持关联I/O操作与对应的处理程序  底层网络传输 API 必须提供给应用 I/O操作的接口，如读，写，连接，绑定等等。对于我们来说，这是结构几乎总是会成为一个“socket”。 Netty 中的接口 Channel 定义了与 socket 丰富交互的操作集： bind, close, config, connect, isActive, isOpen, isWritable, read, write 等等。 Netty 提供大量的 Channel 实现来专门使用。这些包括 AbstractChannel，AbstractNioByteChannel，AbstractNioChannel， EmbeddedChannel， LocalServerChannel，NioSocketChannel 等等。\n一些常用的Channel类型：\nNioSocketChannel\n异步的客户端 TCP Socket 连接。  NioServerSocketChannel\n异步的服务器端 TCP Socket 连接。与客户端的NioSocketChannel对应  NioDatagramChannel\n异步的 UDP 连接。  NioSctpChannel\n异步的客户端 Sctp 连接。  NioSctpServerChannel，异步的 Sctp 服务器端连接，这些通道涵盖了 UDP 和 TCP 网络 IO 以及文件 IO。\nEpollDomainSocketChannel 、EpollServerDomainSocketChannel、EpollSocketChannel、EpollServerSocketChannel、EpollDatagramChannel EmbeddedChannel KQueueDatagramChannel、KQueueDomainSocketChannel、KQueueServerDomainSocketChannel、KQueueServerSocketChannel、KQueueSocketChannel SocketWritableByteChannel netty的 channel 实现机制 Channel网络层读写的抽象\n　AbstractChannel网络层读写的具体实现\n　AbstractNioChannel主要采用selector实现io事件监听\n　AbstractNioByteChannel 客户端channel的抽象，包含NioByteUnsafe，调用构造方法时传入的注册事件不一致read事件。客户端的读是读取数据\n　NioSocketChannel，包含NioSocketChannelConfig\n　AbstractNioMessageChannel服务端的抽象，包含NioMessageUnsafe，调用构造方法时传入的注册事件不一致accept事件。服务端的读是读取一条新连接\n　NioServerSocketChannel包含NioServerSocketChannelConfig\nChannelHandler 它是一个接口，用于处理I/O事件或拦截I/O事件，并将其转发给对应的channelPipeline中的下一个处理程序。\nChannelHandler 本身并没有提供很多方法，因为这个接口有许多的方法需要实现，方便使用期间，可以继承它的子类：\nChannelInboundHandler 用于处理入站 I/O 事件。 ChannelOutboundHandler 用于处理出站 I/O 操作。 或者使用以下适配器类：\nChannelInboundHandlerAdapter 用于处理入站 I/O 事件。 ChannelOutboundHandlerAdapter 用于处理出站 I/O 操作。 ChannelDuplexHandler 用于处理入站和出站事件。\n7.ChannelHandlerContext\n保存Channel相关的上下文信息，同时关联一个ChannelHandler对象\nchannelPipeline 保存 ChannelHandler 的 List，用于处理或拦截 Channel 的入站事件和出站操作。\n在 Netty 中每个 Channel 都有且仅有一个 ChannelPipeline 与之对应，它们的组成关系如下：\n一个 Channel 包含了一个 ChannelPipeline，而 ChannelPipeline 中又维护了一个由 ChannelHandlerContext 组成的双向链表，并且每个 ChannelHandlerContext 中又关联着一个 ChannelHandler。\n入站事件和出站事件在一个双向链表中，入站事件会从链表 head 往后传递到最后一个入站的 handler，出站事件会从链表 tail 往前传递到最前一个出站的 handler，两种类型的 handler 互不干扰。\nSelector\nNetty 基于 Selector 对象实现 I/O 多路复用，通过 Selector 一个线程可以监听多个连接的 Channel 事件。\n当向一个 Selector 中注册 Channel 后，Selector 内部的机制就可以自动不断地查询(Select) 这些注册的 Channel 是否有已就绪的 I/O 事件（例如可读，可写，网络连接完成等），这样程序就可以很简单地使用一个线程高效地管理多个 Channel 。\nEventLoop NioEventLoop\nNioEventLoop中维护了一个线程和任务队列，支持异步提交执行任务，线程启动时会调用NioEventLoop的run方法，执行I/O任务和非I/O任务：\nI/O任务，即selectionKey中就绪事件，例如read，write，accept，connect等，由processSelectedKeys方法触发。\n非I/O任务，添加到taskQueue中的任务，如register()，bind()等任务\n5.NioEventLoopGroup\nNioEventLoopGroup，主要管理 eventLoop 的生命周期，可以理解为一个线程池，内部维护了一组线程，每个线程(NioEventLoop)负责处理多个 Channel 上的事件，而一个 Channel 只对应于一个线程。\n","date":"2020-11-25","permalink":"/zh-cn/posts/netty/netty_structure/","series":null,"tags":["Netty"],"title":"Netty基础——基础概念与架构原理"},{"categories":["技术博客"],"content":"NIO，全称 java-non-blocking IO ,jdk1.4开始支持，java.nio包下，面向块/缓冲区编程\nNIO三大核心部分： Channel、Buffer、Selector\n","date":"2020-11-24","permalink":"/zh-cn/posts/netty/nio/","series":null,"tags":["Netty"],"title":"Netty入门——NIO "},{"categories":["技术博客"],"content":"私有协议栈和Netty协议栈 绝大多数数私有协议的传输层是基于TCP/IP，利用Netty的TCP/IP协议栈可以非常方便的进行私有协议栈的定制开发\nNetty协议栈用于内部各模块间的通信，基于TCP/IP协议，是个类HTTP协议的应用层协议栈，比传统的标准协议栈更轻巧灵活和实用\nNetty协议栈承载了业务内部各模块之间的消息交互和服务调用，它的主要功能如下。 (1）基于Netty 的NIO通信框架，提供高性能的异步通信能力; (2）提供消息的编解码框架，可以实现POJO的序列化和反序列化; (3)提供基于IP地址的白名单接入认证机制; (4）链路的有效性校验机制; (5)链路的断连重连机制。\nNetty协议 通信模型与步骤 考虑到安全，链路建立需要通过基于IP地址或者号段的黑白名单安全认证机制 为样例，本协议使用基于IP地址的安全认证，如果有多个IP，通过逗号进行分割。在实际商用项目中，安全认证机制会更加严格，例如通过密钥对用户名和密码进行安全认证。\n消息定义 header crcCode : int 32 位 netty消息的校验码，由三部分组成 ： 1、0xABEF （固定值，表面是netty协议，2个字节） ；2、主版本号 1~255，1个字节；3、次版本号，1~255，1个字节。也就是： crcCode= 0xABEF + 主版本号 + 次版本号\nlength : int 32\nsessionID : long 64 节点内全局唯一，由会话ID生成器生成\ntype : Byte 8\n 0:业务请求消息\r1:业务响应消息\r2:业务ONE WAY消息（既是请求又是响应消息)\r3:握手请求消息\r4:握手应答消息\r5:心跳请求消息\r6:心跳应答消息\r priority: Byte 8 消息优先级 0~255\nattachment : Map\u0026lt;String , Object\u0026gt; 可选字段，用于扩展请求头\nbody Object 消息体， 对于请求消息，是参数数据，对于相应消息，是返回的数据\n链路的建立与关闭 链路建立 考虑到安全，链路建立需要通过基于IP地址或者号段的黑白名单安全认证机制 为样例，本协议使用基于IP地址的安全认证，如果有多个IP，通过逗号进行分割。在实际商用项目中，安全认证机制会更加严格，例如通过密钥对用户名和密码进行安全认证。\n客户端与服务端链路建立成功之后，由客户端发送握手请求消息，\n握手请求消息的定义如下。\n(1）消息头的type字段值为3; (2）可选附件为个数为0; (3)消息体为空; (4)握手消息的长度为22个字节。 服务端接收到客户端的握手请求消息之后，如果IP校验通过，返回握手成功应答消息给客户端，应用层链路建立成功。\n握手应答消息定义如下。\n(1）消息头的type字段值为4; (2)可选附件个数为0; (3）消息体为 byte类型的结果，“0”表示认证成功;“-1”表示认证失败。链路建立成功之后，客户端和服务端就可以互相发送业务消息了。\n链路关闭 由于采用长连接通信，在正常的业务运行期间，双方通过心跳和业务消息维持链路，任何一方都不需要主动关闭连接。 但是，在以下情况下，客户端和服务端需要关闭连接。 (1）当对方宕机或者重启时，会主动关闭链路，另一方读取到操作系统的通知信号，得知对方REST 链路，需要关闭连接，释放自身的句柄等资源。由于采用TCP全双工通信，通信双方都需要关闭连接，释放资源; (2）消息读写过程中，发生了1/O异常，需要主动关闭连接; ( 3）心跳消息读写过程中发生了IO异常，需要主动关闭连接; (4）心跳超时，需要主动关闭连接; (5）发生编码异常等不可恢复错误时，需要主动关闭连接。\n可靠性设计 心跳检测机制\n重连机制\n重复登录保护\n消息缓存重发\n安全性设计 为了保证整个集群环境的安全，内部长连接采用基于IP地址的安全认证机制，服务端对握手请求消息的IP地址进行合法性校验:如果在白名单之内，则校验通过;否则,拒绝对方连接。\n如果将Netty协议栈放到公网中使用，需要采用更加严格的安全认证机制，例如基于密钥和AES 加密的用户名+密码认证机制，也可以采用SSL/TSL安全传输。\n作为示例程序，Netty协议栈采用最简单的基于IP地址的白名单安全认证机制。\n可扩展性设计 Netty协议需要具备一定的扩展能力，业务可以在消息头中自定义业务域字段，例如消息流水号、业务自定义消息头等。通过Netty消息头中的可选附件 attachment字段, 务可以方便地进行自定义扩展。 Netty 协议栈架构需要具备一定的扩展能力，例如统一的消息拦截、接口日志、安全、加解密等可以被方便地添加和删除，不需要修改之前的逻辑代码，类似Servlet 的FilterChain和AOP，但考虑到性能因素，不推荐通过AOP来实现功能的扩展。\n自定义消息 syntax=\u0026quot;proto3\u0026quot;;\roption java_package=\u0026quot;fun.codenow.netty.privateprotocol.protobuf\u0026quot;;\roption java_outer_classname=\u0026quot;CustomMessageProto\u0026quot;;\rimport \u0026quot;google/protobuf/any.proto\u0026quot;;\rmessage CustomMessage{\rCustomHeader header=1;\rgoogle.protobuf.Any body=2;\rmessage CustomHeader{\rint32 crcCode=1;\rint32 length=2;\rint64 sessionId=3;\renum MessgeType{\rSERVICE_REQ = 0; SERVICE_RESP = 1; ONE_WAY = 2; LOGIN_REQ = 3; LOGIN_RESP = 4; PING = 5; PONG = 6; }\rMessgeType type=4;\rint32 priority=5;\rmap\u0026lt;string,google.protobuf.Any\u0026gt; attachment=6;\r}\r}\rProtobuf编码\npublic class ProtobufDecoder extends MessageToMessageDecoder\u0026lt;ByteBuf\u0026gt; {\rprivate static final boolean HAS_PARSER;\rprivate final MessageLite prototype;\rprivate final ExtensionRegistryLite extensionRegistry;\rpublic ProtobufDecoder(MessageLite prototype) {\rthis(prototype, (ExtensionRegistry)null);\r}\rpublic ProtobufDecoder(MessageLite prototype, ExtensionRegistry extensionRegistry) {\rthis(prototype, (ExtensionRegistryLite)extensionRegistry);\r}\rpublic ProtobufDecoder(MessageLite prototype, ExtensionRegistryLite extensionRegistry) {\rthis.prototype = ((MessageLite)ObjectUtil.checkNotNull(prototype, \u0026quot;prototype\u0026quot;)).getDefaultInstanceForType();\rthis.extensionRegistry = extensionRegistry;\r}\rprotected void decode(ChannelHandlerContext ctx, ByteBuf msg, List\u0026lt;Object\u0026gt; out) throws Exception {\rint length = msg.readableBytes();\rbyte[] array;\rint offset;\rif (msg.hasArray()) {\rarray = msg.array();\roffset = msg.arrayOffset() + msg.readerIndex();\r} else {\rarray = ByteBufUtil.getBytes(msg, msg.readerIndex(), length, false);\roffset = 0;\r}\rif (this.extensionRegistry == null) {\rif (HAS_PARSER) {\rout.add(this.prototype.getParserForType().parseFrom(array, offset, length));\r} else {\rout.add(this.prototype.newBuilderForType().mergeFrom(array, offset, length).build());\r}\r} else if (HAS_PARSER) {\rout.add(this.prototype.getParserForType().parseFrom(array, offset, length, this.extensionRegistry));\r} else {\rout.add(this.prototype.newBuilderForType().mergeFrom(array, offset, length, this.extensionRegistry).build());\r}\r}\rstatic {\rboolean hasParser = false;\rtry {\rMessageLite.class.getDeclaredMethod(\u0026quot;getParserForType\u0026quot;);\rhasParser = true;\r} catch (Throwable var2) {\r}\rHAS_PARSER = hasParser;\r}\r}\r解码\npublic class ProtobufDecoder extends MessageToMessageDecoder\u0026lt;ByteBuf\u0026gt; {\rprivate static final boolean HAS_PARSER;\rprivate final MessageLite prototype;\rprivate final ExtensionRegistryLite extensionRegistry;\rpublic ProtobufDecoder(MessageLite prototype) {\rthis(prototype, (ExtensionRegistry)null);\r}\rpublic ProtobufDecoder(MessageLite prototype, ExtensionRegistry extensionRegistry) {\rthis(prototype, (ExtensionRegistryLite)extensionRegistry);\r}\rpublic ProtobufDecoder(MessageLite prototype, ExtensionRegistryLite extensionRegistry) {\rthis.prototype = ((MessageLite)ObjectUtil.checkNotNull(prototype, \u0026quot;prototype\u0026quot;)).getDefaultInstanceForType();\rthis.extensionRegistry = extensionRegistry;\r}\rprotected void decode(ChannelHandlerContext ctx, ByteBuf msg, List\u0026lt;Object\u0026gt; out) throws Exception {\rint length = msg.readableBytes();\rbyte[] array;\rint offset;\rif (msg.hasArray()) {\rarray = msg.array();\roffset = msg.arrayOffset() + msg.readerIndex();\r} else {\rarray = ByteBufUtil.getBytes(msg, msg.readerIndex(), length, false);\roffset = 0;\r}\rif (this.extensionRegistry == null) {\rif (HAS_PARSER) {\rout.add(this.prototype.getParserForType().parseFrom(array, offset, length));\r} else {\rout.add(this.prototype.newBuilderForType().mergeFrom(array, offset, length).build());\r}\r} else if (HAS_PARSER) {\rout.add(this.prototype.getParserForType().parseFrom(array, offset, length, this.extensionRegistry));\r} else {\rout.add(this.prototype.newBuilderForType().mergeFrom(array, offset, length, this.extensionRegistry).build());\r}\r}\rstatic {\rboolean hasParser = false;\rtry {\rMessageLite.class.getDeclaredMethod(\u0026quot;getParserForType\u0026quot;);\rhasParser = true;\r} catch (Throwable var2) {\r}\rHAS_PARSER = hasParser;\r}\r}\r粘包拆包问题\npublic class ProtobufVarint32FrameDecoder extends ByteToMessageDecoder {\rpublic ProtobufVarint32FrameDecoder() {\r}\rprotected void decode(ChannelHandlerContext ctx, ByteBuf in, List\u0026lt;Object\u0026gt; out) throws Exception {\rin.markReaderIndex();\rint preIndex = in.readerIndex();\rint length = readRawVarint32(in);\rif (preIndex != in.readerIndex()) {\rif (length \u0026lt; 0) {\rthrow new CorruptedFrameException(\u0026quot;negative length: \u0026quot; + length);\r} else {\rif (in.readableBytes() \u0026lt; length) {\rin.resetReaderIndex();\r} else {\rout.add(in.readRetainedSlice(length));\r}\r}\r}\r}\rprivate static int readRawVarint32(ByteBuf buffer) {\rif (!buffer.isReadable()) {\rreturn 0;\r} else {\rbuffer.markReaderIndex();\rbyte tmp = buffer.readByte();\rif (tmp \u0026gt;= 0) {\rreturn tmp;\r} else {\rint result = tmp \u0026amp; 127;\rif (!buffer.isReadable()) {\rbuffer.resetReaderIndex();\rreturn 0;\r} else {\rif ((tmp = buffer.readByte()) \u0026gt;= 0) {\rresult |= tmp \u0026lt;\u0026lt; 7;\r} else {\rresult |= (tmp \u0026amp; 127) \u0026lt;\u0026lt; 7;\rif (!buffer.isReadable()) {\rbuffer.resetReaderIndex();\rreturn 0;\r}\rif ((tmp = buffer.readByte()) \u0026gt;= 0) {\rresult |= tmp \u0026lt;\u0026lt; 14;\r} else {\rresult |= (tmp \u0026amp; 127) \u0026lt;\u0026lt; 14;\rif (!buffer.isReadable()) {\rbuffer.resetReaderIndex();\rreturn 0;\r}\rif ((tmp = buffer.readByte()) \u0026gt;= 0) {\rresult |= tmp \u0026lt;\u0026lt; 21;\r} else {\rresult |= (tmp \u0026amp; 127) \u0026lt;\u0026lt; 21;\rif (!buffer.isReadable()) {\rbuffer.resetReaderIndex();\rreturn 0;\r}\rresult |= (tmp = buffer.readByte()) \u0026lt;\u0026lt; 28;\rif (tmp \u0026lt; 0) {\rthrow new CorruptedFrameException(\u0026quot;malformed varint.\u0026quot;);\r}\r}\r}\r}\rreturn result;\r}\r}\r}\r}\r}\rpublic class ProtobufVarint32LengthFieldPrepender extends MessageToByteEncoder\u0026lt;ByteBuf\u0026gt; {\rpublic ProtobufVarint32LengthFieldPrepender() {\r}\rprotected void encode(ChannelHandlerContext ctx, ByteBuf msg, ByteBuf out) throws Exception {\rint bodyLen = msg.readableBytes();\rint headerLen = computeRawVarint32Size(bodyLen);\rout.ensureWritable(headerLen + bodyLen);\rwriteRawVarint32(out, bodyLen);\rout.writeBytes(msg, msg.readerIndex(), bodyLen);\r}\rstatic void writeRawVarint32(ByteBuf out, int value) {\rwhile((value \u0026amp; -128) != 0) {\rout.writeByte(value \u0026amp; 127 | 128);\rvalue \u0026gt;\u0026gt;\u0026gt;= 7;\r}\rout.writeByte(value);\r}\rstatic int computeRawVarint32Size(int value) {\rif ((value \u0026amp; -128) == 0) {\rreturn 1;\r} else if ((value \u0026amp; -16384) == 0) {\rreturn 2;\r} else if ((value \u0026amp; -2097152) == 0) {\rreturn 3;\r} else {\rreturn (value \u0026amp; -268435456) == 0 ? 4 : 5;\r}\r}\r}\r","date":"2020-11-24","permalink":"/zh-cn/posts/netty/netty_private_protocol_base/","series":null,"tags":["Netty"],"title":"Netty进阶——基于Netty协议栈进行Protobuf私有协议的定制开发 "},{"categories":["技术博客"],"content":"","date":"2020-11-02","permalink":"/zh-cn/posts/mybatis/mybastis_structure/","series":null,"tags":["框架","Java","Mybatis"],"title":"Mybatis源码分析—Mybatis架构与SQL处理过程"},{"categories":["技术博客"],"content":"什么是ClickHouse ClickHouse是面向联机分析处理的列式数据库，支持SQL查询，且查询性能好，特别是基于大宽表的聚合分析查询性能非常优异，比其他分析型数据库速度快一个数量级。 ClickHouse不单单是一个数据库， 它是一个数据库管理系统。因为它允许在运行时创建表和数据库、加载数据和运行查询，而无需重新配置或重启服务。 主要特性包括： 数据压缩比高。 多核并行计算。 向量化计算引擎。 支持嵌套数据结构。 支持稀疏索引。\n支持数据Insert和Update。\nclickhouse为什么如此快 1）优秀的代码，对性能的极致追求\nclickhouse是CPP编写的，代码中大量使用了CPP最新的特性来对查询进行加速。\n2）优秀的执行引擎以及存储引擎\nclickhouse是基于列式存储的，使用了向量化的执行引擎，利用SIMD指令进行处理加速，同时使用LLVM加快函数编译执行，当然了Presto也大量的使用了这样的特性。\n3）稀疏索引\n相比于传统基于HDFS的OLAP引擎，clickhouse不仅有基于分区的过滤，还有基于列级别的稀疏索引，这样在进行条件查询的时候可以过滤到很多不需要扫描的块，这样对提升查询速度是很有帮助的。\n4）存储执行耦合\n存储和执行分离是一个趋势，但是存储和执行耦合也是有优势的，避免了网络的开销，CPU的极致压榨加上SSD的加持，每秒的数据传输对于网络带宽的压力是非常大的，耦合部署可以避免该问题。\n5）数据存储在SSD，极高的iops。\nClickhouse高性能存储和查询的实现原理 1、多核CPU并行计算，看到刚才的文件存储方式，文件是按照压缩块的方式存在.bin文件中。ClickHouse可以通过大量CPU，并行读取不同的压缩块并行解压计算。\n2、SIMD指令集加速，充分利用了CPU寄存器的并行计算能力。如果是传统的CPU指令集，寄存器就算有128位，如果要进行N次8bit的计算，每次都只能利用寄存器的低8位重复计算N次；而SIMD的话，可以将16个8bit的运算并行放到128位的寄存器中，仅通过1次计算就可以并行计算16个8bit的运算。ClickHouse是通过SSE2指令集实现的，所以最好选用Intel的机器。\n3、之前介绍的，ClickHouse分布式水平扩展集群的能力，也可以很好的提升性能。\n4、还有稀疏索引，列式存储和极致的数据压缩，也都是大数据场景下高性能查询的关键点。\n5、实际上，ClickHouse还有很多优化性能的细节。比如聚合分析，通常的实现是通过HashMap实现，HashMap的key是group by的key，HashMap的value是聚合的值。ClickHouse通过对长字符串的Key，进行Hash实现的HashMapWithSavedHash，以及对Uint8这类范围小的数据字段通过数组实现的FixedHashMap，以及大量新增类别字段和内存限制的场景，也有TwoLevelHashMap和Split to disk的实现方案。\n实际上，ClickHouse的内核实现中，并没有使用什么神秘的算法，但是正是这所有的优化组合在一起，才有了ClickHouse彪悍的查询性能。\n海量数据直接写入ClickHouse会失败 ClickHouse的MergeTree表引擎，底层原理是类似于LSM-tree。数据通过Append的方式写入，后续再启动merge线程将小的数据文件进行合并。\n一次数据写入，会生成一个文件目录。目录结构可以看到，分为四个部分：\n第一部分，是分区ID的信息；\n第二部分，是这个目录中包含数据的最小BlockNum；\n第三部分，是这个目录中包含数据的最大BlockNum；\n第四部分，是这个目录进行合并的等级。\n举个例子，图中两个黄色的数据目录合并成蓝色的数据目录，数据BlockNum从1_1和2_2合并成了1_2，数据合并level也从0变成了1。\n了解了ClickHouse MergeTree家族表的写入过程，这里我们就会发现两个问题。\n第一：如果一次写入的数据量太小，比如一条写一次，那么会产生大量的文件目录。当后台合并线程来不及合并的时候，文件目录数量会越来越多，这会导致ClickHouse抛出Too many parts的异常，写入失败。 第二：根据之前的介绍，每一次写入除了写入数据本身，ClickHouse还需要跟Zookeeper进行十来次的数据交互，而我们知道Zookeeper是不能承受高并发的访问。可以看到，写入QPS过高导致进一步Zookeeper的QPS过高，从而导致Zookeeper崩溃。 我们采用的解决方案是，改用Batch的方式写入。即一个Batch的数据，产生一个数据目录，与Zookeeper进行一系列交互。那Batch设置多大呢，Batch太小的话缓解不了ZK的压力，Batch也不能太大，不然上游内存的压力和数据延迟会太大。通过实验，最终我们选用了大小几十万的Batch。\n这样避免了QPS太高带来的问题。当前方案其实还有优化空间的，比如Zookeeper是无法线性扩展的。我了解到，业内有些团队就把log和data part相关信息不写入Zookeeper，这样减少了Zookeeper的压力。不过这样涉及到了对源代码的修改，对于一般的业务团队实现的成本太高了。\n数据写入，遇到的第二个问题是，如果数据写入通过分布式表写入会遇到单点问题。\n先介绍一下分布式表。分布式表实际上是一张逻辑表并不存储真实数据，可以理解为一张代理表。\n比如用户查询分布式表，分布式表会将查询请求下发到每一个分片的本地表上进行查询，然后收集每个分片本地表的结果，汇总之后再返回给用户。\n用户写入分布式表的场景，是用户将一个Batch的数据写入分布式表，分布式表根据一定的规则，将这个Batch的数据分为若干个Mini Batch的数据，存储到不同的分片上。\n这里有一个很容易误解的地方，我们开始以为，分布式表是按照一定规则做一个网络转发，那么我们当时想只要万兆网卡的带宽足够，就不会出现单点的性能瓶颈。\n尤其是Clickhouse底层运用的是Mergetree，在合并的过程中，会存在写放大的问题加重磁盘的压力。峰值每分钟几千万条数据写完耗时几十秒，如果正在做Merge就会阻塞写入请求，查询也会非常慢。\n我们做的两个优化方案：\n第一，对磁盘做Raid提升磁盘的IO。\n第二，在写入之前，上游进行数据划分分表操作，直接分开写入到不同的分片上，磁盘压力直接变为了原来的1/N。\n这样很好的避免了磁盘的单点瓶颈。\n","date":"2020-11-02","permalink":"/zh-cn/posts/clickhouse/clickhouse_structure/","series":null,"tags":["ClickHouse","OLAP","大数据"],"title":"Clickhouse基础概念与架构原理"},{"categories":["技术博客"],"content":"Kubernetes对象的概念 在 Kubernetes 系统中，Kubernetes 对象 是持久化的实体。 Kubernetes 使用这些实体去表示整个集群的状态。它们主要描述了如下信息：\n哪些容器化应用在运行（以及在哪些节点上） 可以被应用使用的资源 关于应用运行时表现的策略，比如重启策略、升级策略，以及容错策略  kubernetes对象的类别 资源对象的类别 Pod Pod 是最小的可部署的 Kubernetes 对象模型。Pod 表示集群上正在运行的进程。一个 Pod 由一个或多个容器组成，Pod 中容器共享存储和网络，在同一台 Docker 主机上运行。在 kubernetes 中，若要运行一个容器，则必须先创建 pod，让容器在 pod 中运行，可以把 Pod 看成是容器的运行环境。 Docker 是 Kubernetes Pod 中最常用的容器运行时，但 Pod 也能支持其他的容器运行时，如 rtk。 Kubernetes 集群中的 Pod 可被用于以下两个主要用途：\n运行单个容器的 Pod。”每个 Pod 一个容器”模型是最常见的 Kubernetes 用例；在这种情况下，可以将 Pod 看作单个容器的包装器，并且 Kubernetes 直接管理 Pod，而不是容器。\n运行多个协同工作的容器的 Pod。 Pod 可能封装由多个紧密耦合且需要共享资源的共处容器组成的应用程序。 这些位于同一位置的容器可能形成单个内聚的服务单元——一个容器将文件从共享卷提供给公众，而另一个单独的“挂斗”容器则刷新或更新这些文件。 Pod 将这些容器和存储资源打包为一个可管理的实体。\nReplicationController  ReplicationController 简写 “RC” 或 “RCS”。译作“副本控制器”，“Replication” 就是“复制”、“副本”的意思。ReplicationController 确保在任何时候都有特定数量的 pod 副本处于运行状态。 换句话说，ReplicationController 确保一个 pod 或一组同类的 pod 总是可用的。 当 pods 数量过多时，ReplicationController 会终止多余的 pods。当 pods 数量太少时，ReplicationController 将会启动新的 pods。 与手动创建的 pod 不同，由 ReplicationController 创建的 pods 在失败、被删除或被终止时会被自动替换。\nReplicaSet  ReplicaSet 简写 “RS”，是 “Replication Controller” 的升级版。和 “ReplicationController” 一样用于确保任何给定时间指定的Pod副本数量，并提供声明式更新等功能。 RC与RS唯一区别就是lable selectore支持不同，RS支持新的基于集合的标签，RC仅支持基于等式的标签。\nDeployment  Deployment是一个更高层次的API对象，他管理ReplicaSets和Pod，并提供声明式更新等功能。 官方建议使用Deployment管理ReplicaSets，而不是直接使用ReplicaSets，这就意味着可能永远不需要直接操作ReplicaSet对象。\nStatefulSet  StatefulSet适合持久性的应用程序，有唯一的网络标识符（IP），持久存储，有序的部署、扩展、删除和滚动更新。\nDaemonSet  Daemon 一词应该不陌生的，Daemon 进程（守护进程）、Demon 程序（守护程序）。顾名思义，DaemonSet 一般是用来部署一些特殊应用的，譬如日志应用等有“守护”意义的应用。 DaemonSet确保所有（或一些）节点运行同一个Pod（当然这里不是指“同一个”，而是和副本一样的概念，当然不可能多个节点运行“同一个”Pod，它又不是量子态）。当节点加入kubernetes集群中，Pod会被调度到该节点上运行，当节点从集群中移除时，DaemonSet的Pod会被删除。删除DaemonSet会清理它所有创建的Pod。\nJob 一次性任务，运行完成后Pod销毁，不再重新启动新容器。\nCronJob CronJob 是在 Job 基础上加上了定时功能。\nHorizontalPodAutoscaling Horizontal Pod Autoscaling可以根据CPU使用率或应用自定义metrics自动扩展Pod数量（支持replication controller、deployment和replica set）。\n控制管理器每隔30s（可以通过–horizontal-pod-autoscaler-sync-period修改）查询metrics的资源使用情况\n支持三种metrics类型\n预定义metrics（比如Pod的CPU）以利用率的方式计算\n自定义的Pod metrics，以原始值（raw value）的方式计算\n自定义的object metrics\n支持两种metrics查询方式：Heapster和自定义的REST API\n支持多metrics\n自定义metrics\n使用方法\n控制管理器开启–horizontal-pod-autoscaler-use-rest-clients\n控制管理器的–apiserver指向API Server Aggregator\n在API Server Aggregator中注册自定义的metrics API\n配置对象 Node、Namespace、Service、Secret、ConfigMap、Ingress、Label、ThirdPartyResource、 ServiceAccount\n存储对象 Volume volume是kubernetes为防止容器重新创建启动时导致的数据丢失、解决容器之间的文件数据共享问题而抽象出的对象。  Persistent Volume 持久卷（PersistentVolume，PV）是集群中的一块存储，可以由管理员事先供应，或者 使用存储类（Storage Class）来动态供应。 持久卷是集群资源，就像节点也是集群资源一样。PV 持久卷和普通的 Volume 一样，也是使用 卷插件来实现的，只是它们拥有独立于任何使用 PV 的 Pod 的生命周期。  策略对象 SecurityContext、ResourceQuota、LimitRange\nKubernetes对象的描述 必须字段：\napiVersion - 创建该对象所使用的 Kubernetes API 的版本\nkind - 想要创建的对象的类别\nmetadata - 帮助唯一性标识对象的一些数据，包括一个 name 字符串、UID 和可选的 namespace\n非必须字段：\nspec - 关于对象的更为详细的描述\n示例 apiVersion: v1 #指定api版本，此值必须在kubectl apiversion中\nkind: Pod #指定创建资源的角色/类型\nmetadata: #资源的元数据/属性\nname: test-pod #资源的名字，在同一个namespace中必须唯一\nlabels: #设定资源的标签 k8s-app: apache\nversion: v1\nkubernetes.io/cluster-service: \u0026ldquo;true\u0026rdquo;\nannotations: #自定义注解列表\n- name: String #自定义注解名字\nspec: #specification of the resource content 指定该资源的内容\nrestartPolicy: Always #表明该容器一直运行，默认k8s的策略，在此容器退出后，会立即创建一个相同的容器\nnodeSelector: #节点选择，先给主机打标签kubectl label nodes kube-node1 zone=node1\nzone: node1\ncontainers:\n- name: test-pod #容器的名字\nimage: 10.192.21.18:5000/test/chat:latest #容器使用的镜像地址\nimagePullPolicy: Never #三个选择Always、Never、IfNotPresent，每次启动时检查和更新（从registery）images的策略， # Always，每次都检查 # Never，每次都不检查（不管本地是否有） # IfNotPresent，如果本地有就不检查，如果没有就拉取 command: [\u0026lsquo;sh\u0026rsquo;] #启动容器的运行命令，将覆盖容器中的Entrypoint,对应Dockefile中的ENTRYPOINT\nargs: [\u0026quot;$(str)\u0026quot;] #启动容器的命令参数，对应Dockerfile中CMD参数\nenv: #指定容器中的环境变量\n- name: str #变量的名字\nvalue: \u0026ldquo;/etc/run.sh\u0026rdquo; #变量的值\nresources: #资源管理 requests: #容器运行时，最低资源需求，也就是说最少需要多少资源容器才能正常运行\ncpu: 0.1 #CPU资源（核数），两种方式，浮点数或者是整数+m，0.1=100m，最少值为0.001核（1m） memory: 32Mi #内存使用量\nlimits: #资源限制\ncpu: 0.5\nmemory: 1000Mi\nports:\n- containerPort: 80 #容器开发对外的端口 name: httpd #名称 protocol: TCP\nlivenessProbe: #pod内容器健康检查的设置 httpGet: #通过httpget检查健康，返回200-399之间，则认为容器正常\npath: / #URI地址\nport: 80\n#host: 127.0.0.1 #主机地址\nscheme: HTTP\ninitialDelaySeconds: 180 #表明第一次检测在容器启动后多长时间后开始\ntimeoutSeconds: 5 #检测的超时时间\nperiodSeconds: 15 #检查间隔时间\n#也可以用这种方法\n#exec: 执行命令的方法进行监测，如果其退出码不为0，则认为容器正常\n# command:\n# - cat\n# - /tmp/health\n#也可以用这种方法\n#tcpSocket: //通过tcpSocket检查健康 # port: number lifecycle: #生命周期管理\npostStart: #容器运行之前运行的任务\nexec:\ncommand:\n- \u0026lsquo;sh\u0026rsquo;\n- \u0026lsquo;yum upgrade -y\u0026rsquo;\npreStop:#容器关闭之前运行的任务\nexec:\ncommand: [\u0026lsquo;service httpd stop\u0026rsquo;]\nvolumeMounts: #挂载持久存储卷 - name: volume #挂载设备的名字，与volumes[*].name 需要对应 mountPath: /data #挂载到容器的某个路径下\nreadOnly: True\nvolumes: #定义一组挂载设备\n- name: volume #定义一个挂载设备的名字\n#meptyDir: {}\nhostPath:\npath: /opt #挂载设备类型为hostPath，路径为宿主机下的/opt,这里设备类型支持很多种 #nfs，\n","date":"2020-10-26","permalink":"/zh-cn/posts/kubernetes/kubernetes_resource_object/","series":null,"tags":["kubernetes","DevOps"],"title":"Kubernetes对象详解"},{"categories":["技术博客"],"content":"Flink 为流式/批式处理应用程序的开发提供了Stateful Stream Processing、DataStream/DataSet ApI 、Table API和SQL这四个不同级别的抽象，如下如所示：\n1、SQL 这层抽象在语义和程序表达式上都类似于 Table API，但是其程序实现都是 SQL 查询表达式。SQL 抽象与 Table API 抽象之间的关联是非常紧密的，并且 SQL 查询语句可以在 Table API 中定义的表上执行。\n2、Table API 以表（Table）为中心的声明式编程（DSL）API，例如在流式数据场景下，它可以表示一张正在动态改变的表。Table API 遵循（扩展）关系模型：即表拥有 schema（类似于关系型数据库中的 schema），并且 Table API 也提供了类似于关系模型中的操作，比如 select、project、join、group-by 和 aggregate 等\n3、Datastream、DataSet API 核心 API，包含 DataStream API（应用于有界/无界数据流场景）和 DataSet API（应用于有界数据集场景）两部分。Core APIs 提供的流式 API（Fluent API）为数据处理提供了通用的模块组件，例如各种形式的用户自定义转换（transformations）、联接（joins）、聚合（aggregations）、窗口（windows）和状态（state）操作等。此层 API 中处理的数据类型在每种编程语言中都有其对应的类。\n4、Stateful Stream Processing（有状态实时流处理） 允许用户在应用程序中自由地处理来自单流或多流的事件（数据），并提供具有全局一致性和容错保障的状态。此外，用户可以在此层抽象中注册事件时间（event time）和处理时间（processing time）回调方法，从而允许程序可以实现复杂计算。\n这4层中，一般用于开发的是第三层，即DataStrem/DataSetAPI。用户可以使用DataStream API处理无界数据流，使用DataSet API处理有界数据流。同时这两个API都提供了各种各样的接口来处理数据。\nFlink程序的模块结构 如下图，Flink程序主要分为 source\u0026ndash;\u0026gt;transformation\u0026ndash;\u0026gt;sink 这三个模块\n在获取执行环境后，程序从数据源中获取数据，并执行Transformation操作，最后将执行结果输出到指定的地方，如消息队列、文件系统、数据库等。\n下面这个简单的例子便包含了整个过程：\n public static void main(String[] args) throws Exception { // Checking input parameters final MultipleParameterTool params = MultipleParameterTool.fromArgs(args); // set up the execution environment final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); // make parameters available in the web interface env.getConfig().setGlobalJobParameters(params); // get input data DataStream\u0026lt;String\u0026gt; text = null; if (params.has(\u0026quot;input\u0026quot;)) { // union all the inputs from text files for (String input : params.getMultiParameterRequired(\u0026quot;input\u0026quot;)) { if (text == null) { text = env.readTextFile(input); } else { text = text.union(env.readTextFile(input)); } } Preconditions.checkNotNull(text, \u0026quot;Input DataStream should not be null.\u0026quot;); } else { System.out.println(\u0026quot;Executing WordCount example with default input data set.\u0026quot;); System.out.println(\u0026quot;Use --input to specify file input.\u0026quot;); // get default test text data text = env.fromElements(WordCountData.WORDS); } DataStream\u0026lt;Tuple2\u0026lt;String, Integer\u0026gt;\u0026gt; counts = // split up the lines in pairs (2-tuples) containing: (word,1) text.flatMap(new Tokenizer()) // group by the tuple field \u0026quot;0\u0026quot; and sum up tuple field \u0026quot;1\u0026quot; .keyBy(value -\u0026gt; value.f0).sum(1); // emit result if (params.has(\u0026quot;output\u0026quot;)) { counts.writeAsText(params.get(\u0026quot;output\u0026quot;)); } else { System.out.println(\u0026quot;Printing result to stdout. Use --output to specify output path.\u0026quot;); counts.print(); } // execute program env.execute(\u0026quot;Streaming WordCount\u0026quot;); } ","date":"2020-10-22","permalink":"/zh-cn/posts/flink/flink_programing_model/","series":null,"tags":["Flink","大数据"],"title":"Flink编程模型详解"},{"categories":["技术博客"],"content":"kubernetes 常用kubectl命令 基本命令 create 通过文件名或控制台输入，创建资源。\nget 用于获取一个或多个资源的信息，包括 Namespace、 Pod、 Node、 Deployment、 Service、 ReplicaSet\n如\nkubectl get cs # 查看集群状态\nkubectl get nodes # 查看集群节点信息\nkubectl get ns # 查看集群命名空间\nkubectl get svc -n kube-system # 查看指定命名空间的服务\nkubectl get pod -o wide # 查看Pod详细信息\nkubectl get pod -o yaml # 以yaml格式查看Pod详细信息\nkubectl get pods # 查看资源对象，查看所有Pod列表\nkubectl get rc,service # 查看资源对象，查看rc和service列表\nkubectl get pod,svc,ep \u0026ndash;show-labels # 查看pod,svc,ep能及标签信息\nkubectl get all \u0026ndash;all-namespaces # 查看所有的命名空间\nrun #创建带有终端的pod kubectl run -i \u0026ndash;tty busybox \u0026ndash;image=busybox\n#启动一个 nginx 实例 kubectl run nginx \u0026ndash;image=nginx\n#启动多个副本的pod kubectl run mybusybox \u0026ndash;image=busybox \u0026ndash;replicas=5\nexpose #为 nginx RC 创建服务，启用本地 80 端口连接到容器上的 8000 端口 kubectl expose rc nginx \u0026ndash;port=80 \u0026ndash;target-port=8000\nkubectl expose（将资源暴露为新的 Service）\ndelete 通过文件名、控制台输入、资源名或者label selector删除资源。\n#删除基于nginx.yaml定义的名称 kubectl delete -f nginx.yaml\n#删除基于Pod.yaml定义的名称 kubectl delete -f pod.yaml\n#删除基于rc名定义的名称 kubectl delete rc rc名\n#删除基于service定义的名称 kubectl delete service service名\n#删除所有Pod kubectl delete pods \u0026ndash;all\n#根据label删除 kubectl delete pod -l app=flannel -n kube-system\n#删除 pod.json 文件中定义的类型和名称的 pod kubectl delete -f ./pod.json\n#删除名为“baz”的 pod 和名为“foo”的 service kubectl delete pod,service baz foo\n#删除具有 name=myLabel 标签的 pod 和 serivce kubectl delete pods,services -l name=myLabel\n#删除具有 name=myLabel 标签的 pod 和 service，包括尚未初始化的 kubectl delete pods,services -l name=myLabel \u0026ndash;include-uninitialized\n#删除 my-ns namespace下的所有 pod 和 serivce，包括尚未初始化的 kubectl -n my-ns delete po,svc \u0026ndash;all\n#强制删除 kubectl delete pods prometheus-7fcfcb9f89-qkkf7 \u0026ndash;grace-period=0 \u0026ndash;force\n#卸载kubernetes-dashboard kubectl delete -f kubernetes-dashboard.yaml\nApp管理 apply 通过文件名或控制台输入，对资源进行配置\n#创建/更新 kubectl apply -f xxx.yaml\nannotate 更新资源的注解\nautoscale convert diff edit 编辑服务端的资源。\nkustomize label patch replace rollout scale set wait 使用应用程序 相关命令 attach 连接到一个正在运行的容器。\nauth cp describe 输出指定的一个/多个资源的详细信息。\nexec 在容器内运行命令\nlogs 输出pod中一个容器的日志。\nport-forward proxy top 集群管理命令 api-versions 输出服务端支持的API版本\ncertificate cluster-info 显示集群信息\ncordon drain taint uncordon KUBECTL SETTINGS AND USAGE alpha api-resources completion config 修改kubeconfig配置文件。\nexplain options plugin version 输出服务端和客户端的版本信息。\n","date":"2020-10-13","permalink":"/zh-cn/posts/kubernetes/kubernetes_cli_order/","series":null,"tags":["kubernetes","DevOps"],"title":"Kubernetes常用kubectl命令总结"},{"categories":["技术博客"],"content":"","date":"2020-10-12","permalink":"/zh-cn/posts/kubernetes/kubernetes_cluster_install/","series":null,"tags":["kubernetes","DevOps"],"title":"Kubernetes v1.19.0集群部署"},{"categories":["技术博客"],"content":"什么是Kubernetes Kubernetes 是一个可移植的、可扩展的开源平台，用于管理容器化的工作负载和服务，可促进声明式配置和自动化。Kubernetes(k8s)是Google开源的容器集群管理系统（谷歌内部:Borg）在Docker技术的基础上，为容器化的应用提供部署运行、资源调度、服务发现和动态伸缩等一系列完整功能，提高了大规模容器集群管理的便捷性。\n核心概念与架构 service service 一个Service对象是对应用集群的抽象，比如一个Mysql集群，一个微服务的集群，都会被看做一个service\n特点： 拥有唯一指定的名称(比如mysql-server)。 拥有一个虚拟IP(Cluster lP、Service IP或VIP）和端口号。 能够提供某种远程服务能力。 被映射到提供这种服务能力的一组容器应用上。  pod k8s中的最小部署单元，不是一个程序/进程，而是一个环境(包括容器、存储、网络ip:port、容器配置)。其中可以运行1个或多个container（docker或其他容器），在一个pod内部的container共享所有资源，包括共享pod的ip:port和磁盘。\npod是临时性的，用完即丢弃的，当pod中的进程结束、node故障，或者资源短缺时，pod会被干掉。基于此，用户很少直接创建一个独立的pods，而会通过k8s中的controller来对pod进行管理。 controller通过pod templates来创建pod，pod template是一个静态模板，创建出来之后的pod就跟模板没有关系了，模板的修改也不会影响现有的pod。\nPod中封装着应用的容器（有的情况下是好几个容器），存储、独立的网络IP，管理容器如何运行的策略选项。Pod代表着部署的一个单位：kubernetes中应用的一个实例，可能由一个或者多个容器组合在一起共享资源。\n在Kubrenetes集群中Pod有如下两种使用方式：\n一个Pod中运行一个容器。“每个Pod中一个容器”的模式是最常见的用法；在这种使用方式中，你可以把Pod想象成是单个容器的封装，kuberentes管理的是Pod而不是直接管理容器。\n在一个Pod中同时运行多个容器。一个Pod中也可以同时封装几个需要紧密耦合互相协作的容器，它们之间共享资源。这些在同一个Pod中的容器可以互相协作成为一个service单位——一个容器共享文件，另一个“sidecar”容器来更新这些文件。Pod将这些容器的存储资源作为一个实体来管理。\ncontainer 容器是独立运行的一个或一组应用，是镜像运行时的实体。\npod 生命周期 需要注意的是pod的生命周期和container的生命周期有一定的联系，但是不能完全混淆一致。pod状态相对来说要简单一些。这里首先列出pod的状态\n1、pending：pod已经被系统认可了，但是内部的container还没有创建出来。这里包含调度到node上的时间以及下载镜像的时间，会持续一小段时间。 2、Running：pod已经与node绑定了（调度成功），而且pod中所有的container已经创建出来，至少有一个容器在运行中，或者容器的进程正在启动或者重启状态。\u0026ndash;这里需要注意pod虽然已经Running了，但是内部的container不一定完全可用。因此需要进一步检测container的状态。 3、Succeeded：这个状态很少出现，表明pod中的所有container已经成功的terminated了，而且不会再被拉起了。 4、Failed：pod中的所有容器都被terminated，至少一个container是非正常终止的。（退出的时候返回了一个非0的值或者是被系统直接终止） 5、unknown：由于某些原因pod的状态获取不到，有可能是由于通信问题。 一般情况下pod最常见的就是前两种状态。而且当Running的时候，需要进一步关注container的状态。下面就来看下container的状态有哪些：\nContainer生命周期 1、Waiting：启动到运行中间的一个等待状态。 2、Running：运行状态。 3、Terminated：终止状态。 如果没有任何异常的情况下，container应该会从Waiting状态变为Running状态，这时容器可用。\n但如果长时间处于Waiting状态，container会有一个字段reason表明它所处的状态和原因，如果这个原因很容易能标识这个容器再也无法启动起来时，例如ContainerCannotRun，整个服务启动就会迅速返回。（这里是一个失败状态返回的特性，不详细阐述）\n当一个容器已经运行起来以后，pod和container的状态是如何关联起来的呢，下面给一些举例来更加形象化其中的关系。\n分层架构 Kubernetes设计理念和功能其实就是一个类似Linux的分层架构 核心层：Kubernetes最核心的功能，对外提供API构建高层的应用，对内提供插件式应用执行环境\n应用层：部署（无状态应用、有状态应用、批处理任务、集群应用等）和路由（服务发现、DNS解析等）\n管理层：系统度量（如基础设施、容器和网络的度量），自动化（如自动扩展、动态Provision等）以及策略管理（RBAC、Quota、PSP、NetworkPolicy等）\n接口层：kubectl命令行工具、客户端SDK以及集群联邦\n生态系统：在接口层之上的庞大容器集群管理调度的生态系统，可以划分为两个范畴\nKubernetes外部：日志、监控、配置管理、CI、CD、Workflow、FaaS、OTS应用、ChatOps等\nKubernetes内部：CRI、CNI、CVI、镜像仓库、Cloud Provider、集群自身的配置和管理等\n核心组件 Kubernetes主要由以下几个核心组件组成： etcd 保存了整个集群的状态；\napiserver 提供了资源操作的唯一入口，并提供认证、授权、访问控制、API注册和发现等机制；\ncontroller manager 负责维护集群的状态，比如故障检测、自动扩展、滚动更新等；\nscheduler 负责资源的调度，按照预定的调度策略将Pod调度到相应的机器上；\nkubelet 负责维护容器的生命周期，同时也负责Volume（CVI）和网络（CNI）的管理；\nContainer runtime 负责镜像管理以及Pod和容器的真正运行（CRI）；\nkube-proxy 负责为Service提供cluster内部的服务发现和负载均衡；\n除了核心组件，还有一些推荐的Add-ons： kube-dns负责为整个集群提供DNS服务\nIngress Controller为服务提供外网入口\nHeapster提供资源监控\nDashboard提供GUI\nFederation提供跨可用区的集群\nFluentd-elasticsearch提供集群日志采集、存储与查询\n","date":"2020-10-09","permalink":"/zh-cn/posts/kubernetes/kubernetes_basic_structure/","series":null,"tags":["kubernetes","DevOps"],"title":"Kubernetes基础概念与组件架构"},{"categories":["技术博客"],"content":"","date":"2020-09-16","permalink":"/zh-cn/posts/kubernetes/what_is_cloud_native/","series":null,"tags":["kubernetes","DevOps"],"title":"容器、kubernetes、DevOps与云原生"},{"categories":["技术博客"],"content":"什么是索引，为什么要使用索引 索引是一种能提高数据查询速度的数据结构， 常用的索引数据解构有 B+ 树 和 Hash\n可以提高数据检索的效率，降低数据库的IO成本 通过索引列对数据进行排序，降低数据排序的成本，降低了CPU的消耗\n劣势：\n索引会占据磁盘空间\n索引虽然会提高查询效率，但是会降低更新表的效率\n索引类型 主键索引 索引列中的值必须是唯一的，不允许有空值。\n普通索引 MySQL中基本索引类型，没有什么限制，允许在定义索引的列中插入重复值和空值。\n唯一索引 索引列中的值必须是唯一的，但是允许为空值。\n全文索引 只能在文本类型CHAR,VARCHAR,TEXT类型字段上创建全文索引。字段长度比较大时，如果创建普通索引，在进行like模糊查询时效率比较低，这时可以创建全文索引。MyISAM和InnoDB中都可以使用全文索引。\n空间索引 MySQL在5.7之后的版本支持了空间索引，而且支持OpenGIS几何数据模型。MySQL在空间索引这方面遵循OpenGIS几何数据模型规则。\n前缀索引 在文本类型如CHAR,VARCHAR,TEXT类列上创建索引时，可以指定索引列的长度，但是数值类型不能指定。\n其他（按照索引列数量分类） ####单列索引 ####组合索引 组合索引的使用，需要遵循最左前缀匹配原则（最左匹配原则）。一般情况下在条件允许的情况下使用组合索引替代多个单列索引使用。\n为什么很少使用Hash作为索引的数据结构 Hash表在等值查询时效率很高，时间复杂度为O(1)；但是不支持范围快速查找，范围查找时还是只能通过扫描全表方式。\n什么是B+树，为什么使用B+树作为数据库索引的底层结构，为什么不使用B树 减少磁盘IO操作，就需要尽量降低树的高度，第一个根节点的位置要合理\n平衡二叉树：采用二分法思维，平衡二叉查找树除了具备二叉树的特点，最主要的特征是树的左右两个子树的层级最多相差1。\nB树，改造平衡二叉树，降低树的高度，减少磁盘IO操作。B树的高度一般2至3层就能满足大部分的应用场景，所以使用B树构建索引可以很好的提升查询的效率。\nB+树，为了解决B树不支持范围查询的快速查找\nB+树和B树最主要的区别在于非叶子节点是否存储数据的问题 B树：非叶子节点和叶子节点都会存储数据。 B+树：只有叶子节点才会存储数据，非叶子节点至存储键值。叶子节点之间使用双向指针连接，最底层的叶子节点形成了一个双向有序链表。  MyISAM索引和InnoDB索引的区别 ####MyISAM MyISAM的数据文件和索引文件是分开存储的。MyISAM使用B+树构建索引树时，叶子节点中存储的键值为索引列的值，数据为索引所在行的磁盘地址。 先在主键树中从根节点开始检索，将根节点加载到内存，比较28\u0026lt;75，走左路。（1次磁盘IO） 将左子树节点加载到内存中，比较16\u0026lt;28\u0026lt;47，向下检索。（1次磁盘IO） 检索到叶节点，将节点加载到内存中遍历，比较16\u0026lt;28，18\u0026lt;28，28=28。查找到值等于30的索引项。（1次磁盘IO） 从索引项中获取磁盘地址，然后到数据文件user.MYD中获取对应整行记录。（1次磁盘IO） 将记录返给客户端。\nInnoDB 索引 InnoDB的数据和索引存储在一个文件t_user_innodb.ibd中。InnoDB的数据组织方式，是聚簇索引。\nInnoDB索引按照叶子节点是否存储数据分为主键索引（聚簇索引）和 辅助索引 除聚簇索引之外的所有索引都称为辅助索引，InnoDB的辅助索引只会存储主键值而非磁盘地址。\n 主键索引的叶子节点会存储数据行，辅助索引只会存储主键值。  回表查询：根据在辅助索引树中获取的主键id，到主键索引树检索数据的过程称为回表查询\n组合索引和覆盖索引 组合索引的最左前缀匹配原则：使用组合索引查询时，mysql会一直向右匹配直至遇到范围查询(\u0026gt;、\u0026lt;、between、like)就停止匹配。\n覆盖索引 覆盖索引并不是说是索引结构，覆盖索引是一种很常用的优化手段。因为在使用辅助索引的时候，我们只可以拿到主键值，相当于获取数据还需要再根据主键查询主键索引再获取到数据。 但是试想下这么一种情况，在上面abc_innodb表中的组合索引查询时，如果我只需要abc字段的，那是不是意味着我们查询到组合索引的叶子节点就可以直接返回了，而不需要回表。这种情况就是覆盖索引。\n覆盖索引和联合索引是什么 覆盖索引，返回的字段建立索引，减少回表操作\n联合索引，在合理的情况下，尽可能在一个****索引中包含多个字段\n覆盖索引的字段可能不是在同一个索引，即覆盖索引中所使用的索引不一定是联合索引\n","date":"2020-03-22","permalink":"/zh-cn/posts/mysql/mysql_index/","series":null,"tags":["关系型数据库","MySQL","存储"],"title":"MySQL索引与优化"},{"categories":["技术博客"],"content":"ElasticSearch写过程 分片\n一个分片就是一个运行的Lucenes实例，个节点可以包含多个分片，Es中所有数据均衡的存储在集群中各个节点的分片中\n主分片和副本分片\n注意\n1、默认索引是5个分片\n2、分片一定设置是不可以修改的，只能新建新索引解决\n数据写入过程:\nES的任意节点都可以作为协调节点(coordinating node)接受请求，当协调节点接受到请求后进行一系列处理，然后通过_routing字段找到对应的primary shard，并将请求转发给primary shard, primary shard完成写入后， 将写入并发发送给各replica， raplica执行写入操作后返回给primary shard， primary shard再将请求返回给协调节点\n数据持久化步骤如下：write -\u0026gt; refresh -\u0026gt; flush -\u0026gt; merge\nwrite:一个新文档过来，会存储在 in-memory buffer 内存缓存区中，顺便会记录 Translog。(这时候数据还没到 segment ，是搜不到这个新文档的。数据只有被 refresh 后，才可以被搜索到,设置了refresh时间，所以是准实时)\nrefresh: 1、in-memory buffer 中的文档写入到新的 segment 中，但 segment 是存储在文件系统的缓存中。此时文档可以被搜索到; 2、最后清空 in-memory buffer。注意: Translog 没有被清空，为了将 segment 数据写到磁盘\nflush:将segment从文件系统缓存写入磁盘。最后清空translog。translog 作用很大：保证文件缓存中的文档不丢失；系统重启时，从 translog 中恢复；新的 segment 收录到 commit point 中\nmerge： 当磁盘中的segment越来越多，会导致搜索速度变慢，通过merge将小段文件合并为大文件。\nElasticSearch读过程 客户端发送请求到任意一个node，成为coordinate node\ncoordinate node对document进行路由，将请求转发到对应的node，此时会使用round-robin随机轮询算法，在primary shard以及其所有replica中随机选择一个，让读请求负载均衡\n接收请求的node返回document给coordinate node\ncoordinate node返回document给客户端\n写入document时，每个document会自动分配一个全局唯一的id即doc id，同时也是根据doc id进行hash路由到对应的primary shard上。也可以手动指定doc id，比如用订单id，用户id。\n读取document时，你可以通过doc id来查询，然后会根据doc id进行hash，判断出来当时把doc id分配到了哪个shard上面去，从那个shard去查询）\nElasticSearch 数据搜索过程 客户端发送请求到一个coordinate node\n协调节点将搜索请求转发到所有的shard对应的primary shard或replica shard也可以\nquery phase：每个shard将自己的搜索结果（其实就是一些doc id），返回给协调节点，由协调节点进行数据的合并、排序、分页等操作，产出最终结果\nfetch phase：接着由协调节点，根据doc id去各个节点上拉取实际的document数据，最终返回给客户端\n","date":"2020-03-07","permalink":"/zh-cn/posts/elasticsearch/elasticsearch_read_write_search_process/","series":null,"tags":["ElasticSearch","OLAP","大数据"],"title":"Elasticsearch数据的写入、读取与检索过程详解"},{"categories":["技术博客"],"content":"常用可视化形式 折线图（Line, area, and bar charts），面积图和条形图—比较X / Y图表中的不同系列。\n饼图（Pie chart ）-显示每个来源总计。\n数据表（Data table ）-将聚合展平为表格式。\n公制（Data table ）—显示一个数字。\n目标和计量器（Goal and gauge ）—显示带有进度指示器的数字。\n标签云（Goal and gauge ）—在云中显示单词，单词的大小与其重要性相对应。\nLens 快速可视化，拖放需要统计的字段即可快速构建可视化\nTSVB 使用管道聚合可视化时间序列数据\nTimelion 计算和合并来自多个时间序列数据集的数据\nMaps 地图\nHeat Map 热图 显示矩阵内的阴影单元格\nDashboard tools 文字信息部件（Markdown widget）显示自由格式的信息或说明。\n控件（ Controls）： 将交互式输入添加到仪表板\nVega 完成对查询和显示的控制\n","date":"2020-03-07","permalink":"/zh-cn/posts/elasticsearch/kibana_visualization_type/","series":null,"tags":["Kibana","OLAP","大数据"],"title":"Kibana可视化展示的各种形式汇总"},{"categories":["技术博客"],"content":"聚合的两个核心概念：桶（bucket）和指标（metric）\n　桶（bucket）: 满足特定条件的文档的集合\n指标（metric）: 对桶内的文档进行聚合分析的操作\n桶在概念上类似于SQL的分组（GROUP BY）,而指标则类似于COUNT()、SUM()、MAX()等统计方法。\n2、桶和指标的深入理解\n（1）桶　　a、简单来说桶就是满足特定条件的文档的集合。\n　b、当聚合开始被执行，每个文档里面的值通过计算来决定符合哪个桶的条件，如果匹配到，文档将放入相应的桶并接着开始聚合操作。\n　c、桶也可以被嵌套在其他桶里面。\n（2）指标\n　a、桶能让我们划分文档到有意义的集合，但是最终我们需要的是对这些桶内的文档进行一些指标的计算。分桶是一种达到目的地的手段：它提供了一种给文档分组的方法来让我们可以计算感兴趣的指标。\n　b、大多数指标是简单的数学运算（如：最小值、平均值、最大值、汇总），这些是通过文档的值来计算的。\n（3）桶和指标的组合\n　聚合是由桶和指标组成的。聚合可能只有一个桶，可能只有一个指标，或者可能两个都有。也有可能一些桶嵌套在其他桶里面。\n","date":"2020-03-05","permalink":"/zh-cn/posts/elasticsearch/elasticsearch_buckets_metrics/","series":null,"tags":["ElasticSearch","OLAP","大数据"],"title":"Elasticsearch聚合—桶（bucket）和指标（metric）"},{"categories":["技术博客"],"content":"","date":"2020-03-05","permalink":"/zh-cn/posts/elasticsearch/elasticsearch_inverted_index/","series":null,"tags":["ElasticSearch","OLAP","大数据"],"title":"ElasticSearch倒排索引原理探索"},{"categories":["技术博客"],"content":"","date":"2020-03-02","permalink":"/zh-cn/posts/other/lsm_store/","series":null,"tags":[],"title":"深入理解LSM存储结构"},{"categories":["技术博客"],"content":"1.1、设计阶段调优\n（1）根据业务增量需求，采取基于日期模板创建索引，通过roll over API滚动索引； （2）使用别名进行索引管理； （3）每天凌晨定时对索引做force_merge操作，以释放空间； （4）采取冷热分离机制，热数据存储到SSD，提高检索效率；冷数据定期进行shrink操作，以缩减存储； （5）采取curator进行索引的生命周期管理； （6）仅针对需要分词的字段，合理的设置分词器； （7）Mapping阶段充分结合各个字段的属性，是否需要检索、是否需要存储等。……..\n1.2、写入调优\n（1）写入前副本数设置为0； （2）写入前关闭refresh_interval设置为-1，禁用刷新机制； （3）写入过程中：采取bulk批量写入； （4）写入后恢复副本数和刷新间隔； （5）尽量使用自动生成的id。\n1.3、查询调优\n（1）禁用wildcard； （2）、禁用批量terms（成百上千的场景）； （3）充分利用倒排索引机制，能keyword类型尽量keyword； （4）数据量大时候，可以先基于时间敲定索引再检索； （5）设置合理的路由机制。\n1.4、其他调优 部署调优，业务调优等。 上面的提及一部分，面试者就基本对你之前的实践或者运维经验有所评估了。\n","date":"2020-02-29","permalink":"/zh-cn/posts/elasticsearch/elasticsearch_cluster/","series":null,"tags":["ElasticSearch","OLAP","大数据"],"title":"ElasticSearch集群与调优"},{"categories":["技术博客"],"content":"","date":"2020-02-25","permalink":"/zh-cn/posts/elasticsearch/elasticsearch_data_input/","series":null,"tags":["ElasticSearch","OLAP","大数据"],"title":"ElasticSearch 数据导入方案"},{"categories":["技术博客"],"content":"","date":"2020-02-22","permalink":"/zh-cn/posts/elasticsearch/elasticsearch_account_management_and_security/","series":null,"tags":["ElasticSearch","OLAP","大数据"],"title":"ElasticSearch用户权限与安全机制"},{"categories":["技术博客"],"content":"基本概念 集群(cluster)：有一个主节点，通过选举产生，从外部来看es集群，在逻辑上是个整体，你与任何一个节点的通信和与整个es集群通信是等价的。\n索引(index)：数据可以存储在不同索引中，索引可以看做是传统中的数据库，可以在索引中写入文档和搜索文档\n文档(document)，文档由字段组成，是ES索引中数据存储的基本单位\n映射(mapping)：所有文档写进索引之前都会先进行分析，如何将输入的文本分割为词条、哪些词条又会被过滤，这种行为叫做映射（mapping）。一般由用户自己定义规则。\n分片(shards)：一个完整索引可以分成多个分片分布到不同节点，分布式存储分布式搜索分片的数量只能在索引创建前指定，并且索引创建后不能更改。5.X默认不能通过配置文件定义分片\n副本(replicas)：代表索引副本，可设置多个，提高系统容错性（分片损坏可从副本恢复），还能通过对副本自动请求搜索负载均衡，提高ES查询效率\n数据恢复(Discovery)：当挂掉的节点重新启动加入，会进行数据恢复\n数据源(River)：ES数据的来源，它是以插件方式存在的一个es服务，通过读取river中的数据并把它索引到es中，官方的river有couchDB的，RabbitMQ的，Twitter的，Wikipedia的，river这个功能将会在后面的文件中重点说到。\n网关（gateway）：代表es索引的持久化存储方式，es默认是先把索引存放到内存中，当内存满了时再持久化到硬盘。当这个es集群关闭再重新启动时就会从gateway中读取索引数据。es支持多种类型的gateway，有本地文件系统（默认），分布式文件系统，Hadoop的HDFS和amazon的s3云存储服务。\n自动发现（discovery.zen）：代表es的自动发现节点机制，es是一个基于p2p的系统，它先通过广播寻找存在的节点，再通过多播协议来进行节点之间的通信，同时也支持点对点的交互。5.X关闭广播，需要自定义\n通信（Transport） ：代表es内部节点或集群与客户端的交互方式，默认内部是使用tcp协议进行交互，同时它支持http协议（json格式）、thrift、servlet、memcached、zeroMQ等的传输协议（通过插件方式集成）。节点间通信端口默认：9300-9400\n分片和复制（shards and replicas） ：一个索引可以存储超出单个结点硬件限制的大量数据。比如，一个具有10亿文档的索引占据1TB的磁盘空间，而任一节点可能没有这样大的磁盘空间来存储或者单个节点处理搜索请求，响应会太慢。\n为了解决这个问题，Elasticsearch提供了将索引划分成多片的能力，这些片叫做分片。当你创建一个索引的时候，你可以指定你想要的分片的数量。每个分片本身也是一个功能完善并且独立的“索引”，这个“索引” 可以被放置到集群中的任何节点上。\n分片之所以重要，主要有两方面的原因：\n1、允许你水平分割/扩展你的内容容量\n2、允许你在分片（位于多个节点上）之上进行分布式的、并行的操作，进而提高性能/吞吐量\n至于一个分片怎样分布，它的文档怎样聚合回搜索请求，是完全由Elasticsearch管理的，对于作为用户的你来说，这些都是透明的。\n在一个网络/云的环境里，失败随时都可能发生。在某个分片/节点因为某些原因处于离线状态或者消失的情况下，故障转移机制是非常有用且强烈推荐的。为此， Elasticsearch允许你创建分片的一份或多份拷贝，这些拷贝叫做复制分片，或者直接叫复制。\n复制之所以重要，有两个主要原因：\n在分片/节点失败的情况下，复制提供了高可用性。复制分片不与原/主要分片置于同一节点上是非常重要的。因为搜索可以在所有的复制上并行运行，提高搜索速度。\n","date":"2020-02-20","permalink":"/zh-cn/posts/elasticsearch/elasticsearch__structure/","series":null,"tags":["ElasticSearch","OLAP","大数据"],"title":"ElasticSearch基础概念与架构原理"},{"categories":["技术博客"],"content":"Mapping数据建模 数据建模即创建数据模型的过程，它主要分为以下的步骤\n概念分析：确定系统的核心需求和范围边界，设计实现和实体间的关系 逻辑模型：进一步梳理业务需求，确定每个实体的属性、关系和约束等 物理模型：结合具体的数据库产品，在满足业务读写性能等需求的前提下确定最终的定义\nElasticSearch索引建立可以遵循一个流程：字段类型——是否要搜索及分词——是否要聚合及排序——是否要额外的存储\n是何种类型？ 字符串类型：需要分词设定为text类型，否则设置为keyword类型 枚举类型：基于性能考虑将其设定为keyword类型，即便该数据为整型（如状态码） 数值类型：尽量选择贴近的类型，比如byte即可表示所有数值时，即选用byte,不要用long 其他类型：比如布尔类型、日期、地理位置数据等\n是否需要检索？ 完全不需要检索、排序、聚合分析的字段：enable设置为false 不需要检索的字段：index设置为false 需要检索的字段，可以通过如下配置设定需要的存储粒度 index_options: 结合需要设定 norms: 不需要归一化数据时关闭即可 ####是否需要排序和聚合分析？ 不需要排序或者聚合分析功能：\ndoc_values设定为false fielddata设定为false ####是否需要专门存储当前字段的数据？ store设定为true,即可存储该字段的原始内容（与_source中的不相关） 一般结合_source的enabled设定为false时使用\n索引建立Mapping的过程如下图所示\nmapping 设计非常重要，需要从两个维度进行考虑：\n功能：搜索、排序、聚合 性能：存储的开锁、内存的开销、搜索的性能 mapping 注意事项： 加入新字段很容易（必要时需要 update_by_query） 更新删除字段不允许（需要 reindex 重建数据）\n下面列出Mapping 字段的相关设置：\n   参数 取值 说明     enabled ture/false 默认为true, false：仅存储，不做搜索或聚合分析(比如cookie/session字段)   index ture/false 控制当前字段是否索引，默认为true,即记录索引，false不记录，即不可搜索   index_options docs/freqs/positions/offsets 存储倒排索引的哪些信息,text类型默认配置为positions,其他默认为docs ,记录内容越多，占用空间越大。   norms true/false 是否存储归一化相关参数，如果字段仅用于过滤和聚合分析，可关闭   doc_values true/false 是否启用doc_values,用于排序和聚合分析   field_data true/false 是否为text类型启用fielddata,实现排序和聚合分析   store true/false 是否存储该字段值,默认是false   coerce true/false 是否开启自动数据类型转换功能，比如字符串转换为数字、浮点转换为整型等（默认是true   multifields - 多字段-灵活使用多字段特性来解决多样的业务需求   dynamic true/false/strict 控制mapping自动更新   date_detection true/false 是否自动识别日期类型    常用规则   如果索引不允许自动新增字段，将 dynamic 设置成 strict。默认为 true；\n  不需要分词的字段，将 type 设置成 keyword。默认使用了多字段特性，text、keyword这2种类型都有；\n  不需要建立索引的字段，将 index 设置成 false。默认为 true；\n  不需要排序和聚合的字段，将 doc_values 设置成false。默认为 true；\n  不需要检查、排序、聚合的字段，将 enable 设置成 false，仅做存储；\n  type = text 的字段，默认不可以排序，如需要排序，将 fielddata 设置成 true，默认为 false；\n  单个索引避免过多字段，默认最大值为1000；\n  避免空值引起的聚合不准确的问题；\n  避免使用正则查询；\n  尽量不要设计成索引关联，可冗余多一些字段，以空间换时间，如实在无法避免，按以下方式处理：\n   Object:优先考虑Denormalization； Nested： 当数据包含多数值对象，同时有查询请求； Child/Parent:关联文档更新非常频繁时  ","date":"2020-02-16","permalink":"/zh-cn/posts/elasticsearch/elasticsearch_data_modeling/","series":null,"tags":["ElasticSearch","OLAP","大数据"],"title":"ElasticSearch Mapping 数据建模规范与建模过程"},{"categories":["技术博客"],"content":"简单查询 精准查询term （完全匹配，不使用分词器） term单值查询\n{ \u0026quot;query\u0026quot;: { \u0026quot;term\u0026quot;: { \u0026quot;productType\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;101\u0026quot; } } } } term多值查询\nGET /test/_search { \u0026quot;query\u0026quot;: { \u0026quot;bool\u0026quot;: { \u0026quot;must\u0026quot;: [ { \u0026quot;term\u0026quot;: { \u0026quot;mac\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;2541229\u0026quot; } } }, { \u0026quot;term\u0026quot;: { \u0026quot;productType\u0026quot;: { \u0026quot;value\u0026quot;: \u0026quot;1\u0026quot; } } } ] } } } terms查询多值\n{ \u0026quot;query\u0026quot;: { \u0026quot;terms\u0026quot;: { \u0026quot;productType\u0026quot;:[\u0026quot;101\u0026quot;,\u0026quot;102\u0026quot;] } } } 模糊查询 （模糊匹配，使用分词器） match 、 match_all、multi_match、match_phrase\nmatch_all 匹配所有的， 当不给查询条件时，默认全查 match\n { \u0026quot;query\u0026quot;: { \u0026quot;match\u0026quot;: { \u0026quot;username\u0026quot;: \u0026quot;张三\u0026quot; } } } multi_match 同时对查询的关键词，多个字段同时进行匹配，即多个字段是AND的关系 更丰富的查询 按brandName（品牌名）、sortName（分类名）、productName（商品名）productKeyword（商品关键字），搜索“牛仔 弹力”关键词， brandName源值、拼音值、关键字值都是100分，sortName源值、拼音值80分，productName源值60分，productKeyword值20分，分值由高到低优先级搜索\n{ \u0026quot;query\u0026quot;: { \u0026quot;multi_match\u0026quot;: { \u0026quot;query\u0026quot;: \u0026quot;牛仔 弹力\u0026quot;, \u0026quot;fields\u0026quot;: [ \u0026quot;brandName^100\u0026quot;, \u0026quot;brandName.brandName_pinyin^100\u0026quot;, \u0026quot;brandName.brandName_keyword^100\u0026quot;, \u0026quot;sortName^80\u0026quot;, \u0026quot;sortName.sortName_pinyin^80\u0026quot;, \u0026quot;productName^60\u0026quot;, \u0026quot;productKeyword^20\u0026quot; ], \u0026quot;type\u0026quot;: \u0026lt;multi-match-type\u0026gt;, \u0026quot;operator\u0026quot;: \u0026quot;AND\u0026quot; } } } match_phrase 查询分析文本，并从分析文本中创建短语查询。（即对查询的条件也进行分词，然后使用分词进行匹配查询）\nwildcard：通配符查询  表示全匹配，？ 表示单一匹配，etc： aaa* 或者 a?b；  prefix：前缀匹配 搜索框如果输入aa,那么可能匹配到的字段值为 aab,aavb等；\nfuzzy min_similarity：弹性模糊匹配 有两个搜索框，第一个搜索框为搜索匹配值，会自动纠错，比如输入 ggjk,那么可能会匹配到ggjo，第二个框为最小相似度，采用的算法是Damerau-Levenshtein（最佳字符串对齐）算法，不建议填写这个框，我到发稿前也是被搞的头皮发麻，等我完全吃透再更新；\nfuzzy max_expansions ：弹性模糊匹配 有两个搜索框，第一个搜索框为搜索匹配值，会自动纠错，比如输入gjk,那么可能会匹配到ggjo，第二个框是最大扩展匹配数，比如是1，那么ggjk只会随机模糊匹配到一种可能结果，即使它会出现2种或者更加多，也只会搜索一种；\nrange：范围查询 gt为大于，gte为大于等于，lt小于，lte小于等于，所搜索的字段值在两个搜索框标识数值之间；\nquery_string：字符片段查询， 如果是数字，则严格匹配数字，如果是字符串，则按照自身或者分片词匹配；\ntext：分片词查询，等确定后更新； missing：查询没有定义该字段或者该字段值为null的数据。 compound query(复合查询)bool query、boosting query、constant_score query、dis_max query、 function_score 的区别 bool query（多查询或复合查询的默认查询方式） 用于组合多个叶子或复合查询子句的默认查询，包含must, should, must_not, or filter 。must和should子句将它们的分数组合在一起 - 匹配子句越多越好 - 而must_not和filter子句在过滤器上下文中执行。\n　must：返回的文档必须满足must子句的条件，并且参与计算分值\n　filter：返回的文档必须满足filter子句的条件。不参与计算分值\n　must_not：返回的文档必须不满足must_not定义的条件。不参与评分。\n　should：返回的文档可能满足should子句的条件。在一个Bool查询中，如果没有must或者filter，有一个或者多个should子句，那么只要满足一个就可以返回。minimum_should_match参数定义了至少满足几个子句。\n注1：评分计算 bool 查询会为每个文档计算相关度评分 _score ， 再将所有匹配的 must 和 should 语句的分数 _score 求和，最后除以 must 和 should 语句的总数。 must_not 语句不会影响评分； 它的作用只是将不相关的文档排除。\n注2：控制精度 所有 must 语句必须匹配，所有 must_not 语句都必须不匹配，但有多少 should 语句应该匹配呢？ 默认情况下，没有 should 语句是必须匹配的，只有一个例外：那就是当没有 must 语句的时候，至少有一个 should 语句必须匹配。 就像我们能控制 match 查询的精度 一样，我们可以通过 minimum_should_match 参数控制需要匹配的 should 语句的数量， 它既可以是一个绝对的数字，又可以是个百分比：\nboosting query 提升查询可用于有效降级与给定查询匹配的结果。与bool查询中的“NOT”子句不同，这仍然会选择包含不良术语的文档，但会降低其总分。\nconstant_score query 含另一个查询但在过滤器上下文中执行的查询。所有匹配的文档都给出相同的“常量”_score\ndis_max query 一个接受多个查询的查询，并返回与任何查询子句匹配的任何文档。虽然bool查询组合了所有匹配查询的分数，但dis_max查询使用单个最佳匹配查询子句的分数。\n一个查询，它生成由其子查询生成的文档的并集，并为每个文档评分由任何子查询生成的该文档的最大分数，以及任何其他匹配子查询的平局增量。\n当在具有不同增强因子的多个字段中搜索单词时，这非常有用（因此不能将字段等效地组合到单个搜索字段中）。我们希望主要分数是与最高提升相关联的分数，而不是字段分数的总和（如布尔查询所给出的）。如果查询是“albino elephant”，则这确保匹配一个字段的“albino”和匹配另一个的“elephant”获得比匹配两个字段的“albino”更高的分数。要获得此结果，请同时使用Boolean Query和DisjunctionMax Query：对于每个术语，DisjunctionMaxQuery在每个字段中搜索它，而将这些DisjunctionMaxQuery的集合组合成BooleanQuery。　function_score query 使用函数修改主查询返回的分数，以考虑流行度、最近度、距离或使用脚本实现的自定义算法等因素。\n地理坐标的查询 **矩形范围内 查询 geo_bounding_box query\n坐标距离范围 查询 geo_distance query\n{ \u0026quot;query\u0026quot;: { \u0026quot;geo_distance\u0026quot;: { \u0026quot;distance\u0026quot;: \u0026quot;100km\u0026quot;, \u0026quot;location\u0026quot;: { \u0026quot;lat\u0026quot;: 40, \u0026quot;lon\u0026quot;: -70 } } } } 多边形范围内查询 geo_polygon query\ngeo_shape query\ngeo-shapes 与指定的几何形状相交，包含于其中或不与指定的几何形状相交的对象 geo-points 与指定的地理形状相交\n查询中Query context和Filter context的区别、什么是相关性得分 1、查询上下文中，查询操作不仅仅会进行查询，还会计算分值，用于确定相关度；在过滤器上下文中，查询操作仅判断是否满足查询条件\n2、 过滤器上下文中，查询的结果可以被缓存。\n","date":"2020-02-15","permalink":"/zh-cn/posts/elasticsearch/elasticsearch_query_dsl/","series":null,"tags":["ElasticSearch","OLAP","大数据"],"title":"Elasticsearch的DSL——常用检索、复合检索、高级检索"},{"categories":["技术博客"],"content":"","date":"2020-02-11","permalink":"/zh-cn/posts/elasticsearch/elasticsearch_lifecycle_management/","series":null,"tags":["ElasticSearch","OLAP","大数据"],"title":"ElasticSearch 生命周期管理——索引生命周期与冷热数据分离"},{"categories":["技术博客"],"content":"ElasticSearch数据类型 基础类型 String keyword字段通常用于排序， 聚合和术语级查询\nkeyword类型\n（keyword类型可设置属性：boost、doc_values、eager_global_ordinals、fields、ignore_above、index、index_options、norms、null_value、store、similarity、normalizer、split_queries_on_whitespace、meta）\nconstant_keyword类型\n提交的值只能是固定的或者没有该值 （constant_keyword类型可设置的属性：meta、value）\nwildcard类型\n存储为通配符grep式查询优化的值 （可设置的参数：ignore_above） wildcard 字段像关键字字段一样是未标记的，因此不支持依赖词位置的查询，例如短语查询\ntext类型\ntext将对字段值进行分析以进行全文本搜索 （可设置属性：analyzer、boost、eager_global_ordinals、fielddata、fielddata_frequency_filter、fields、index、index_options、index_prefixes、index_pharses、norms、position_increment_gap、store、search_analyzer、search_quote_analyzer、similarity、term_vector、meta）\n数字 long类型\ninteger类型\nshort类型\nbyte类型\ndouble类型\nfloat类型\nhalf float类型\nscaled float类型\n（数字类型可设置参数：coerce、boost、doc_values、ignore_malformed、index、null_value、source、meta；scaled_float 接受一个附加参数：scaling_factor）\n时间 date类型\n（date类型可设置的属性：boost、doc_values、index、null_value、store、meta、format、locale、ignore_malformed） **日期格式可以自定义，但是如果未format指定，则使用默认格式：“ strict_date_optional_time || epoch_millis”\ndate_nanos类型\ndate_nanos类型（是date的补充，增加了纳秒级别的时间戳和格式时间支持，1420070400 ） **日期格式可以自定义，但是如果未format指定，则使用默认格式：“ strict_date_optional_time || epoch_millis”\n布尔 boolean类型\n（boolean可设置属性：boost、doc_values、index、null_value、store、meta）\n二进制 binary类型\n（binary类型可设置的属性，doc_values，store）\n区间 integer range类型\nfloat range类型\nlong ranage类型\ndouble range类型\ndate range类型\nip_range类型\n（可设置属性：coerce、boost、index、store）\n复杂文档 Array数组类型\n没有特定的mapping类型，elasticsearch默认支持相同类型的多个值\nObject类型\n对象类型，可包含内部对象 （object对象可设置属性：dynamic、enabled、properties、）\nNested类型\nNeste是object数据类型的专用版本 nested字段可设置的属性：dynamic、properties、include_in_parent、include_in_root； 设置限制：index.mapping.nested_fields.limit，index.mapping.nested_objects.limit） 如果您需要索引对象数组并保持数组中每个对象的独立性，请使用nested数据类型而不是 object数据类型。\nGEO地理位置 geo point类型\n存储经纬度 （可设置的属性参数：ignore_malformed、ignore_z_value、null_value） 场景： 以在边界框内，中心点一定距离内，多边形内或geo_shape查询中找到地理位置。 以地理位置 或距中心点的距离汇总文档。 将距离整合到文档的相关性分数中。 按距离对文档 进行排序。\ngeo shape类型\nIP ip类型\n存储ip4、ip6地址 （ip类型可设置属性:boost、doc_values、index、null_values、store）\n自动补全 completion类型\nString长度 token_count类型\n父子索引Join Join类型：存储存在父子关系的文档，树状结构等\n别名 alias类型\nalias类型：字段名称的别名搜索 示例：\nPUT trips { \u0026quot;mappings\u0026quot;: { \u0026quot;properties\u0026quot;: { \u0026quot;distance\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;long\u0026quot; }, \u0026quot;route_length_miles\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;alias\u0026quot;, \u0026quot;path\u0026quot;: \u0026quot;distance\u0026quot; }, \u0026quot;transit_mode\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; } } } }  Dense vector dense_vector类型 密集矢量类型\nHistogram histogram直方图数据类型\n存储直方图数据，两个数组必须等长 ####Flattened flattened类型\n此数据类型对于索引具有大量或未知数量的唯一键的对象很有用。将整个对象映射为单个字段，仅为整个JSON对象创建一个字段映射 flattened类型可设置的属性：boost、depth_limit、doc_values、eager_global_ordinals、ignore_above、index、index_options、null_value、similarity，split_queries_on_whitespace）\nPercolator percolator类型\nPoint point类型\n二维坐标点 （可设置属性：ignore_malformd、ignore_z_value、null）\nRank feature rank_featur类型\n用于rank_feature查询\nRank features rank_features类型\n用户多个属性的rank_feature查询\nSparse vector sparse_vector类型\nShape shape类型\nSearch-as-you-type search_as_you_type类型\n用于特定搜素的数据存储，前缀、中缀搜索 （特定设置属性：max_shingle_size）\nElasticSearch的Mapping参数 以下映射参数对于某些或所有字段数据类型是通用的：\nanalyzer 仅text字段支持analyzer映射参数，用于指定文本分析的分析器，\nboost 修改字段的得分权重（不建议使用）\ncoerce true|false,将数据以合适的值进行存储 字符串将被强制转换为数字。 浮点将被截断为整数值。\ncopy_to true|false ,将多个字段的值复制到组字段中，然后可以将其作为单个字段进行查询，提高搜索嘟嘟\ndoc_values true|false: 字段排序或聚合\n几乎所有字段类型都支持Doc值，但textandannotated_text字段除外。\n默认情况下，所有支持doc值的字段均已启用它们,不需要可关闭从而节约磁盘空间\ndynamic true|false|strict\n该dynamic设置控制是否可以动态添加新字段。\neager_global_ordinals 如果您正在优化索引速度，那么这是正确的方法，但是如果搜索性能是优先考虑的情况，建议您急切地在将用于聚合的字段上急切加载全局序号：\nenabled enabled设置仅可应用于顶级映射定义和object字段，设置是否建立索引\nfielddata text字段使用称为的查询时内存数据结构 fielddata\nfields 为不同的目的以不同的方式对同一字段建立索引\nformat 设置日期的格式\nignore_above 长于ignore_above设置的字符串将不会被索引或存储。\nignore_malformed 是否拒接错误数据类型的文档\nindex_options 该index_options参数控制将哪些信息添加到反向索引中以进行搜索和突出显示，这个参数只能在text中使用\nindex_phrases 加快词语搜索\nindex_prefixes 加快前缀搜索\nindex 是否对字段值建立索引\nmeta 设置字段限制\nnormalizer norms 字段是否参与评分\nnull_value 使用指定的值替换空值，以便搜索\nposition_increment_gap properties search_analyzer similarity 相似度算法\nstore 对字段值进行索引时，是否存储数据\nterm_vector 存储特定术语以方便文档检索\n","date":"2020-02-10","permalink":"/zh-cn/posts/elasticsearch/elasticsearch_datatype/","series":null,"tags":["ElasticSearch","OLAP","大数据"],"title":"ElasticSearch 7.9 数据类型和Mapping参数详解"},{"categories":["life"],"content":"关于我  我是一名专注于Java架构和大数据开发的互联网人。 2020，是我毕业后在职场的第二年，但也知道了自己的兴趣方向，明白了生活的不易。之前都是在CSDN https://blog.csdn.net/Jack__iT\r上写博客，现在想有个专属的小天地。\n我也许只是浩瀚星辰中的小星星，但这并无法阻挡我发出自己的光芒。\n共勉 忘了在哪看到的这段话，算是挺有意思的鸡汤吧，咱一起喝碗鸡汤补补：\n纽约时间比加州时间早三个小时，\nNew York is 3 hours ahead of California,\n但加州时间并没有变慢。\nbut it does not make California slow.\n有人22岁就毕业了，\nSomeone graduated at the age of 22,\n但等了五年才找到好的工作！\nbut waited 5 years before securing a good job!\n有人25岁就当上CEO，\nSomeone became a CEO at 25,\n却在50岁去世。\nand died at 50.\n也有人迟到50岁才当上CEO，\nWhile another became a CEO at 50,\n然后活到90岁。\nand lived to 90 years.\n有人依然单身，\nSomeone is still single,\n同时也有人已婚。\nwhile someone else got married.\n奥巴马55岁就退休，\nObama retires at 55,\n川普70岁才开始当总统。\nbut Trump starts at 70.\n世上每个人本来就有自己的发展时区。\nAbsolutely everyone in this world works based on their Time Zone.\n身边有些人看似走在你前面，\nPeople around you might seem to go ahead of you,\n也有人看似走在你后面。\nsome might seem to be behind you.\n但其实每个人在自己的时区有自己的步程。\nBut everyone is running their own RACE, in their own TIME.\n不用嫉妒或嘲笑他们。\nDon’t envy them or mock them.\n他们都在自己的时区里，你也是！\nThey are in their TIME ZONE, and you are in yours!\n生命就是等待正确的行动时机。\nLife is about waiting for the right moment to act.\n所以，放轻松。\nSo, RELAX.\n你没有落后。\nYou’re not LATE.\n你没有领先。\nYou’re not EARLY.\n在命运为你安排的属于自己的时区里，一切都准时。\nYou are very much ON TIME, and in your TIME ZONE Destiny set up for you.\n","date":"2020-02-09","permalink":"/zh-cn/posts/life/hello/","series":null,"tags":["随笔","感想"],"title":"你好，第一篇手记"},{"categories":["技术博客"],"content":"Java各个版本的特性 Java 5 1、泛型\n2、增强for循环\n3、自动装箱拆箱\n4、枚举\n5、可变参数\n6、静态导入\n7、自定义注解 关键字 @interface\nJava 6 1、集合框架增强 为了更好的支持双向访问集合。添加了许多新的类和接口。 新的数组拷贝方法。Arrays.copyOf和Arrays.copyOfRange\n2、为了更好的支持双向访问集合。添加了许多新的类和接口。 新的数组拷贝方法。Arrays.copyOf和Arrays.copyOfRange\n3、支持JDBC4.0规范\nJava 7 Swing\n新增 JLayer 类，是一个灵活而且功能强大的Swing组件修饰器，使用方法：How to Decorate Components with JLayer. Nimbus Look and Feel 外观从 com.sun.java.swing 包移到 javax.swing 包中，详情：javax.swing.plaf.nimbus 更轻松的重量级和轻量级组件的混合 支持透明窗体以及非矩形窗体的图形界面，请看 How to Create Translucent and Shaped Windows JColorChooser 类新增 HSV tab.  网络\n新增 URLClassLoader.close 方法，请看 Closing a URLClassLoader. 支持 Sockets Direct Protocol (SDP) 提供高性能网络连接，详情请看 Understanding the Sockets Direct Protocol.  集合\n新增 TransferQueue 接口，是 BlockingQueue 的改进版，实现类为 LinkedTransferQueue  RIA/发布\n拖拽的小程序使用一个默认或者定制的标题进行修饰  XML\n包含 Java API for XML Processing (JAXP) 1.4.5, 支持 Java Architecture for XML Binding (JAXB) 2.2.3, 和 Java API for XML Web Services (JAX-WS) 2.2.4.  java.lang 包\n消除了在多线程环境下的非层次话类加载时导致的潜在死锁，详情：Multithreaded Custom Class Loaders in Java SE 7.  Java 虚拟机\n支持非 Java 语言: Java SE 7 引入一个新的 JVM 指令用于简化实现动态类型编程语言 Garbage-First Collector 是一个服务器端的垃圾收集器用于替换 Concurrent Mark-Sweep Collector (CMS). 提升了 Java HotSpot 虚拟机的性能  Java I/O\njava.nio.file 包以及相关的包 java.nio.file.attribute 提供对文件 I/O 以及访问文件系统的全面支持，请看 File I/O (featuring NIO.2). 目录 /sample/nio/chatserver/ 包含使用 java.nio.file 包的演示程序 目录 /demo/nio/zipfs/ 包含 NIO.2 NFS 文件系统的演示程序  安全性\n新的内置对多个基于 ECC 算法(ECDSA/ECDH)的支持，详情请看：Sun PKCS#11 Provider's Supported Algorithms in Java PKCS#11 Reference Guide. 禁用了一些弱加密算法，详情请看 Appendix D: Disabling Cryptographic Algorithms in Java PKI Programmer's Guide and Disabled Cryptographic Algorithms in Java Secure Socket Extension (JSSE) Reference Guide. Java 安全套接字扩展中对 SSL/TLS 的增强  并发\nfork/join 框架，基于 ForkJoinPool 类，是 Executor 接口的实现，设计它用来进行高效的运行大量任务；使用 work-stealing 技术用来保证大量的 worker 线程工作，特别适合多处理器环境，详情请看 Fork/Join目录/sample/forkjoin/ 包含了 fork/join 框架的演示程序 ThreadLocalRandom 类class 消除了使用伪随机码线程的竞争，请看 Concurrent Random Numbers. Phaser 类是一个新的同步的屏障，与 CyclicBarrier 类似.Java 2D 一个新的基于 XRender 的 Java 2D 渲染管道支持现在的 X11 桌面，改善了图形性能，请看 System Properties for Java 2D Technology 中的 xrender . JDK 可枚举并显示出已安装的 OpenType/CFF 字体，通过 GraphicsEnvironment.getAvailableFontFamilyNames 方法 See Selecting a Font. TextLayout 类支持西藏语脚本 libfontconfig, 是一个字体配置 api ，see Fontconfig.  国际化\n支持 Unicode 6.0.0目录 /demo/jfc/Font2DTest/ 包含 Unicode 6.0 的演示程序Java SE 7 可容纳在 ISO 4217 中新的货币，详情请看 Currency 类.  Java 编程语言特性\n二进制数字表达方式 使用下划线对数字进行分隔表达，例如 1_322_222 switch 语句支持字符串变量 泛型实例创建的类型推断 使用可变参数时，提升编译器的警告和错误信息 try-with-resources 语句 同时捕获多个异常处理  JDBC 4.1 支持使用 try-with-resources 语句进行自动的资源释放，包括连接、语句和结果集 支持 RowSet 1.1\nJava 8 1、lambada表达式(Lambda Expressions)。Lambda允许把函数作为一个方法的参数（函数作为参数传递进方法中)。\n2、方法引用（Method references）。方法引用提供了非常有用的语法，可以直接引用已有Java类或对象（实例）的方法或构造器。与lambda联合使用，可以使语言的构造更紧凑简洁，减少冗余代码。\n3、默认方法（Default methods）。默认方法允许将新功能添加到库的接口中，并确保兼容实现老版本接口的旧有代码。\n4、重复注解（Repeating Annotations）。重复注解提供了在同一声明或类型中多次应用相同注解类型的能力。\n5、类型注解（Type Annotation）。在任何地方都能使用注解，而不是在声明的地方。\n6、类型推断增强。\n7、方法参数反射（Method Parameter Reflection）。\n8、Stream API 。新添加的Stream API（java.util.stream） 把真正的函数式编程风格引入到Java中。Stream API集成到了Collections API里。\n9、HashMap改进，在键值哈希冲突时能有更好表现。\n10、Date Time API。加强对日期和时间的处理。LocateDateTime\n11、java.util 包下的改进，提供了几个实用的工具类。\n并行数组排序。 标准的Base64编解码。 支持无符号运算。\n12.java.util.concurrent 包下增加了新的类和方法。\njava.util.concurrent.ConcurrentHashMap 类添加了新的方法以支持新的StreamApi和lambada表达式。 java.util.concurrent.atomic 包下新增了类以支持可伸缩可更新的变量。 java.util.concurrent.ForkJoinPool类新增了方法以支持 common pool。 新增了java.util.concurrent.locks.StampedLock类，为控制读/写访问提供了一个基于性能的锁，且有三种模式可供选择。  13.HotSpot\n删除了 永久代（PermGen）. 方法调用的字节码指令支持默认方法。\n使用Metaspace（JEP 122）代替持久代（PermGen space）。在JVM参数方面，使用-XX:MetaSpaceSize和-XX:MaxMetaspaceSize代替原来的-XX:PermSize和-XX:MaxPermSize\nJava 9 新特性 1、模块系统 JPMS\n2、G1 成为默认垃圾回收器\n3、HTTP/2 Client\n4、JShell\n5、集合相关，更便捷的方法\n6、Process API Updates\n7、Stack-Walking API\n8、Variable Handles\n9、Docker方面支持\nJava 10 新特性 1、var 局部变量类型推断。\n2、统一的 GC 接口\n3、 应用程序类数据（AppCDS）共享\nJEP314，使用附加的 Unicode 语言标记扩展。  Java 11 新特性 局部类型推断\n集合、字符串新API\nHTTP API\nEpsilon垃圾收集器 JDK上对这个特性的描述是：开发一个处理内存分配但不实现任何实际内存回收机制的GC，一旦可用堆内存用完，JVM就会退出。\n性能测试(它可以帮助过滤掉GC引起的性能假象) 内存压力测试 非常短的JOB任务 VM接口测试  ZGC 垃圾回收器\nGC暂停时间不会超过10毫秒 既能处理几百兆的小堆，也能处理几个T的大堆 和G1相比，应用吞吐能力不会下降超过15% 为未来的GC功能和利用colord指针以及Load barriers优化奠定了基础  ZGC是一个并发、基于region、压缩型的垃圾收集器，只有root扫描阶段会STW(strop the world，停止所有线程)，因此ZGC的停顿时间不会随着堆的增长和存活对象的增长而变长。 用法：-XX:UnlockExperimentalVMOptions -XX:+UseZGC 虽然功能如此强大，但很遗憾的是，在Windows系统的JDK中并没有提供ZGC\nFlight Recorder\n这是一个记录仪，用于诊断程序运行过程，那么在之前这是一个商业版的特性，是要收费的，从Java11开始，Fight Recorder免费提供使用并开源。它可以导出事件到文件中， 之后可以用Java Mission Control来分析，也可以在应用启动时配置java -XX:StartFlightRecording或者在应用启动之后使用jcmd来录制，\nJava 12 新特性 1、switch表达式\n2 默认CDS归档\n3 Shenandoah GC\nShenandoah是一种垃圾收集（GC）算法，旨在保证低延迟（10 - 500 ms的下限）。 它通过在运行Java工作线程的同时执行GC操作减少GC暂停时间。 使用Shenandoah，暂停时间不依赖于堆的大小。 这意味着无论堆的大小如何，暂停时间都是差不多的。 这是一个实验性功能，不包含在默认（Oracle）的OpenJDK版本中。\n4 JMH 基准测试\n此功能为JDK源代码添加了一套微基准测试（大约100个），简化了现有微基准测试的运行和新基准测试的创建过程。 它基于Java Microbenchmark Harness（JMH）并支持JMH更新。\n此功能使开发人员可以轻松运行当前的微基准测试并为JDK源代码添加新的微基准测试。 可以基于Java Microbenchmark Harness（JMH）轻松测试JDK性能。 它将支持JMH更新，并在套件中包含一组（约100个）基准测试。\n5 JVM 常量 API\nJEP 334引入了一个API，用于建模关键类文件和运行时artifacts，例如常量池。 此API将包括ClassDesc，MethodTypeDesc，MethodHandleDesc和DynamicConstantDesc等类。此 API 对于操作类和方法的工具很有帮助。\n6 G1的可中断 mixed GC\n此功能通过将Mixed GC集拆分为强制部分和可选部分，使G1垃圾收集器更有效地中止垃圾收集过程。通过允许垃圾收集过程优先处理强制集，g1可以更多满足满足暂停时间目标。\nG1是一个垃圾收集器，设计用于具有大量内存的多处理器机器。由于它提高了性能效率，g1垃圾收集器最终将取代cms垃圾收集器。\nG1垃圾收集器的主要目标之一是满足用户设置的暂停时间。G1采用一个分析引擎来选择在收集期间要处理的工作量。此选择过程的结果是一组称为GC集的区域。一旦GC集建立并且GC已经开始，那么G1就无法停止。\n如果G1发现GC集选择选择了错误的区域，它会将GC区域的拆分为两部分（强制部分和可选部分）来切换到处理Mix GC的增量模式。如果未达到暂停时间目标，则停止对可选部分的垃圾收集。\n7 G1归还不使用的内存\n此功能的主要目标是改进G1垃圾收集器，以便在不活动时将Java堆内存归还给操作系统。 为实现此目标，G1将在低应用程序活动期间定期生成或持续循环检查完整的Java堆使用情况。\n这将立即归还未使用的部分Java堆内存给操作系统。 用户可以选择执行FULL GC以最大化返回的内存量。\n8 移除多余ARM64实现\nJava 12将只有一个ARM 64位实现（aarch64）。 目标是删除所有与arm64实现相关的代码，同时保留32位ARM端口和64位aarch64实现。\n这将把重点转移到单个64位ARM实现，并消除维护两个实现所需的重复工作。 当前的JDK 11实现中有两个64位ARM实现。\n","date":"2019-11-06","permalink":"/zh-cn/posts/java/basic/java_vesrion/","series":null,"tags":["Java"],"title":"Java各个版本的特性"},{"categories":["技术博客"],"content":"ForkJoin 特性 使用 提供两个抽象类继承ForkJoinTask ，分别是RecursiveAction和RecursiveTask.他们的区别在于：RecursiveTask有返回值，RecursiveAction无返回值。 ForkJoinPool pool = new ForkJoinPool();\nForkJoinPool的submit、invoke和execute的区别\nexecute 异步执行tasks，没有返回结果 submit会把任务对象本身返回，返回后我们可以通过get()获取方法执行结果，带Task返回值，可通过task.get 实现同步到主线程\n","date":"2019-02-18","permalink":"/zh-cn/posts/java/juc/forkjoin/","series":null,"tags":["并发编程","Java"],"title":"Java并发编程 juc包——ForkJoin"},{"categories":["技术博客"],"content":"线程池 JUC Executors 通过JUC的ThreadPoolExecutor类创建各种类型线程池，包括了\nExecutors.newCachedThreadPool(); 可缓存的线程池，可以进行缓存的线程池，意味着它的线程数是最大的，无限的。但是核心线程数为 0，这没关系。这里要考虑线程的摧毁，因为不能够无限的创建新的线程，所以在一定时间内要摧毁空闲的线程。\n public static ExecutorService newCachedThreadPool() {\rreturn new ThreadPoolExecutor(0, Integer.MAX_VALUE,\r60L, TimeUnit.SECONDS,\rnew SynchronousQueue\u0026lt;Runnable\u0026gt;());\r}\rpublic static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) {\rreturn new ThreadPoolExecutor(0, Integer.MAX_VALUE,\r60L, TimeUnit.SECONDS,\rnew SynchronousQueue\u0026lt;Runnable\u0026gt;(),\rthreadFactory);\r}\rExecutors.newFixedThreadPool(); 传入一个固定的核心线程数，并且核心线程数等于最大线程数，而且它们的线程数存活时间都是无限的\n public static ExecutorService newFixedThreadPool(int nThreads) {\rreturn new ThreadPoolExecutor(nThreads, nThreads,\r0L, TimeUnit.MILLISECONDS,\rnew LinkedBlockingQueue\u0026lt;Runnable\u0026gt;());\r}\r public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) {\rreturn new ThreadPoolExecutor(nThreads, nThreads,\r0L, TimeUnit.MILLISECONDS,\rnew LinkedBlockingQueue\u0026lt;Runnable\u0026gt;(),\rthreadFactory);\r}\rExecutors.newScheduledThreadPool(); 有计划性的线程池，就是在给定的延迟之后运行，或周期性地执行。\n public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) {\rreturn new ScheduledThreadPoolExecutor(corePoolSize);\r}\rpublic static ScheduledExecutorService newScheduledThreadPool(\rint corePoolSize, ThreadFactory threadFactory) {\rreturn new ScheduledThreadPoolExecutor(corePoolSize, threadFactory);\r}\rExecutors.newSingleThreadExecutor(); 单核心线程池，最大线程也只有一个，这里的时间为 0 意味着无限的生命，就不会被摧毁了。\n public static ExecutorService newSingleThreadExecutor() {\rreturn new FinalizableDelegatedExecutorService\r(new ThreadPoolExecutor(1, 1,\r0L, TimeUnit.MILLISECONDS,\rnew LinkedBlockingQueue\u0026lt;Runnable\u0026gt;()));\r}\rpublic static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) {\rreturn new FinalizableDelegatedExecutorService\r(new ThreadPoolExecutor(1, 1,\r0L, TimeUnit.MILLISECONDS,\rnew LinkedBlockingQueue\u0026lt;Runnable\u0026gt;(),\rthreadFactory));\r}\rExecutors.newWorkStealingPool(); (JDK 1.8 新增 用的是 ForkJoinPool 类) 是一个并行的线程池，参数中传入的是一个线程并发的数量 这个线程池不会保证任务的顺序执行，也就是 WorkStealing 的意思，抢占式的工作。\n对应的源码实现\n public static ExecutorService newWorkStealingPool(int parallelism) {\rreturn new ForkJoinPool\r(parallelism,\rForkJoinPool.defaultForkJoinWorkerThreadFactory,\rnull, true);\r}\r public static ExecutorService newWorkStealingPool() {\rreturn new ForkJoinPool\r(Runtime.getRuntime().availableProcessors(),\rForkJoinPool.defaultForkJoinWorkerThreadFactory,\rnull, true);\r}\r自定义线程池 通过ThreadPoolExecutor类创建自定义线程池\n public ThreadPoolExecutor(int corePoolSize,\rint maximumPoolSize,\rlong keepAliveTime,\rTimeUnit unit,\rBlockingQueue\u0026lt;Runnable\u0026gt; workQueue) {\rthis(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,\rExecutors.defaultThreadFactory(), defaultHandler);\r}\r添加ThreadFactory参数 public ThreadPoolExecutor(int corePoolSize,\rint maximumPoolSize,\rlong keepAliveTime,\rTimeUnit unit,\rBlockingQueue\u0026lt;Runnable\u0026gt; workQueue,\rThreadFactory threadFactory) {\rthis(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,\rthreadFactory, defaultHandler);\r}\r添加拒绝策略\rpublic ThreadPoolExecutor(int corePoolSize,\rint maximumPoolSize,\rlong keepAliveTime,\rTimeUnit unit,\rBlockingQueue\u0026lt;Runnable\u0026gt; workQueue,\rRejectedExecutionHandler handler) {\rthis(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,\rExecutors.defaultThreadFactory(), handler);\r}\rpublic ThreadPoolExecutor(int corePoolSize,\rint maximumPoolSize,\rlong keepAliveTime,\rTimeUnit unit,\rBlockingQueue\u0026lt;Runnable\u0026gt; workQueue,\rThreadFactory threadFactory,\rRejectedExecutionHandler handler) {\rif (corePoolSize \u0026lt; 0 ||\rmaximumPoolSize \u0026lt;= 0 ||\rmaximumPoolSize \u0026lt; corePoolSize ||\rkeepAliveTime \u0026lt; 0)\rthrow new IllegalArgumentException();\rif (workQueue == null || threadFactory == null || handler == null)\rthrow new NullPointerException();\rthis.acc = System.getSecurityManager() == null ?\rnull :\rAccessController.getContext();\rthis.corePoolSize = corePoolSize;\rthis.maximumPoolSize = maximumPoolSize;\rthis.workQueue = workQueue;\rthis.keepAliveTime = unit.toNanos(keepAliveTime);\rthis.threadFactory = threadFactory;\rthis.handler = handler;\r}\r通过Spring提供的ThreadPoolTaskExecutor创建线程池\n线程池处理线程的流程 查看核心线程是否空闲，有空闲，使用核心线程，没空闲，执行下一步； 查看线程任务队列，未满，将任务存储在任务队列，已满，执行下一步； 查看是否已满，即是否达到最大线程数，未达到，则创建线程，达到，则执行既定拒绝策略\n线程池参数 corePoolSize、maximumPoolSize、workQueue\nkeepAliveTime，unit 、threadFactory、rejecthandler （线程策略）\n","date":"2019-02-17","permalink":"/zh-cn/posts/java/juc/threadpool/","series":null,"tags":["并发编程","Java"],"title":"Java并发编程 juc包——线程池"},{"categories":["技术博客"],"content":"容器的线程安全\n同步容器 同步容器可实现线程安全 ArrayList Vector（使用synchronized实现线程安全） , Stack （使用synchronized实现线程安全） HashMap HashTable （使用synchronized修饰，线程安全，key,value不能为空） Collections.synchronizedXXX（如Set，Map）来实现线程安全\n并发容器J.U.C AQS ——AbstractQueuedSynchronizedr，提供基于FIFO的队列，双向链表实现队列 Java.util.concurrent包的 ArrayList CopyOnWriteArrayList 线程安全，1、消耗内存2、不能用于实时读场景，更适合读多写少的场景，读写分离，最终一致性， HashSet TreeSet CopyOnWriteArraySet ConcurrentSkipListSet\nHashMap,TreeMap ConcurrentHashMap（速度快，支持更快并发）, ConcurrentSkipListMap（key排序）\n安全共享对象的策略 1、线程安全对象 2、被守护对象 3、线程限制 4、共享只读\nAQS并发容器的同步器，AbstractQueuedSynchronizer 使用Node实现FIFO队列 利用int类型表示状态 使用方法是继承 排它锁和共享锁\nHashMap的底层原理 ConcurrentHashMap的底层原理 ","date":"2019-02-10","permalink":"/zh-cn/posts/java/juc/concurrent_container/","series":null,"tags":["并发编程","Java"],"title":"Java并发编程 juc包——并发容器"},{"categories":["技术博客"],"content":"CAS unsafe Atomic包 Atomic的核心操作就是CAS（compareandset,利用CMPXCHG指令实现，它是一个原子指令）,该指令有三个操作数，变量的内存值V（value的缩写），变量的当前预期值E（exception的缩写）， 变量想要更新的值U（update的缩写），当内存值和当前预期值相同时，将变量的更新值覆盖内存值\nAtomic系列的类中的核心方法都会调用unsafe类中的几个本地方法。我们需要先知道一个东西就是Unsafe类，全名为：sun.misc.Unsafe，这个类包含了大量的对C代码的操作， 包括很多直接内存分配以及原子操作的调用，而它之所以标记为非安全的，是告诉你这个里面大量的方法调用都会存在安全隐患，需要小心使用，否则会导致严重的后果，例如在通过unsafe分配内存的时候， 如果自己指定某些区域可能会导致一些类似C++一样的指针越界到其他进程的问题。\nAtomic包中的类按照操作的数据类型可以分成4组\nAtomicBoolean，AtomicInteger，AtomicLong 线程安全的基本类型的原子性操作\nAtomicIntegerArray，AtomicLongArray，AtomicReferenceArray 线程安全的数组类型的原子性操作，它操作的不是整个数组，而是数组中的单个元素\nAtomicLongFieldUpdater，AtomicIntegerFieldUpdater，AtomicReferenceFieldUpdater 基于反射原理对象中的基本类型（长整型、整型和引用类型）进行线程安全的操作\nAtomicReference，AtomicMarkableReference，AtomicStampedReference ABA问题的解决方法 使用AtomicMarkableReference，AtomicStampedReference。使用上述两个Atomic类进行操作。他们在实现compareAndSet指令的时候除了要比较当对象的前值和预期值以外， 还要比较当前（操作的）戳值和预期（操作的）戳值，当全部相同时，compareAndSet方法才能成功。每次更新成功，戳值都会发生变化，戳值的设置是由编程人员自己控制的。\nAtomic包的相关类 AtomicBoolean\nAtomiclnteger\nAtomiclntegerArray\nAtomiclntegerFieldUpdater 原子更新整型的字段的更新器。 AtomicLong\nAtomicLongArray\nAtomicLongFieldUpdater\nAtomicMarkableReference 原子更新带有标记位的引用类型。可以原子的更新一个布尔类型的标记位和引用类型。构造方法是AtomicMarkableReference(V initialRef, boolean initialMark)\nAtomicReference 原子更新引用类型。\nAtomicReferenceArray 原子更新引用类型数组里的元素。 AtomicReferenceFieldUpdater 原子更新引用类型里的字段\nAtomicStampedReference 原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于原子的更数据和数据的版本号，可以解决使用CAS进行原子更新时，可能出现的ABA问题。\nDoubleAccumulator （jdk1.8新增）\nDoubleAdder （jdk1.8新增）\nLongAccumulator （jdk1.8新增）\nLongAdder （jdk1.8新增）\nStriped64\n除了atomic包提供的， Java的基本类型里还有char，float和double等 如何实现Atomic包的原子性 Atomic包里的类基本都是使用Unsafe实现的，让我们一起看下Unsafe的源码，发现Unsafe只提供了三种CAS方法，compareAndSwapObject，compareAndSwapInt和compareAndSwapLong， 再看AtomicBoolean源码，发现其是先把Boolean转换成整型，再使用compareAndSwapInt进行CAS， 所以原子更新double也可以用类似的思路来实现。\n","date":"2019-02-08","permalink":"/zh-cn/posts/java/juc/atomic/","series":null,"tags":["并发编程","Java"],"title":"Java并发编程 juc包——Atomic包"},{"categories":["技术博客"],"content":"AQS AbstractQueuedSynchronizer,抽象的队列式同步器。是除了java自带的synchronized关键字之外的锁机制\n使用Node实现FIFO队列 利用int类型表示状态 使用方法是继承 排它锁和共享锁\n核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并将共享资源设置为锁定状态，如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制， 这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。 CLH（Craig，Landin，and Hagersten）队列是一个虚拟的双向队列，虚拟的双向队列即不存在队列实例，仅存在节点之间的关联关系。 AQS是将每一条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node），来实现锁的分配。\n用大白话来说，AQS就是基于CLH队列，用volatile修饰共享变量state，线程通过CAS去改变状态符，成功则获取锁成功，失败则进入等待队列，等待被唤醒。\n**注意：AQS是自旋锁： **在等待唤醒的时候，经常会使用自旋（while(!cas())）的方式，不停地尝试获取锁，直到被其他线程获取成功\n实现了AQS的锁有：自旋锁、互斥锁、读锁写锁、条件产量、信号量、栅栏都是AQS的衍生物\n另外 AQS 还维护了一个很重要的变量exclusiveOwnerThread，它表示的是获得锁的线程，也叫独占线程。AQS中还有一个用来存储获取锁失败线程的队列，以及head 和 tail 结点\nAQS构建锁和其他同步组件 CountDownLatch （计数器，执行countDown方法后会减一，await()方法保证countDown减为0） CountDownLatch latch=new CountDownLatch(100); latch.countDown(); latch.await();\n同步辅助类，非常实用的多线程控制工具类， CountDownLatch(int count) //实例化一个倒计数器，count指定计数个数 countDown() // 计数减一 await() //等待，当计数减到0时，所有线程并行执行\nSemaphore信号量 控制同时并发访问的个数 final Semaphore semaphore=new Semaphore(3); semaphore.acquire(3); semaphore.release(3);\nsemaphore.tryAcquire(3，……);尝试获取许可，能获取则执行，设置等待时间和获取个数\nCyclicBarrier 设置计数器等待其他符合数量条件线程就绪再继续执行之后的操作，可循环使用\nReentrantLock与锁 可重入锁，JDK实现，对指定代码枷锁 与synchronized锁的区别\npublic class ReentrantLockExample { //请求总数 private static int clientcount=5000; //并发数 public static int threadTotal=200; //计数器 public static int count=0;\nprivate final static Lock lock=new ReentrantLock(); public static void main(String[] args) throws InterruptedException { ExecutorService executorService=Executors.newCachedThreadPool(); final Semaphore semaphore=new Semaphore(threadTotal); final CountDownLatch countDownLatch=new CountDownLatch(clientcount); for (int i=0;i\u0026lt;clientcount;i++){ executorService.execute(()-\u0026gt;{ try { semaphore.acquire(); add(); semaphore.release(); } catch (InterruptedException e) { e.printStackTrace(); } countDownLatch.countDown(); }); } countDownLatch.await(); executorService.shutdown();;\n}\rpublic static void add(){\rlock.lock();;\rtry {\rcount++;\r} finally {\rlock.unlock();\r}\r}\r }\nCondition FutureTask AQS 定义的两种资源方式 1.Exclusive：独占，只有一个线程能执行，如ReentrantLock\n2.Share：共享，多个线程可以同时执行，如Semaphore、CountDownLatch、ReadWriteLock，CyclicBarrier\n自定义同步器 自定义同步器一般的方式是这样（模板方法模式很经典的一个应用）：\n使用者继承AbstractQueuedSynchronizer并重写指定的方法。（这些重写方法很简单，无非是对于共享资源state的获取和释放） 将AQS组合在自定义同步组件的实现中，并调用其模板方法，而这些模板方法会调用使用者重写的方法。 这和我们以往通过实现接口的方式有很大区别，这是模板方法模式很经典的一个运用。 自定义同步器在实现的时候只需要实现共享资源state的获取和释放方式即可，至于具体线程等待队列的维护，AQS已经在顶层实现好了。自定义同步器实现的时候主要实现下面几种方法： isHeldExclusively()：该线程是否正在独占资源。只有用到condition才需要去实现它。 tryAcquire(int)：独占方式。尝试获取资源，成功则返回true，失败则返回false。 tryRelease(int)：独占方式。尝试释放资源，成功则返回true，失败则返回false。 tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。 tryReleaseShared(int)：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false。\nReentrantLock为例，（可重入独占式锁）：state初始化为0，表示未锁定状态，A线程lock()时，会调用tryAcquire()独占锁并将state+1.之后其他线程再想tryAcquire的时候就会失败，直到A线程unlock（）到state=0为止，其他线程才有机会获取该锁。A释放锁之前，自己也是可以重复获取此锁（state累加），这就是可重入的概念。 注意：获取多少次锁就要释放多少次锁，保证state是能回到零态的。\n以CountDownLatch为例，任务分N个子线程去执行，state就初始化 为N，N个线程并行执行，每个线程执行完之后countDown（）一次，state就会CAS减一。当N子线程全部执行完毕，state=0，会unpark()主调用线程，主调用线程就会从await()函数返回，继续之后的动作。\n一般来说，自定义同步器要么是独占方法，要么是共享方式，他们也只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。但AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。 在acquire() acquireShared()两种方式下，线程在等待队列中都是忽略中断的，acquireInterruptibly()/acquireSharedInterruptibly()是支持响应中断的。\n同步类在实现时一般都将自定义同步器（sync）定义为内部类，供自己使用；而同步类自己（Mutex）则实现某个接口，对外服务。\n","date":"2019-02-06","permalink":"/zh-cn/posts/java/juc/aqs/","series":null,"tags":["并发编程","Java"],"title":"Java并发编程 juc包——AQS"},{"categories":["技术博客"],"content":"CAS CAS : compare and swap 或者 compare and exchange 比较交换。 当我们需要对内存中的数据进行修改操作时，为了避免多线程并发修改的情况，我们在对他进行修改操作前，先读取他原来的值E，然后进行计算得出新的的值V，在修改前去比较当前内存中的值N是否和我之前读到的E相同， 如果相同，认为其他线程没有修改过内存中的值，如果不同，说明被其他线程修改了，这时，要继续循环去获取最新的值E，再进行计算和比较，直到我们预期的值和当前内存中的值相等时，再对数据执行修改操作。\nsynchronize synchronize具有原子性、有序性、可见性和可重入性 有序性： synchronized和volatile都具有有序性 有序性： synchronized和volatile都具有可见性 原子性： volatile不具备原子性\nsynchronize 锁的实现 synchronized有两种形式上锁，一个是对方法上锁，一个是构造同步代码块。他们的底层实现其实都一样，在进入同步代码之前先获取锁，获取到锁之后锁的计数器+1， 同步代码执行完锁的计数器-1，如果获取失败就阻塞式等待锁的释放\n在JVM中，对象是分成三部分存在的：对象头、实例数据、对其填充\n对象头是我们需要关注的重点，它是synchronized实现锁的基础，因为synchronized申请锁、上锁、释放锁都与对象头有关。对象头主要结构是由Mark Word 和 Class Metadata Address组成， 其中Mark Word存储对象的hashCode、锁信息或分代年龄或GC标志等信息，Class Metadata Address是类型指针指向对象的类元数据，JVM通过该指针确定该对象是哪个类的实例。\n锁也分不同状态，JDK6之前只有两个状态：无锁、有锁（重量级锁），而在JDK6之后对synchronized进行了优化，新增了两种状态，总共就是四个状态：无锁状态、偏向锁、轻量级锁、重量级锁， 其中无锁就是一种状态了。锁的类型和状态在对象头Mark Word中都有记录，在申请锁、锁升级等过程中JVM都需要读取对象的Mark Word数据。\n每一个锁都对应一个monitor对象，在HotSpot虚拟机中它是由ObjectMonitor实现的（C++实现）。每个对象都存在着一个monitor与之关联，对象与其monitor之间的关系有存在多种实现方式， 如monitor可以与对象一起创建销毁或当线程试图获取对象锁时自动生成，但当一个monitor被某个线程持有后，它便处于锁定状态。\n在jdk6的时候，新增了两个锁状态，通过锁消除、锁粗化、自旋锁等方法使用各种场景，给synchronized性能带来了很大的提升。\n锁状态 无锁状态、偏向锁（单线程多次申请同一锁对象）、轻量级锁（第二个线程申请同一锁对象交替进行而不是同时进行）、重量级锁（同一时间多个线程申请，）\n锁膨胀\n上面讲到锁有四种状态，并且会因实际情况进行膨胀升级，其膨胀方向是：无锁——\u0026gt;偏向锁——\u0026gt;轻量级锁——\u0026gt;重量级锁，并且膨胀方向不可逆。\n偏向锁\n一句话总结它的作用：减少统一线程获取锁的代价。在大多数情况下，锁不存在多线程竞争，总是由同一线程多次获得，那么此时就是偏向锁。\n核心思想：\r如果一个线程获得了锁，那么锁就进入偏向模式，此时Mark Word的结构也就变为偏向锁结构，当该线程再次请求锁时，无需再做任何同步操作，\r即获取锁的过程只需要检查Mark Word的锁标记位为偏向锁以及当前线程ID等于Mark Word的ThreadID即可，这样就省去了大量有关锁申请的操作。\r获取过程\r当一个线程访问同步块时，会先判断锁标志位是否为01，如果是01，则判断是否为偏向锁，如果是，会先判断当前锁对象头中是否存储了当前的线程id，如果存储了，则直接获得锁。\r如果对象头中指向不是当前线程id，则通过CAS尝试将自己的线程id存储进当前锁对象的对象头中来获取偏向锁。当cas尝试获取偏向锁成功后则继续执行同步代码块，否则等待安全点的到来撤销原来线程的偏向锁，\r撤销时需要暂停原持有偏向锁的线程，判断线程是否活动状态，如果已经退出同步代码块则唤醒新的线程开始获取偏向锁，否则开始锁竞争进行锁升级过程，升级为轻量级锁。\r 轻量级锁\n轻量级锁是由偏向锁升级而来，当存在第二个线程申请同一个锁对象时，偏向锁就会立即升级为轻量级锁。注意这里的第二个线程只是申请锁，不存在两个线程同时竞争锁，可以是一前一后地交替执行同步块。\n锁消除 JVM对运行上下文进行扫描，去除不可能存在竞争的锁\n锁粗化 锁粗化是虚拟机对另一种极端情况的优化处理，通过扩大锁的范围，避免反复加锁和释放锁。比如下面method3经过锁粗化优化之后就和method4执行效率一样了\n自旋锁与自适应锁\n轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进行一项称为自旋锁的优化手段。\n自旋锁：许多情况下，共享数据的锁定状态持续时间较短，切换线程不值得，通过让线程执行循环等待锁的释放，不让出CPU。如果得到锁，就顺利进入临界区。如果还不能获得锁，那就会将线程在操作系统层面挂起，这就是自旋锁的优化方式。但是它也存在缺点：如果锁被其他线程长时间占用，一直不释放CPU，会带来许多的性能开销。\n自适应自旋锁：这种相当于是对上面自旋锁优化方式的进一步优化，它的自旋的次数不再固定，其自旋的次数由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定，这就解决了自旋锁带来的缺点。\n旋锁或自适应自旋锁： 因为线程阻塞后进入排队队列和唤醒都需要CPU从用户态转为核心态，尤其频繁的阻塞和唤醒对CPU来说是负荷很重的工作。同时统计发现，很多对象锁的锁定状态只会持续很短的一段时间，例如一个线程切换周期，这样的话在很短的时间内阻塞线程又很快唤醒线程显然不值得，所以引入了自旋锁概念。\n所谓“自旋”，就monitor并不把线程阻塞放入排队队列，而是去执行一个无意义的循环，循环结束后看看是否锁已释放并直接进行竞争上岗步骤，如果竞争不到继续自旋循环，循环过程中线程的状态一直处于running状态。明显自旋锁使得synchronized的对象锁方式在线程之间引入了不公平。但是这样可以保证大吞吐率和执行效率。\n不过虽然自旋锁方式省去了阻塞线程的时间和空间（队列的维护等）开销，但是长时间自旋也是很低效的。所以自旋的次数一般控制在一个范围内，例如10,50等，在超出这个范围后，线程就进入排队队列。\n自适应自旋锁，就是自旋的次数是通过JVM在运行时收集的统计信息，动态调整自旋锁的自旋次数上界。\n只有一个线程进入临界区 \u0026mdash;\u0026mdash;-偏向锁 多个线程交替进入临界区\u0026mdash;\u0026mdash;\u0026ndash;轻量级锁 多个线程同时进入临界区\u0026mdash;\u0026mdash;-重量级锁\nsynchronized锁升级原理: 在锁对象的对象头里面有一个threadid字段，在第一次访问的时候threadid为空，jvm让其持有偏向锁，并将threadid设置为其线程id，再次进入的时候会先判断threadid是否与其线程id一致，如果一致则可以直接使用此对象，如果不一致，则升级偏向锁为轻量级锁，通过自旋循环一定次数来获取锁，执行一定次数之后，如果还没有正常获取到要使用的对象，此时就会把锁从轻量级升级为重量级锁，此过程就构成了synchronized锁的升级。\nsynchronized用的锁是存在java对象头里的。 其中最后两位代表是否加锁的标志位。锁标志位如果是01的话需要根据前一位的是否为偏向锁来判断当前的锁状态，如果前一位为0则代表无锁状态，如果为1则代表有偏向锁。 后两位：00代表轻量级锁，10代表重量级锁，11代表GC垃圾回收的标记信息。\n锁的升级的目的: 锁升级是为了减低了锁带来的性能消耗。在Java 6之后优化synchronized的实现方式，使用了偏向锁升级为轻量级锁再升级到重量级锁的方式，从而减低了锁带来的性能消耗。\nABA 问题 其他线程修改后的值和原来的值相同，（设置一个状态标志就行）\n","date":"2019-02-06","permalink":"/zh-cn/posts/java/synchronized/","series":null,"tags":["并发编程","Java"],"title":"Java并发编程——synchronized关键字"},{"categories":["技术博客"],"content":"JVM的GC有哪些 一、Serial收集器(jdk1.3) Serial收集器是最基本、发展历史最悠久的收集器，曾经（在JDK 1.3.1之前）是虚拟机新生代收集的唯一选择。\n特性： 这个收集器是一个单线程的收集器，但它的“单线程”的意义并不仅仅说明它只会使用一个CPU或一条收集线程去完成垃圾收集工作，更重要的是在它进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束。Stop The World\n应用场景： Serial收集器是虚拟机运行在Client模式下的默认新生代收集器。\n优势： 简单而高效（与其他收集器的单线程比），对于限定单个CPU的环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程收集效率。\n二、ParNew收集器(jdk1.4) 特性： ParNew收集器其实就是Serial收集器的多线程版本，除了使用多条线程进行垃圾收集之外，其余行为包括Serial收集器可用的所有控制参数、收集算法、Stop The World、对象分配规则、回收策略等都与Serial收集器完全一样，在实现上，这两种收集器也共用了相当多的代码。\n应用场景： ParNew收集器是许多运行在Server模式下的虚拟机中首选的新生代收集器。\n很重要的原因是：除了Serial收集器外，目前只有它能与CMS收集器配合工作。 在JDK 1.5时期，HotSpot推出了一款在强交互应用中几乎可认为有划时代意义的垃圾收集器——CMS收集器，这款收集器是HotSpot虚拟机中第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程同时工作。 不幸的是，CMS作为老年代的收集器，却无法与JDK 1.4.0中已经存在的新生代收集器Parallel Scavenge配合工作，所以在JDK 1.5中使用CMS来收集老年代的时候，新生代只能选择ParNew或者Serial收集器中的一个。\nSerial收集器 VS ParNew收集器： ParNew收集器在单CPU的环境中绝对不会有比Serial收集器更好的效果，甚至由于存在线程交互的开销，该收集器在通过超线程技术实现的两个CPU的环境中都不能百分之百地保证可以超越Serial收集器。 然而，随着可以使用的CPU的数量的增加，它对于GC时系统资源的有效利用还是很有好处的。\n三、Parallel Scavenge收集器(jdk1.4) 特性： Parallel Scavenge收集器是一个新生代收集器，它也是使用复制算法的收集器，又是并行的多线程收集器。\n应用场景： 停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验，而高吞吐量则可以高效率地利用CPU时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。\n对比分析：\nParallel Scavenge收集器 VS CMS等收集器： Parallel Scavenge收集器的特点是它的关注点与其他收集器不同，CMS等收集器的关注点是尽可能地缩短垃圾收集时用户线程的停顿时间，而Parallel Scavenge收集器的目标则是达到一个可控制的吞吐量（Throughput）。 由于与吞吐量关系密切，Parallel Scavenge收集器也经常称为“吞吐量优先”收集器。\nParallel Scavenge收集器 VS ParNew收集器： Parallel Scavenge收集器与ParNew收集器的一个重要区别是它具有自适应调节策略。\nGC自适应的调节策略： Parallel Scavenge收集器有一个参数-XX:+UseAdaptiveSizePolicy。当这个参数打开之后，就不需要手工指定新生代的大小、Eden与Survivor区的比例、晋升老年代对象年龄等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量，这种调节方式称为GC自适应的调节策略（GC Ergonomics）。\n四、Serial Old收集器(jdk1.5) 特性： Serial Old是Serial收集器的老年代版本，它同样是一个单线程收集器，使用标记－整理算法。\n应用场景：\nClient模式 Serial Old收集器的主要意义也是在于给Client模式下的虚拟机使用。\nServer模式 如果在Server模式下，那么它主要还有两大用途：一种用途是在JDK 1.5以及之前的版本中与Parallel Scavenge收集器搭配使用，另一种用途就是作为CMS收集器的后备预案，在并发收集发生Concurrent Mode Failure时使用。\n五、Parallel Old收集器(jdk1.6) 特性： Parallel Old是Parallel Scavenge收集器的老年代版本，使用多线程和“标记－整理”算法。\n应用场景： 在注重吞吐量以及CPU资源敏感的场合，都可以优先考虑Parallel Scavenge加Parallel Old收集器。\n这个收集器是在JDK 1.6中才开始提供的，在此之前，新生代的Parallel Scavenge收集器一直处于比较尴尬的状态。原因是，如果新生代选择了Parallel Scavenge收集器，老年代除了Serial Old收集器外别无选择（Parallel Scavenge收集器无法与CMS收集器配合工作）。由于老年代Serial Old收集器在服务端应用性能上的“拖累”，使用了Parallel Scavenge收集器也未必能在整体应用上获得吞吐量最大化的效果，由于单线程的老年代收集中无法充分利用服务器多CPU的处理能力，在老年代很大而且硬件比较高级的环境中，这种组合的吞吐量甚至还不一定有ParNew加CMS的组合“给力”。直到Parallel Old收集器出现后，“吞吐量优先”收集器终于有了比较名副其实的应用组合。\n六、CMS收集器（jdk1.5） 特性： CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。目前很大一部分的Java应用集中在互联网站或者B/S系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。CMS收集器就非常符合这类应用的需求。\nCMS收集器是基于“标记—清除”算法实现的，它的运作过程相对于前面几种收集器来说更复杂一些，整个过程分为4个步骤：\n初始标记（CMS initial mark） 初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，需要“Stop The World”。\n并发标记（CMS concurrent mark） 并发标记阶段就是进行GC Roots Tracing的过程。\n重新标记（CMS remark） 重新标记阶段是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段稍长一些，但远比并发标记的时间短，仍然需要“Stop The World”。\n并发清除（CMS concurrent sweep） 并发清除阶段会清除对象。\n由于整个过程中耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起工作，所以，从总体上来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。\n优点： CMS是一款优秀的收集器，它的主要优点在名字上已经体现出来了：并发收集、低停顿。\n缺点：\nCMS收集器对CPU资源非常敏感 其实，面向并发设计的程序都对CPU资源比较敏感。在并发阶段，它虽然不会导致用户线程停顿，但是会因为占用了一部分线程（或者说CPU资源）而导致应用程序变慢，总吞吐量会降低。 CMS默认启动的回收线程数是（CPU数量+3）/ 4，也就是当CPU在4个以上时，并发回收时垃圾收集线程不少于25%的CPU资源，并且随着CPU数量的增加而下降。但是当CPU不足4个（譬如2个）时，CMS对用户程序的影响就可能变得很大。\nCMS收集器无法处理浮动垃圾 CMS收集器无法处理浮动垃圾，可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生。\n由于CMS并发清理阶段用户线程还在运行着，伴随程序运行自然就还会有新的垃圾不断产生，这一部分垃圾出现在标记过程之后，CMS无法在当次收集中处理掉它们，只好留待下一次GC时再清理掉。这一部分垃圾就称为“浮动垃圾”。 也是由于在垃圾收集阶段用户线程还需要运行，那也就还需要预留有足够的内存空间给用户线程使用，因此CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，需要预留一部分空间提供并发收集时的程序运作使用。要是CMS运行期间预留的内存无法满足程序需要，就会出现一次“Concurrent Mode Failure”失败，这时虚拟机将启动后备预案：临时启用Serial Old收集器来重新进行老年代的垃圾收集，这样停顿时间就很长了。\nCMS收集器会产生大量空间碎片 CMS是一款基于“标记—清除”算法实现的收集器，这意味着收集结束时会有大量空间碎片产生。\n空间碎片过多时，将会给大对象分配带来很大麻烦，往往会出现老年代还有很大空间剩余，但是无法找到足够大的连续空间来分配当前对象，不得不提前触发一次Full GC。\n七、G1收集器 （JDK 7u4推出，JDK 9 设置为默认收集器） 特性： G1（Garbage-First）是一款面向服务端应用的垃圾收集器。HotSpot开发团队赋予它的使命是未来可以替换掉JDK 1.5中发布的CMS收集器。与其他GC收集器相比，G1具备如下特点。\n并行与并发 G1能充分利用多CPU、多核环境下的硬件优势，使用多个CPU来缩短Stop-The-World停顿的时间，部分其他收集器原本需要停顿Java线程执行的GC动作，G1收集器仍然可以通过并发的方式让Java程序继续执行。\n分代收集 与其他收集器一样，分代概念在G1中依然得以保留。虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但它能够采用不同的方式去处理新创建的对象和已经存活了一段时间、熬过多次GC的旧对象以获取更好的收集效果。\n空间整合 与CMS的“标记—清理”算法不同，G1从整体来看是基于“标记—整理”算法实现的收集器，从局部（两个Region之间）上来看是基于“复制”算法实现的，但无论如何，这两种算法都意味着G1运作期间不会产生内存空间碎片，收集后能提供规整的可用内存。这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。\n可预测的停顿 这是G1相对于CMS的另一大优势，降低停顿时间是G1和CMS共同的关注点，但G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒。\n在G1之前的其他收集器进行收集的范围都是整个新生代或者老年代，而G1不再是这样。使用G1收集器时，Java堆的内存布局就与其他收集器有很大差别，它将整个Java堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分Region（不需要连续）的集合。\nG1收集器之所以能建立可预测的停顿时间模型，是因为它可以有计划地避免在整个Java堆中进行全区域的垃圾收集。G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region（这也就是Garbage-First名称的来由）。这种使用Region划分内存空间以及有优先级的区域回收方式，保证了G1收集器在有限的时间内可以获取尽可能高的收集效率。\n执行过程： G1收集器的运作大致可划分为以下几个步骤：\n初始标记（Initial Marking） 初始标记阶段仅仅只是标记一下GC Roots能直接关联到的对象，并且修改TAMS（Next Top at Mark Start）的值，让下一阶段用户程序并发运行时，能在正确可用的Region中创建新对象，这阶段需要停顿线程，但耗时很短。\n并发标记（Concurrent Marking） 并发标记阶段是从GC Root开始对堆中对象进行可达性分析，找出存活的对象，这阶段耗时较长，但可与用户程序并发执行。\n最终标记（Final Marking） 最终标记阶段是为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程Remembered Set Logs里面，最终标记阶段需要把Remembered Set Logs的数据合并到Remembered Set中，这阶段需要停顿线程，但是可并行执行。\n筛选回收（Live Data Counting and Evacuation） 筛选回收阶段首先对各个Region的回收价值和成本进行排序，根据用户所期望的GC停顿时间来制定回收计划，这个阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分Region，时间是用户可控制的，而且停顿用户线程将大幅提高收集效率。\n八、ZGC 收集器 （Java 11 ） 可伸缩、低延迟的垃圾回收器 GC 暂停时间不超过 10ms\n堆管理容量范围（小M级别，大到T级别）\n对应用吞吐量影响不超过15%（对比 G1）\n为进一步的添加新特性和优化做基础\n默认支持 Linux/x64 系统\nGC中使用的算法 如何选择GC ","date":"2019-01-06","permalink":"/zh-cn/posts/java/juc/java_memory_gc/","series":null,"tags":["JVM","GC","Java"],"title":"深入理解Java虚拟机——JVM的GC详解"},{"categories":["技术博客"],"content":"Java内存模型 java堆 线程共享 存放对象的实例\njava堆是JVM内存管理最大的一块区域 所有对象实例与数组都要在堆上分配内存。它也是垃圾收集器的主要管理区域。java对可以处于物理上不连续的空间，只要逻辑上是连续的即可。 如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将抛出OutOfMemoryError异常。 为了支持垃圾收集（GC），堆内存通常被分为三块区域:新生代内存(young generation)、老年代内存(old generation,jdk8移除)、永久内存(Permanent Generation for VM Matedata),一个对象被创建以后首先被放到Nursery中的Eden内存中，假设存活期超两个Survivor之后就会被转移到长时内存中(Old Generation)中;永久内存中存放着对象的方法、变量等元数据信息。\n虚拟机栈 线程私有 栈中存放一个个栈帧，每个栈帧对应一个方法。一个栈帧包括（局部变量表，操作数栈，指向当前方法所属的类的运行时常量池，方法返回地址和一些额外的附加按信息。）\n局部变量表，就是用来存储方法中的局部变量（包括在方法中声明的非静态变量以及函数形参）对于基本数据类型的变量，则直接存储它的值，对于引用类型的变量，则存的是指向对象的引用。局部变量表的大小在编译器就可以确定其大小了，因此在程序执行期间局部变量表的大小是不会改变的。 操作数栈，程序中的所有计算过程都是在借助于操作数栈来完成的。 指向运行时常量池的引用，因为在方法执行的过程中有可能需要用到类中的常量，所以必须要有一个引用指向运行时常量。 方法返回地址，当一个方法执行完毕之后，要返回之前调用它的地方，因此在栈帧中必须保存一个方法返回地址 注意，当线程执行一个方法时，就会随之创建一个对应的栈帧，并将建立的栈帧压栈。当方法执行完毕之后，便会将栈帧出栈。因此可知，线程当前执行的方法所对应的栈帧必定位于Java栈的顶部。在这个区域规定了两种异常状况： 如果线程请求的栈深入大于虚拟机所允许的深度，将抛出StackOverFlowError异常！ 如果虚拟机栈可以动态扩展，当扩展到无法申请内存到足够的内存，就会抛出OutOfMemoryError异常!\n本地方法栈 线程私有 和虚拟站的区别是虚拟机栈为虚拟机执行Java方法（字节码）服务，而本地方法栈则为虚拟机使用到的Native方法服务。\n程序计数器 线程私有 记录当前线程的程序执行指令的计数器，通过改变这个计数器的值来选取下一条需要执行的字节码指令，各个线程间计数器互相独立\n方法区 线程共享 方法区在JVM中也是一个非常重要的区域，它与堆一样，是被线程共享的区域。在方法区中，存储了每个类的信息（包括类的名称、方法信息、字段信息）、静态变量、常量以及编译器编译后的代码等。方法区是堆的一个逻辑部分，为了区分Java堆，它还有一个别名Non-Heap（非堆）。相对而言，GC对于这个区域的收集是很少出现的。当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。\n新生代内存、老年代内存和永久代内存 为了支持垃圾收集（GC），堆内存通常被分为三块区域:新生代内存(young generation)、老年代内存(old generation,jdk8移除)、永久内存(Permanent Generation for VM Matedata), 一个对象被创建以后首先被放到Nursery中的Eden内存中，假设存活期超两个Survivor之后就会被转移到长时内存中(Old Generation)中;永久内存中存放着对象的方法、变量等元数据信息。\n常见的内存溢出 JDK7和JDK8的JVM内存模型的区别：\n1、方法区变化。元数据区取代了永久代，就是JDK8没有了PermSize相关的参数配置了。元空间的本质和永久代类似，都是对JVM规范中方法区的实现。不过元空间与永久代之间最大的区别在于：元数据空间并不在虚拟机中，而是使用本地内存。\n2、运行时常量池变化。在近三个JDK版本（1.6、1.7、1.8）中， 运行时常量池（Runtime Constant Pool）的所处区域一直在不断的变化，在JDK1.6时它是方法区的一部分；1.7又把他放到了堆内存中；1.8之后出现了元空间，它又回到了方法区。\n内存泄露（Memory Leak）：程序在申请内存后，对象没有被GC所回收，它始终占用内存，内存泄漏的堆积最终会造成内存溢出。\n内存溢出（Memory Overflow）：程序运行过程中无法申请到足够的内存而导致的一种错误。内存溢出通常发生于OLD段或Perm段垃圾回收后，仍然无内存空间容纳新的Java对象的情况。通常都是由于内存泄露导致堆栈内存不断增大，从而引发内存溢出。\njmap -histo:live后相当于手动调用了一次GC\n这会导致由JVM根据运行情况去自动分配了内存，在物理内存足够的情况下，JVM出于对应用程序性能的考虑并没有调用FGC\n那些参数都是啥意思？ -Xmx指定堆内存最大值，这个是最常用的参数，实在懒得理解，光设置这个也凑合了。\n-XX:MaxMetaspaceSize指定非堆内存的元空间最大值，这个参数是java8之后才有的，不过现在应该没几个人用更早的版本了吧……对于学习、测试用的小应用，非堆内存基本都占用很小，但是如果不指定，最大值默认1024m，就算Xmx限制了也还会吃很多内存……\n-XX:CompressedClassSpaceSize这个是Metaspace的一部分，程序的代码被存储在这里，启动后几乎不会增长，可以根据自己的情况指定一个比较小的值，给Metaspace其他部分留够空间。\n其他jvm参数，\n如何知道自己java应用的内存占用来决定最佳分配？ jdk路径/bin/jstat -gccapacity pid 根据pid查看某个应用的当前内存和最大内存。可以知道内存占用量的情况，也可以看出来前面的jvm参数配置有没有生效。\njstat还有很多参数，查出来的数值具体是什么意思也请自行搜索深入学习。\n如果是在windows上运行，还可以用jdk路径/bin/jconsole.exe查看可视化的内存使用情况。\njps [options] [hostid] 如果不指定hostid就默认为当前主机或服务器。\n命令行参数选项说明如下：  -q 不输出类名、Jar名和传入main方法的参数 -m 输出传入main方法的参数 -l 输出main类或Jar的全限名 -v 输出传入JVM的参数\n","date":"2019-01-06","permalink":"/zh-cn/posts/java/juc/java_memory_model/","series":null,"tags":["JVM","GC","Java"],"title":"深入理解Java虚拟机——Java内存模型"}]