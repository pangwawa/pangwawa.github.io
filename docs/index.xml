<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>小吴的工作手记</title>
    <link>https://pangwawa.github.io/</link>
    <description>Recent content on 小吴的工作手记</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-Hans</language>
    <lastBuildDate>Mon, 02 Nov 2020 11:23:22 +0800</lastBuildDate><atom:link href="https://pangwawa.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Mybatis源码分析—Mybatis架构与SQL处理过程</title>
      <link>https://pangwawa.github.io/posts/mybatis/mybastis_structure/</link>
      <pubDate>Mon, 02 Nov 2020 11:23:22 +0800</pubDate>
      
      <guid>https://pangwawa.github.io/posts/mybatis/mybastis_structure/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Clickhouse基础概念与架构原理</title>
      <link>https://pangwawa.github.io/posts/clickhouse/clickhouse_structure/</link>
      <pubDate>Mon, 02 Nov 2020 11:22:51 +0800</pubDate>
      
      <guid>https://pangwawa.github.io/posts/clickhouse/clickhouse_structure/</guid>
      <description>什么是ClickHouse ClickHouse是面向联机分析处理的列式数据库，支持SQL查询，且查询性能好，特别是基于大宽表的聚合分析查询性能非常优异，比其他分析型数据库速度快一个数量级。 ClickHouse不单单是一个数据库， 它是一个数据库管理系统。因为它允许在运行时创建表和数据库、加载数据和运行查询，而无需重新配置或重启服务。 主要特性包括： 数据压缩比高。 多核并行计算。 向量化计算引擎。 支持嵌套数据结构。 支持稀疏索引。
支持数据Insert和Update。
clickhouse为什么如此快 1）优秀的代码，对性能的极致追求
clickhouse是CPP编写的，代码中大量使用了CPP最新的特性来对查询进行加速。
2）优秀的执行引擎以及存储引擎
clickhouse是基于列式存储的，使用了向量化的执行引擎，利用SIMD指令进行处理加速，同时使用LLVM加快函数编译执行，当然了Presto也大量的使用了这样的特性。
3）稀疏索引
相比于传统基于HDFS的OLAP引擎，clickhouse不仅有基于分区的过滤，还有基于列级别的稀疏索引，这样在进行条件查询的时候可以过滤到很多不需要扫描的块，这样对提升查询速度是很有帮助的。
4）存储执行耦合
存储和执行分离是一个趋势，但是存储和执行耦合也是有优势的，避免了网络的开销，CPU的极致压榨加上SSD的加持，每秒的数据传输对于网络带宽的压力是非常大的，耦合部署可以避免该问题。
5）数据存储在SSD，极高的iops。
Clickhouse高性能存储和查询的实现原理 1、多核CPU并行计算，看到刚才的文件存储方式，文件是按照压缩块的方式存在.bin文件中。ClickHouse可以通过大量CPU，并行读取不同的压缩块并行解压计算。
2、SIMD指令集加速，充分利用了CPU寄存器的并行计算能力。如果是传统的CPU指令集，寄存器就算有128位，如果要进行N次8bit的计算，每次都只能利用寄存器的低8位重复计算N次；而SIMD的话，可以将16个8bit的运算并行放到128位的寄存器中，仅通过1次计算就可以并行计算16个8bit的运算。ClickHouse是通过SSE2指令集实现的，所以最好选用Intel的机器。
3、之前介绍的，ClickHouse分布式水平扩展集群的能力，也可以很好的提升性能。
4、还有稀疏索引，列式存储和极致的数据压缩，也都是大数据场景下高性能查询的关键点。
5、实际上，ClickHouse还有很多优化性能的细节。比如聚合分析，通常的实现是通过HashMap实现，HashMap的key是group by的key，HashMap的value是聚合的值。ClickHouse通过对长字符串的Key，进行Hash实现的HashMapWithSavedHash，以及对Uint8这类范围小的数据字段通过数组实现的FixedHashMap，以及大量新增类别字段和内存限制的场景，也有TwoLevelHashMap和Split to disk的实现方案。
实际上，ClickHouse的内核实现中，并没有使用什么神秘的算法，但是正是这所有的优化组合在一起，才有了ClickHouse彪悍的查询性能。
海量数据直接写入ClickHouse会失败 ClickHouse的MergeTree表引擎，底层原理是类似于LSM-tree。数据通过Append的方式写入，后续再启动merge线程将小的数据文件进行合并。
一次数据写入，会生成一个文件目录。目录结构可以看到，分为四个部分：
第一部分，是分区ID的信息；
第二部分，是这个目录中包含数据的最小BlockNum；
第三部分，是这个目录中包含数据的最大BlockNum；
第四部分，是这个目录进行合并的等级。
举个例子，图中两个黄色的数据目录合并成蓝色的数据目录，数据BlockNum从1_1和2_2合并成了1_2，数据合并level也从0变成了1。
了解了ClickHouse MergeTree家族表的写入过程，这里我们就会发现两个问题。
第一：如果一次写入的数据量太小，比如一条写一次，那么会产生大量的文件目录。当后台合并线程来不及合并的时候，文件目录数量会越来越多，这会导致ClickHouse抛出Too many parts的异常，写入失败。 第二：根据之前的介绍，每一次写入除了写入数据本身，ClickHouse还需要跟Zookeeper进行十来次的数据交互，而我们知道Zookeeper是不能承受高并发的访问。可以看到，写入QPS过高导致进一步Zookeeper的QPS过高，从而导致Zookeeper崩溃。 我们采用的解决方案是，改用Batch的方式写入。即一个Batch的数据，产生一个数据目录，与Zookeeper进行一系列交互。那Batch设置多大呢，Batch太小的话缓解不了ZK的压力，Batch也不能太大，不然上游内存的压力和数据延迟会太大。通过实验，最终我们选用了大小几十万的Batch。
这样避免了QPS太高带来的问题。当前方案其实还有优化空间的，比如Zookeeper是无法线性扩展的。我了解到，业内有些团队就把log和data part相关信息不写入Zookeeper，这样减少了Zookeeper的压力。不过这样涉及到了对源代码的修改，对于一般的业务团队实现的成本太高了。
数据写入，遇到的第二个问题是，如果数据写入通过分布式表写入会遇到单点问题。
先介绍一下分布式表。分布式表实际上是一张逻辑表并不存储真实数据，可以理解为一张代理表。
比如用户查询分布式表，分布式表会将查询请求下发到每一个分片的本地表上进行查询，然后收集每个分片本地表的结果，汇总之后再返回给用户。
用户写入分布式表的场景，是用户将一个Batch的数据写入分布式表，分布式表根据一定的规则，将这个Batch的数据分为若干个Mini Batch的数据，存储到不同的分片上。
这里有一个很容易误解的地方，我们开始以为，分布式表是按照一定规则做一个网络转发，那么我们当时想只要万兆网卡的带宽足够，就不会出现单点的性能瓶颈。
尤其是Clickhouse底层运用的是Mergetree，在合并的过程中，会存在写放大的问题加重磁盘的压力。峰值每分钟几千万条数据写完耗时几十秒，如果正在做Merge就会阻塞写入请求，查询也会非常慢。
我们做的两个优化方案：
第一，对磁盘做Raid提升磁盘的IO。
第二，在写入之前，上游进行数据划分分表操作，直接分开写入到不同的分片上，磁盘压力直接变为了原来的1/N。
这样很好的避免了磁盘的单点瓶颈。</description>
    </item>
    
    <item>
      <title>Kubernetes资源对象详解</title>
      <link>https://pangwawa.github.io/posts/kubernetes/kubernetes_resource_object/</link>
      <pubDate>Mon, 26 Oct 2020 10:54:43 +0800</pubDate>
      
      <guid>https://pangwawa.github.io/posts/kubernetes/kubernetes_resource_object/</guid>
      <description>Kubernetes 资源对象 Pod Pod 是最小的可部署的 Kubernetes 对象模型。Pod 表示集群上正在运行的进程。一个 Pod 由一个或多个容器组成，Pod 中容器共享存储和网络，在同一台 Docker 主机上运行。在 kubernetes 中，若要运行一个容器，则必须先创建 pod，让容器在 pod 中运行，可以把 Pod 看成是容器的运行环境。 Docker 是 Kubernetes Pod 中最常用的容器运行时，但 Pod 也能支持其他的容器运行时，如 rtk。 Kubernetes 集群中的 Pod 可被用于以下两个主要用途：
运行单个容器的 Pod。”每个 Pod 一个容器”模型是最常见的 Kubernetes 用例；在这种情况下，可以将 Pod 看作单个容器的包装器，并且 Kubernetes 直接管理 Pod，而不是容器。
运行多个协同工作的容器的 Pod。 Pod 可能封装由多个紧密耦合且需要共享资源的共处容器组成的应用程序。 这些位于同一位置的容器可能形成单个内聚的服务单元——一个容器将文件从共享卷提供给公众，而另一个单独的“挂斗”容器则刷新或更新这些文件。 Pod 将这些容器和存储资源打包为一个可管理的实体。
ReplicationController  ReplicationController 简写 “RC” 或 “RCS”。译作“副本控制器”，“Replication” 就是“复制”、“副本”的意思。ReplicationController 确保在任何时候都有特定数量的 pod 副本处于运行状态。 换句话说，ReplicationController 确保一个 pod 或一组同类的 pod 总是可用的。 当 pods 数量过多时，ReplicationController 会终止多余的 pods。当 pods 数量太少时，ReplicationController 将会启动新的 pods。 与手动创建的 pod 不同，由 ReplicationController 创建的 pods 在失败、被删除或被终止时会被自动替换。</description>
    </item>
    
    <item>
      <title>Flink编程模型详解</title>
      <link>https://pangwawa.github.io/posts/flink/flink_programing_model/</link>
      <pubDate>Thu, 22 Oct 2020 18:19:12 +0800</pubDate>
      
      <guid>https://pangwawa.github.io/posts/flink/flink_programing_model/</guid>
      <description>Flink 为流式/批式处理应用程序的开发提供了Stateful Stream Processing、DataStream/DataSet ApI 、Table API和SQL这四个不同级别的抽象，如下如所示：
1、SQL 这层抽象在语义和程序表达式上都类似于 Table API，但是其程序实现都是 SQL 查询表达式。SQL 抽象与 Table API 抽象之间的关联是非常紧密的，并且 SQL 查询语句可以在 Table API 中定义的表上执行。
2、Table API 以表（Table）为中心的声明式编程（DSL）API，例如在流式数据场景下，它可以表示一张正在动态改变的表。Table API 遵循（扩展）关系模型：即表拥有 schema（类似于关系型数据库中的 schema），并且 Table API 也提供了类似于关系模型中的操作，比如 select、project、join、group-by 和 aggregate 等
3、Datastream、DataSet API 核心 API，包含 DataStream API（应用于有界/无界数据流场景）和 DataSet API（应用于有界数据集场景）两部分。Core APIs 提供的流式 API（Fluent API）为数据处理提供了通用的模块组件，例如各种形式的用户自定义转换（transformations）、联接（joins）、聚合（aggregations）、窗口（windows）和状态（state）操作等。此层 API 中处理的数据类型在每种编程语言中都有其对应的类。
4、Stateful Stream Processing（有状态实时流处理） 允许用户在应用程序中自由地处理来自单流或多流的事件（数据），并提供具有全局一致性和容错保障的状态。此外，用户可以在此层抽象中注册事件时间（event time）和处理时间（processing time）回调方法，从而允许程序可以实现复杂计算。
这4层中，一般用于开发的是第三层，即DataStrem/DataSetAPI。用户可以使用DataStream API处理无界数据流，使用DataSet API处理有界数据流。同时这两个API都提供了各种各样的接口来处理数据。
Flink程序的模块结构 如下图，Flink程序主要分为 source&amp;ndash;&amp;gt;transformation&amp;ndash;&amp;gt;sink 这三个模块
在获取执行环境后，程序从数据源中获取数据，并执行Transformation操作，最后将执行结果输出到指定的地方，如消息队列、文件系统、数据库等。
下面这个简单的例子便包含了整个过程：
 public static void main(String[] args) throws Exception { // Checking input parameters final MultipleParameterTool params = MultipleParameterTool.</description>
    </item>
    
    <item>
      <title>Kubernetes常用kubectl命令总结</title>
      <link>https://pangwawa.github.io/posts/kubernetes/kubernetes_cli_order/</link>
      <pubDate>Tue, 13 Oct 2020 18:01:51 +0800</pubDate>
      
      <guid>https://pangwawa.github.io/posts/kubernetes/kubernetes_cli_order/</guid>
      <description>kubernetes 常用kubectl命令 基本命令 create get 用于获取一个或多个资源的信息，包括 Namespace、 Pod、 Node、 Deployment、 Service、 ReplicaSet
如
kubectl get cs # 查看集群状态
kubectl get nodes # 查看集群节点信息
kubectl get ns # 查看集群命名空间
kubectl get svc -n kube-system # 查看指定命名空间的服务
kubectl get pod -o wide # 查看Pod详细信息
kubectl get pod -o yaml # 以yaml格式查看Pod详细信息
kubectl get pods # 查看资源对象，查看所有Pod列表
kubectl get rc,service # 查看资源对象，查看rc和service列表
kubectl get pod,svc,ep &amp;ndash;show-labels # 查看pod,svc,ep能及标签信息
kubectl get all &amp;ndash;all-namespaces # 查看所有的命名空间</description>
    </item>
    
    <item>
      <title>Kubernetes v1.19.0集群部署</title>
      <link>https://pangwawa.github.io/posts/kubernetes/kubernetes_cluster_install/</link>
      <pubDate>Mon, 12 Oct 2020 17:46:07 +0800</pubDate>
      
      <guid>https://pangwawa.github.io/posts/kubernetes/kubernetes_cluster_install/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Kubernetes基础概念与组件架构</title>
      <link>https://pangwawa.github.io/posts/kubernetes/kubernetes_basic_structure/</link>
      <pubDate>Fri, 09 Oct 2020 17:45:53 +0800</pubDate>
      
      <guid>https://pangwawa.github.io/posts/kubernetes/kubernetes_basic_structure/</guid>
      <description>什么是Kubernetes Kubernetes 是一个可移植的、可扩展的开源平台，用于管理容器化的工作负载和服务，可促进声明式配置和自动化。Kubernetes(k8s)是Google开源的容器集群管理系统（谷歌内部:Borg）在Docker技术的基础上，为容器化的应用提供部署运行、资源调度、服务发现和动态伸缩等一系列完整功能，提高了大规模容器集群管理的便捷性。
核心概念与架构 service service 一个Service对象是对应用集群的抽象，比如一个Mysql集群，一个微服务的集群，都会被看做一个service
特点： 拥有唯一指定的名称(比如mysql-server)。 拥有一个虚拟IP(Cluster lP、Service IP或VIP）和端口号。 能够提供某种远程服务能力。 被映射到提供这种服务能力的一组容器应用上。  pod k8s中的最小部署单元，不是一个程序/进程，而是一个环境(包括容器、存储、网络ip:port、容器配置)。其中可以运行1个或多个container（docker或其他容器），在一个pod内部的container共享所有资源，包括共享pod的ip:port和磁盘。
pod是临时性的，用完即丢弃的，当pod中的进程结束、node故障，或者资源短缺时，pod会被干掉。基于此，用户很少直接创建一个独立的pods，而会通过k8s中的controller来对pod进行管理。 controller通过pod templates来创建pod，pod template是一个静态模板，创建出来之后的pod就跟模板没有关系了，模板的修改也不会影响现有的pod。
Pod中封装着应用的容器（有的情况下是好几个容器），存储、独立的网络IP，管理容器如何运行的策略选项。Pod代表着部署的一个单位：kubernetes中应用的一个实例，可能由一个或者多个容器组合在一起共享资源。
在Kubrenetes集群中Pod有如下两种使用方式：
一个Pod中运行一个容器。“每个Pod中一个容器”的模式是最常见的用法；在这种使用方式中，你可以把Pod想象成是单个容器的封装，kuberentes管理的是Pod而不是直接管理容器。
在一个Pod中同时运行多个容器。一个Pod中也可以同时封装几个需要紧密耦合互相协作的容器，它们之间共享资源。这些在同一个Pod中的容器可以互相协作成为一个service单位——一个容器共享文件，另一个“sidecar”容器来更新这些文件。Pod将这些容器的存储资源作为一个实体来管理。
container 容器是独立运行的一个或一组应用，是镜像运行时的实体。
pod 生命周期 需要注意的是pod的生命周期和container的生命周期有一定的联系，但是不能完全混淆一致。pod状态相对来说要简单一些。这里首先列出pod的状态
1、pending：pod已经被系统认可了，但是内部的container还没有创建出来。这里包含调度到node上的时间以及下载镜像的时间，会持续一小段时间。 2、Running：pod已经与node绑定了（调度成功），而且pod中所有的container已经创建出来，至少有一个容器在运行中，或者容器的进程正在启动或者重启状态。&amp;ndash;这里需要注意pod虽然已经Running了，但是内部的container不一定完全可用。因此需要进一步检测container的状态。 3、Succeeded：这个状态很少出现，表明pod中的所有container已经成功的terminated了，而且不会再被拉起了。 4、Failed：pod中的所有容器都被terminated，至少一个container是非正常终止的。（退出的时候返回了一个非0的值或者是被系统直接终止） 5、unknown：由于某些原因pod的状态获取不到，有可能是由于通信问题。 一般情况下pod最常见的就是前两种状态。而且当Running的时候，需要进一步关注container的状态。下面就来看下container的状态有哪些：
Container生命周期 1、Waiting：启动到运行中间的一个等待状态。 2、Running：运行状态。 3、Terminated：终止状态。 如果没有任何异常的情况下，container应该会从Waiting状态变为Running状态，这时容器可用。
但如果长时间处于Waiting状态，container会有一个字段reason表明它所处的状态和原因，如果这个原因很容易能标识这个容器再也无法启动起来时，例如ContainerCannotRun，整个服务启动就会迅速返回。（这里是一个失败状态返回的特性，不详细阐述）
当一个容器已经运行起来以后，pod和container的状态是如何关联起来的呢，下面给一些举例来更加形象化其中的关系。
分层架构 Kubernetes设计理念和功能其实就是一个类似Linux的分层架构 核心层：Kubernetes最核心的功能，对外提供API构建高层的应用，对内提供插件式应用执行环境
应用层：部署（无状态应用、有状态应用、批处理任务、集群应用等）和路由（服务发现、DNS解析等）
管理层：系统度量（如基础设施、容器和网络的度量），自动化（如自动扩展、动态Provision等）以及策略管理（RBAC、Quota、PSP、NetworkPolicy等）
接口层：kubectl命令行工具、客户端SDK以及集群联邦
生态系统：在接口层之上的庞大容器集群管理调度的生态系统，可以划分为两个范畴
Kubernetes外部：日志、监控、配置管理、CI、CD、Workflow、FaaS、OTS应用、ChatOps等
Kubernetes内部：CRI、CNI、CVI、镜像仓库、Cloud Provider、集群自身的配置和管理等
核心组件 Kubernetes主要由以下几个核心组件组成： etcd 保存了整个集群的状态；
apiserver 提供了资源操作的唯一入口，并提供认证、授权、访问控制、API注册和发现等机制；
controller manager 负责维护集群的状态，比如故障检测、自动扩展、滚动更新等；
scheduler 负责资源的调度，按照预定的调度策略将Pod调度到相应的机器上；
kubelet 负责维护容器的生命周期，同时也负责Volume（CVI）和网络（CNI）的管理；
Container runtime 负责镜像管理以及Pod和容器的真正运行（CRI）；
kube-proxy 负责为Service提供cluster内部的服务发现和负载均衡；</description>
    </item>
    
    <item>
      <title>容器、kubernetes、DevOps与云原生</title>
      <link>https://pangwawa.github.io/posts/kubernetes/what_is_cloud_native/</link>
      <pubDate>Wed, 16 Sep 2020 20:22:15 +0800</pubDate>
      
      <guid>https://pangwawa.github.io/posts/kubernetes/what_is_cloud_native/</guid>
      <description></description>
    </item>
    
    <item>
      <title>MySQL索引与优化</title>
      <link>https://pangwawa.github.io/posts/mysql/mysql_index/</link>
      <pubDate>Sun, 22 Mar 2020 18:09:01 +0800</pubDate>
      
      <guid>https://pangwawa.github.io/posts/mysql/mysql_index/</guid>
      <description>什么是索引，为什么要使用索引 索引是一种能提高数据查询速度的数据结构， 常用的索引数据解构有 B+ 树 和 Hash
可以提高数据检索的效率，降低数据库的IO成本 通过索引列对数据进行排序，降低数据排序的成本，降低了CPU的消耗
劣势：
索引会占据磁盘空间
索引虽然会提高查询效率，但是会降低更新表的效率
索引类型 主键索引 索引列中的值必须是唯一的，不允许有空值。
普通索引 MySQL中基本索引类型，没有什么限制，允许在定义索引的列中插入重复值和空值。
唯一索引 索引列中的值必须是唯一的，但是允许为空值。
全文索引 只能在文本类型CHAR,VARCHAR,TEXT类型字段上创建全文索引。字段长度比较大时，如果创建普通索引，在进行like模糊查询时效率比较低，这时可以创建全文索引。MyISAM和InnoDB中都可以使用全文索引。
空间索引 MySQL在5.7之后的版本支持了空间索引，而且支持OpenGIS几何数据模型。MySQL在空间索引这方面遵循OpenGIS几何数据模型规则。
前缀索引 在文本类型如CHAR,VARCHAR,TEXT类列上创建索引时，可以指定索引列的长度，但是数值类型不能指定。
其他（按照索引列数量分类） ####单列索引 ####组合索引 组合索引的使用，需要遵循最左前缀匹配原则（最左匹配原则）。一般情况下在条件允许的情况下使用组合索引替代多个单列索引使用。
为什么很少使用Hash作为索引的数据结构 Hash表在等值查询时效率很高，时间复杂度为O(1)；但是不支持范围快速查找，范围查找时还是只能通过扫描全表方式。
什么是B+树，为什么使用B+树作为数据库索引的底层结构，为什么不使用B树 减少磁盘IO操作，就需要尽量降低树的高度，第一个根节点的位置要合理
平衡二叉树：采用二分法思维，平衡二叉查找树除了具备二叉树的特点，最主要的特征是树的左右两个子树的层级最多相差1。
B树，改造平衡二叉树，降低树的高度，减少磁盘IO操作。B树的高度一般2至3层就能满足大部分的应用场景，所以使用B树构建索引可以很好的提升查询的效率。
B+树，为了解决B树不支持范围查询的快速查找
B+树和B树最主要的区别在于非叶子节点是否存储数据的问题 B树：非叶子节点和叶子节点都会存储数据。 B+树：只有叶子节点才会存储数据，非叶子节点至存储键值。叶子节点之间使用双向指针连接，最底层的叶子节点形成了一个双向有序链表。  MyISAM索引和InnoDB索引的区别 ####MyISAM MyISAM的数据文件和索引文件是分开存储的。MyISAM使用B+树构建索引树时，叶子节点中存储的键值为索引列的值，数据为索引所在行的磁盘地址。 先在主键树中从根节点开始检索，将根节点加载到内存，比较28&amp;lt;75，走左路。（1次磁盘IO） 将左子树节点加载到内存中，比较16&amp;lt;28&amp;lt;47，向下检索。（1次磁盘IO） 检索到叶节点，将节点加载到内存中遍历，比较16&amp;lt;28，18&amp;lt;28，28=28。查找到值等于30的索引项。（1次磁盘IO） 从索引项中获取磁盘地址，然后到数据文件user.MYD中获取对应整行记录。（1次磁盘IO） 将记录返给客户端。
InnoDB 索引 InnoDB的数据和索引存储在一个文件t_user_innodb.ibd中。InnoDB的数据组织方式，是聚簇索引。
InnoDB索引按照叶子节点是否存储数据分为主键索引（聚簇索引）和 辅助索引 除聚簇索引之外的所有索引都称为辅助索引，InnoDB的辅助索引只会存储主键值而非磁盘地址。
 主键索引的叶子节点会存储数据行，辅助索引只会存储主键值。  回表查询：根据在辅助索引树中获取的主键id，到主键索引树检索数据的过程称为回表查询
组合索引和覆盖索引 组合索引的最左前缀匹配原则：使用组合索引查询时，mysql会一直向右匹配直至遇到范围查询(&amp;gt;、&amp;lt;、between、like)就停止匹配。
覆盖索引 覆盖索引并不是说是索引结构，覆盖索引是一种很常用的优化手段。因为在使用辅助索引的时候，我们只可以拿到主键值，相当于获取数据还需要再根据主键查询主键索引再获取到数据。 但是试想下这么一种情况，在上面abc_innodb表中的组合索引查询时，如果我只需要abc字段的，那是不是意味着我们查询到组合索引的叶子节点就可以直接返回了，而不需要回表。这种情况就是覆盖索引。
覆盖索引和联合索引是什么 覆盖索引，返回的字段建立索引，减少回表操作
联合索引，在合理的情况下，尽可能在一个****索引中包含多个字段
覆盖索引的字段可能不是在同一个索引，即覆盖索引中所使用的索引不一定是联合索引</description>
    </item>
    
    <item>
      <title>Elasticsearch数据的写入、读取与检索过程详解</title>
      <link>https://pangwawa.github.io/posts/elasticsearch/elasticsearch_read_write_search_process/</link>
      <pubDate>Sat, 07 Mar 2020 18:25:18 +0800</pubDate>
      
      <guid>https://pangwawa.github.io/posts/elasticsearch/elasticsearch_read_write_search_process/</guid>
      <description>ElasticSearch写过程 分片
一个分片就是一个运行的Lucenes实例，个节点可以包含多个分片，Es中所有数据均衡的存储在集群中各个节点的分片中
主分片和副本分片
注意
1、默认索引是5个分片
2、分片一定设置是不可以修改的，只能新建新索引解决
数据写入过程:
ES的任意节点都可以作为协调节点(coordinating node)接受请求，当协调节点接受到请求后进行一系列处理，然后通过_routing字段找到对应的primary shard，并将请求转发给primary shard, primary shard完成写入后， 将写入并发发送给各replica， raplica执行写入操作后返回给primary shard， primary shard再将请求返回给协调节点
数据持久化步骤如下：write -&amp;gt; refresh -&amp;gt; flush -&amp;gt; merge
write:一个新文档过来，会存储在 in-memory buffer 内存缓存区中，顺便会记录 Translog。(这时候数据还没到 segment ，是搜不到这个新文档的。数据只有被 refresh 后，才可以被搜索到,设置了refresh时间，所以是准实时)
refresh: 1、in-memory buffer 中的文档写入到新的 segment 中，但 segment 是存储在文件系统的缓存中。此时文档可以被搜索到; 2、最后清空 in-memory buffer。注意: Translog 没有被清空，为了将 segment 数据写到磁盘
flush:将segment从文件系统缓存写入磁盘。最后清空translog。translog 作用很大：保证文件缓存中的文档不丢失；系统重启时，从 translog 中恢复；新的 segment 收录到 commit point 中
merge： 当磁盘中的segment越来越多，会导致搜索速度变慢，通过merge将小段文件合并为大文件。
ElasticSearch读过程 客户端发送请求到任意一个node，成为coordinate node
coordinate node对document进行路由，将请求转发到对应的node，此时会使用round-robin随机轮询算法，在primary shard以及其所有replica中随机选择一个，让读请求负载均衡
接收请求的node返回document给coordinate node
coordinate node返回document给客户端</description>
    </item>
    
    <item>
      <title>Kibana可视化展示的各种形式汇总</title>
      <link>https://pangwawa.github.io/posts/elasticsearch/kibana_visualization_type/</link>
      <pubDate>Sat, 07 Mar 2020 17:09:39 +0800</pubDate>
      
      <guid>https://pangwawa.github.io/posts/elasticsearch/kibana_visualization_type/</guid>
      <description>常用可视化形式 折线图（Line, area, and bar charts），面积图和条形图—比较X / Y图表中的不同系列。
饼图（Pie chart ）-显示每个来源总计。
数据表（Data table ）-将聚合展平为表格式。
公制（Data table ）—显示一个数字。
目标和计量器（Goal and gauge ）—显示带有进度指示器的数字。
标签云（Goal and gauge ）—在云中显示单词，单词的大小与其重要性相对应。
Lens 快速可视化，拖放需要统计的字段即可快速构建可视化
TSVB 使用管道聚合可视化时间序列数据
Timelion 计算和合并来自多个时间序列数据集的数据
Maps 地图
Heat Map 热图 显示矩阵内的阴影单元格
Dashboard tools 文字信息部件（Markdown widget）显示自由格式的信息或说明。
控件（ Controls）： 将交互式输入添加到仪表板
Vega 完成对查询和显示的控制</description>
    </item>
    
    <item>
      <title>Elasticsearch聚合—桶（bucket）和指标（metric）</title>
      <link>https://pangwawa.github.io/posts/elasticsearch/elasticsearch_buckets_metrics/</link>
      <pubDate>Thu, 05 Mar 2020 17:07:30 +0800</pubDate>
      
      <guid>https://pangwawa.github.io/posts/elasticsearch/elasticsearch_buckets_metrics/</guid>
      <description>聚合的两个核心概念：桶（bucket）和指标（metric）
　桶（bucket）: 满足特定条件的文档的集合
指标（metric）: 对桶内的文档进行聚合分析的操作
桶在概念上类似于SQL的分组（GROUP BY）,而指标则类似于COUNT()、SUM()、MAX()等统计方法。
2、桶和指标的深入理解
（1）桶　　a、简单来说桶就是满足特定条件的文档的集合。
　b、当聚合开始被执行，每个文档里面的值通过计算来决定符合哪个桶的条件，如果匹配到，文档将放入相应的桶并接着开始聚合操作。
　c、桶也可以被嵌套在其他桶里面。
（2）指标
　a、桶能让我们划分文档到有意义的集合，但是最终我们需要的是对这些桶内的文档进行一些指标的计算。分桶是一种达到目的地的手段：它提供了一种给文档分组的方法来让我们可以计算感兴趣的指标。
　b、大多数指标是简单的数学运算（如：最小值、平均值、最大值、汇总），这些是通过文档的值来计算的。
（3）桶和指标的组合
　聚合是由桶和指标组成的。聚合可能只有一个桶，可能只有一个指标，或者可能两个都有。也有可能一些桶嵌套在其他桶里面。</description>
    </item>
    
    <item>
      <title>ElasticSearch倒排索引原理探索</title>
      <link>https://pangwawa.github.io/posts/elasticsearch/elasticsearch_inverted_index/</link>
      <pubDate>Thu, 05 Mar 2020 11:20:35 +0800</pubDate>
      
      <guid>https://pangwawa.github.io/posts/elasticsearch/elasticsearch_inverted_index/</guid>
      <description></description>
    </item>
    
    <item>
      <title>深入理解LSM存储结构</title>
      <link>https://pangwawa.github.io/posts/other/lsm_store/</link>
      <pubDate>Mon, 02 Mar 2020 11:18:34 +0800</pubDate>
      
      <guid>https://pangwawa.github.io/posts/other/lsm_store/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ElasticSearch集群与调优</title>
      <link>https://pangwawa.github.io/posts/elasticsearch/elasticsearch_cluster/</link>
      <pubDate>Sat, 29 Feb 2020 11:10:33 +0800</pubDate>
      
      <guid>https://pangwawa.github.io/posts/elasticsearch/elasticsearch_cluster/</guid>
      <description>1.1、设计阶段调优
（1）根据业务增量需求，采取基于日期模板创建索引，通过roll over API滚动索引； （2）使用别名进行索引管理； （3）每天凌晨定时对索引做force_merge操作，以释放空间； （4）采取冷热分离机制，热数据存储到SSD，提高检索效率；冷数据定期进行shrink操作，以缩减存储； （5）采取curator进行索引的生命周期管理； （6）仅针对需要分词的字段，合理的设置分词器； （7）Mapping阶段充分结合各个字段的属性，是否需要检索、是否需要存储等。……..
1.2、写入调优
（1）写入前副本数设置为0； （2）写入前关闭refresh_interval设置为-1，禁用刷新机制； （3）写入过程中：采取bulk批量写入； （4）写入后恢复副本数和刷新间隔； （5）尽量使用自动生成的id。
1.3、查询调优
（1）禁用wildcard； （2）、禁用批量terms（成百上千的场景）； （3）充分利用倒排索引机制，能keyword类型尽量keyword； （4）数据量大时候，可以先基于时间敲定索引再检索； （5）设置合理的路由机制。
1.4、其他调优 部署调优，业务调优等。 上面的提及一部分，面试者就基本对你之前的实践或者运维经验有所评估了。</description>
    </item>
    
    <item>
      <title>ElasticSearch 数据导入方案</title>
      <link>https://pangwawa.github.io/posts/elasticsearch/elasticsearch_data_input/</link>
      <pubDate>Tue, 25 Feb 2020 11:08:58 +0800</pubDate>
      
      <guid>https://pangwawa.github.io/posts/elasticsearch/elasticsearch_data_input/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ElasticSearch用户权限与安全机制</title>
      <link>https://pangwawa.github.io/posts/elasticsearch/elasticsearch_account_management_and_security/</link>
      <pubDate>Sat, 22 Feb 2020 10:32:21 +0800</pubDate>
      
      <guid>https://pangwawa.github.io/posts/elasticsearch/elasticsearch_account_management_and_security/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ElasticSearch基础概念与架构原理</title>
      <link>https://pangwawa.github.io/posts/elasticsearch/elasticsearch__structure/</link>
      <pubDate>Thu, 20 Feb 2020 11:14:21 +0800</pubDate>
      
      <guid>https://pangwawa.github.io/posts/elasticsearch/elasticsearch__structure/</guid>
      <description>基本概念 集群(cluster)：有一个主节点，通过选举产生，从外部来看es集群，在逻辑上是个整体，你与任何一个节点的通信和与整个es集群通信是等价的。
索引(index)：数据可以存储在不同索引中，索引可以看做是传统中的数据库，可以在索引中写入文档和搜索文档
文档(document)，文档由字段组成，是ES索引中数据存储的基本单位
映射(mapping)：所有文档写进索引之前都会先进行分析，如何将输入的文本分割为词条、哪些词条又会被过滤，这种行为叫做映射（mapping）。一般由用户自己定义规则。
分片(shards)：一个完整索引可以分成多个分片分布到不同节点，分布式存储分布式搜索分片的数量只能在索引创建前指定，并且索引创建后不能更改。5.X默认不能通过配置文件定义分片
副本(replicas)：代表索引副本，可设置多个，提高系统容错性（分片损坏可从副本恢复），还能通过对副本自动请求搜索负载均衡，提高ES查询效率
数据恢复(Discovery)：当挂掉的节点重新启动加入，会进行数据恢复
数据源(River)：ES数据的来源，它是以插件方式存在的一个es服务，通过读取river中的数据并把它索引到es中，官方的river有couchDB的，RabbitMQ的，Twitter的，Wikipedia的，river这个功能将会在后面的文件中重点说到。
网关（gateway）：代表es索引的持久化存储方式，es默认是先把索引存放到内存中，当内存满了时再持久化到硬盘。当这个es集群关闭再重新启动时就会从gateway中读取索引数据。es支持多种类型的gateway，有本地文件系统（默认），分布式文件系统，Hadoop的HDFS和amazon的s3云存储服务。
自动发现（discovery.zen）：代表es的自动发现节点机制，es是一个基于p2p的系统，它先通过广播寻找存在的节点，再通过多播协议来进行节点之间的通信，同时也支持点对点的交互。5.X关闭广播，需要自定义
通信（Transport） ：代表es内部节点或集群与客户端的交互方式，默认内部是使用tcp协议进行交互，同时它支持http协议（json格式）、thrift、servlet、memcached、zeroMQ等的传输协议（通过插件方式集成）。节点间通信端口默认：9300-9400
分片和复制（shards and replicas） ：一个索引可以存储超出单个结点硬件限制的大量数据。比如，一个具有10亿文档的索引占据1TB的磁盘空间，而任一节点可能没有这样大的磁盘空间来存储或者单个节点处理搜索请求，响应会太慢。
为了解决这个问题，Elasticsearch提供了将索引划分成多片的能力，这些片叫做分片。当你创建一个索引的时候，你可以指定你想要的分片的数量。每个分片本身也是一个功能完善并且独立的“索引”，这个“索引” 可以被放置到集群中的任何节点上。
分片之所以重要，主要有两方面的原因：
1、允许你水平分割/扩展你的内容容量
2、允许你在分片（位于多个节点上）之上进行分布式的、并行的操作，进而提高性能/吞吐量
至于一个分片怎样分布，它的文档怎样聚合回搜索请求，是完全由Elasticsearch管理的，对于作为用户的你来说，这些都是透明的。
在一个网络/云的环境里，失败随时都可能发生。在某个分片/节点因为某些原因处于离线状态或者消失的情况下，故障转移机制是非常有用且强烈推荐的。为此， Elasticsearch允许你创建分片的一份或多份拷贝，这些拷贝叫做复制分片，或者直接叫复制。
复制之所以重要，有两个主要原因：
在分片/节点失败的情况下，复制提供了高可用性。复制分片不与原/主要分片置于同一节点上是非常重要的。因为搜索可以在所有的复制上并行运行，提高搜索速度。</description>
    </item>
    
    <item>
      <title>ElasticSearch Mapping 数据建模规范与建模过程</title>
      <link>https://pangwawa.github.io/posts/elasticsearch/elasticsearch_data_modeling/</link>
      <pubDate>Sun, 16 Feb 2020 09:41:35 +0800</pubDate>
      
      <guid>https://pangwawa.github.io/posts/elasticsearch/elasticsearch_data_modeling/</guid>
      <description>Mapping数据建模 数据建模即创建数据模型的过程，它主要分为以下的步骤
概念分析：确定系统的核心需求和范围边界，设计实现和实体间的关系 逻辑模型：进一步梳理业务需求，确定每个实体的属性、关系和约束等 物理模型：结合具体的数据库产品，在满足业务读写性能等需求的前提下确定最终的定义
ElasticSearch索引建立可以遵循一个流程：字段类型——是否要搜索及分词——是否要聚合及排序——是否要额外的存储
是何种类型？ 字符串类型：需要分词设定为text类型，否则设置为keyword类型 枚举类型：基于性能考虑将其设定为keyword类型，即便该数据为整型（如状态码） 数值类型：尽量选择贴近的类型，比如byte即可表示所有数值时，即选用byte,不要用long 其他类型：比如布尔类型、日期、地理位置数据等
是否需要检索？ 完全不需要检索、排序、聚合分析的字段：enable设置为false 不需要检索的字段：index设置为false 需要检索的字段，可以通过如下配置设定需要的存储粒度 index_options: 结合需要设定 norms: 不需要归一化数据时关闭即可 ####是否需要排序和聚合分析？ 不需要排序或者聚合分析功能：
doc_values设定为false fielddata设定为false ####是否需要专门存储当前字段的数据？ store设定为true,即可存储该字段的原始内容（与_source中的不相关） 一般结合_source的enabled设定为false时使用
索引建立Mapping的过程如下图所示
mapping 设计非常重要，需要从两个维度进行考虑：
功能：搜索、排序、聚合 性能：存储的开锁、内存的开销、搜索的性能 mapping 注意事项： 加入新字段很容易（必要时需要 update_by_query） 更新删除字段不允许（需要 reindex 重建数据）
下面列出Mapping 字段的相关设置：
   参数 取值 说明     enabled ture/false 默认为true, false：仅存储，不做搜索或聚合分析(比如cookie/session字段)   index ture/false 控制当前字段是否索引，默认为true,即记录索引，false不记录，即不可搜索   index_options docs/freqs/positions/offsets 存储倒排索引的哪些信息,text类型默认配置为positions,其他默认为docs ,记录内容越多，占用空间越大。   norms true/false 是否存储归一化相关参数，如果字段仅用于过滤和聚合分析，可关闭   doc_values true/false 是否启用doc_values,用于排序和聚合分析   field_data true/false 是否为text类型启用fielddata,实现排序和聚合分析   store true/false 是否存储该字段值,默认是false   coerce true/false 是否开启自动数据类型转换功能，比如字符串转换为数字、浮点转换为整型等（默认是true   multifields - 多字段-灵活使用多字段特性来解决多样的业务需求   dynamic true/false/strict 控制mapping自动更新   date_detection true/false 是否自动识别日期类型    常用规则   如果索引不允许自动新增字段，将 dynamic 设置成 strict。默认为 true；</description>
    </item>
    
    <item>
      <title>Elasticsearch的DSL——常用检索、复合检索、高级检索</title>
      <link>https://pangwawa.github.io/posts/elasticsearch/elasticsearch_query_dsl/</link>
      <pubDate>Sat, 15 Feb 2020 17:49:40 +0800</pubDate>
      
      <guid>https://pangwawa.github.io/posts/elasticsearch/elasticsearch_query_dsl/</guid>
      <description>简单查询 精准查询term （完全匹配，不使用分词器） term单值查询
{ &amp;quot;query&amp;quot;: { &amp;quot;term&amp;quot;: { &amp;quot;productType&amp;quot;: { &amp;quot;value&amp;quot;: &amp;quot;101&amp;quot; } } } } term多值查询
GET /test/_search { &amp;quot;query&amp;quot;: { &amp;quot;bool&amp;quot;: { &amp;quot;must&amp;quot;: [ { &amp;quot;term&amp;quot;: { &amp;quot;mac&amp;quot;: { &amp;quot;value&amp;quot;: &amp;quot;2541229&amp;quot; } } }, { &amp;quot;term&amp;quot;: { &amp;quot;productType&amp;quot;: { &amp;quot;value&amp;quot;: &amp;quot;1&amp;quot; } } } ] } } } terms查询多值
{ &amp;quot;query&amp;quot;: { &amp;quot;terms&amp;quot;: { &amp;quot;productType&amp;quot;:[&amp;quot;101&amp;quot;,&amp;quot;102&amp;quot;] } } } 模糊查询 （模糊匹配，使用分词器） match 、 match_all、multi_match、match_phrase
match_all 匹配所有的， 当不给查询条件时，默认全查 match</description>
    </item>
    
    <item>
      <title>ElasticSearch 生命周期管理——索引生命周期与冷热数据分离</title>
      <link>https://pangwawa.github.io/posts/elasticsearch/elasticsearch_lifecycle_management/</link>
      <pubDate>Tue, 11 Feb 2020 09:46:25 +0800</pubDate>
      
      <guid>https://pangwawa.github.io/posts/elasticsearch/elasticsearch_lifecycle_management/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ElasticSearch 7.9 数据类型和Mapping参数详解</title>
      <link>https://pangwawa.github.io/posts/elasticsearch/elasticsearch_datatype/</link>
      <pubDate>Mon, 10 Feb 2020 09:23:44 +0800</pubDate>
      
      <guid>https://pangwawa.github.io/posts/elasticsearch/elasticsearch_datatype/</guid>
      <description>ElasticSearch数据类型 基础类型 String keyword字段通常用于排序， 聚合和术语级查询
keyword类型
（keyword类型可设置属性：boost、doc_values、eager_global_ordinals、fields、ignore_above、index、index_options、norms、null_value、store、similarity、normalizer、split_queries_on_whitespace、meta）
constant_keyword类型
提交的值只能是固定的或者没有该值 （constant_keyword类型可设置的属性：meta、value）
wildcard类型
存储为通配符grep式查询优化的值 （可设置的参数：ignore_above） wildcard 字段像关键字字段一样是未标记的，因此不支持依赖词位置的查询，例如短语查询
text类型
text将对字段值进行分析以进行全文本搜索 （可设置属性：analyzer、boost、eager_global_ordinals、fielddata、fielddata_frequency_filter、fields、index、index_options、index_prefixes、index_pharses、norms、position_increment_gap、store、search_analyzer、search_quote_analyzer、similarity、term_vector、meta）
数字 long类型
integer类型
short类型
byte类型
double类型
float类型
half float类型
scaled float类型
（数字类型可设置参数：coerce、boost、doc_values、ignore_malformed、index、null_value、source、meta；scaled_float 接受一个附加参数：scaling_factor）
时间 date类型
（date类型可设置的属性：boost、doc_values、index、null_value、store、meta、format、locale、ignore_malformed） **日期格式可以自定义，但是如果未format指定，则使用默认格式：“ strict_date_optional_time || epoch_millis”
date_nanos类型
date_nanos类型（是date的补充，增加了纳秒级别的时间戳和格式时间支持，1420070400 ） **日期格式可以自定义，但是如果未format指定，则使用默认格式：“ strict_date_optional_time || epoch_millis”
布尔 boolean类型
（boolean可设置属性：boost、doc_values、index、null_value、store、meta）
二进制 binary类型
（binary类型可设置的属性，doc_values，store）
区间 integer range类型
float range类型
long ranage类型
double range类型
date range类型
ip_range类型
（可设置属性：coerce、boost、index、store）
复杂文档 Array数组类型
没有特定的mapping类型，elasticsearch默认支持相同类型的多个值
Object类型
对象类型，可包含内部对象 （object对象可设置属性：dynamic、enabled、properties、）</description>
    </item>
    
    <item>
      <title>你好，第一篇手记</title>
      <link>https://pangwawa.github.io/posts/life/hello/</link>
      <pubDate>Sun, 09 Feb 2020 15:00:01 +0800</pubDate>
      
      <guid>https://pangwawa.github.io/posts/life/hello/</guid>
      <description>关于我  我是一名专注于Java架构和大数据开发的互联网人。 2020，是我毕业后在职场的第二年，但也知道了自己的兴趣方向，明白了生活的不易。之前都是在CSDN https://blog.csdn.net/Jack__iT上写博客，现在想有个专属的小天地。
我也许只是浩瀚星辰中的小星星，但这并无法阻挡我发出自己的光芒。
共勉 忘了在哪看到的这段话，算是挺有意思的鸡汤吧，咱一起喝碗鸡汤补补：
纽约时间比加州时间早三个小时，
New York is 3 hours ahead of California,
但加州时间并没有变慢。
but it does not make California slow.
有人22岁就毕业了，
Someone graduated at the age of 22,
但等了五年才找到好的工作！
but waited 5 years before securing a good job!
有人25岁就当上CEO，
Someone became a CEO at 25,
却在50岁去世。
and died at 50.
也有人迟到50岁才当上CEO，
While another became a CEO at 50,
然后活到90岁。
and lived to 90 years.
有人依然单身，</description>
    </item>
    
    <item>
      <title>Java各个版本的特性</title>
      <link>https://pangwawa.github.io/posts/java/java_vesrion/</link>
      <pubDate>Wed, 06 Nov 2019 10:22:19 +0800</pubDate>
      
      <guid>https://pangwawa.github.io/posts/java/java_vesrion/</guid>
      <description>Java各个版本的特性 Java 5 1、泛型
2、增强for循环
3、自动装箱拆箱
4、枚举
5、可变参数
6、静态导入
7、自定义注解 关键字 @interface
Java 6 1、集合框架增强 为了更好的支持双向访问集合。添加了许多新的类和接口。 新的数组拷贝方法。Arrays.copyOf和Arrays.copyOfRange
2、为了更好的支持双向访问集合。添加了许多新的类和接口。 新的数组拷贝方法。Arrays.copyOf和Arrays.copyOfRange
3、支持JDBC4.0规范
Java 7 Swing
新增 JLayer 类，是一个灵活而且功能强大的Swing组件修饰器，使用方法：How to Decorate Components with JLayer. Nimbus Look and Feel 外观从 com.sun.java.swing 包移到 javax.swing 包中，详情：javax.swing.plaf.nimbus 更轻松的重量级和轻量级组件的混合 支持透明窗体以及非矩形窗体的图形界面，请看 How to Create Translucent and Shaped Windows JColorChooser 类新增 HSV tab.  网络
新增 URLClassLoader.close 方法，请看 Closing a URLClassLoader. 支持 Sockets Direct Protocol (SDP) 提供高性能网络连接，详情请看 Understanding the Sockets Direct Protocol.</description>
    </item>
    
    <item>
      <title>关于我</title>
      <link>https://pangwawa.github.io/about/about_me/</link>
      <pubDate>Sat, 23 Mar 2019 11:41:37 +0800</pubDate>
      
      <guid>https://pangwawa.github.io/about/about_me/</guid>
      <description>我是一名专注于Java架构、大数据开发的互联网从业者</description>
    </item>
    
    <item>
      <title>深入理解Java虚拟机——JVM的GC详解</title>
      <link>https://pangwawa.github.io/posts/java/java_memory_gc/</link>
      <pubDate>Sun, 06 Jan 2019 09:31:57 +0800</pubDate>
      
      <guid>https://pangwawa.github.io/posts/java/java_memory_gc/</guid>
      <description>JVM的GC有哪些 一、Serial收集器(jdk1.3) Serial收集器是最基本、发展历史最悠久的收集器，曾经（在JDK 1.3.1之前）是虚拟机新生代收集的唯一选择。
特性： 这个收集器是一个单线程的收集器，但它的“单线程”的意义并不仅仅说明它只会使用一个CPU或一条收集线程去完成垃圾收集工作，更重要的是在它进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束。Stop The World
应用场景： Serial收集器是虚拟机运行在Client模式下的默认新生代收集器。
优势： 简单而高效（与其他收集器的单线程比），对于限定单个CPU的环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程收集效率。
二、ParNew收集器(jdk1.4) 特性： ParNew收集器其实就是Serial收集器的多线程版本，除了使用多条线程进行垃圾收集之外，其余行为包括Serial收集器可用的所有控制参数、收集算法、Stop The World、对象分配规则、回收策略等都与Serial收集器完全一样，在实现上，这两种收集器也共用了相当多的代码。
应用场景： ParNew收集器是许多运行在Server模式下的虚拟机中首选的新生代收集器。
很重要的原因是：除了Serial收集器外，目前只有它能与CMS收集器配合工作。 在JDK 1.5时期，HotSpot推出了一款在强交互应用中几乎可认为有划时代意义的垃圾收集器——CMS收集器，这款收集器是HotSpot虚拟机中第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程同时工作。 不幸的是，CMS作为老年代的收集器，却无法与JDK 1.4.0中已经存在的新生代收集器Parallel Scavenge配合工作，所以在JDK 1.5中使用CMS来收集老年代的时候，新生代只能选择ParNew或者Serial收集器中的一个。
Serial收集器 VS ParNew收集器： ParNew收集器在单CPU的环境中绝对不会有比Serial收集器更好的效果，甚至由于存在线程交互的开销，该收集器在通过超线程技术实现的两个CPU的环境中都不能百分之百地保证可以超越Serial收集器。 然而，随着可以使用的CPU的数量的增加，它对于GC时系统资源的有效利用还是很有好处的。
三、Parallel Scavenge收集器(jdk1.4) 特性： Parallel Scavenge收集器是一个新生代收集器，它也是使用复制算法的收集器，又是并行的多线程收集器。
应用场景： 停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验，而高吞吐量则可以高效率地利用CPU时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。
对比分析：
Parallel Scavenge收集器 VS CMS等收集器： Parallel Scavenge收集器的特点是它的关注点与其他收集器不同，CMS等收集器的关注点是尽可能地缩短垃圾收集时用户线程的停顿时间，而Parallel Scavenge收集器的目标则是达到一个可控制的吞吐量（Throughput）。 由于与吞吐量关系密切，Parallel Scavenge收集器也经常称为“吞吐量优先”收集器。
Parallel Scavenge收集器 VS ParNew收集器： Parallel Scavenge收集器与ParNew收集器的一个重要区别是它具有自适应调节策略。
GC自适应的调节策略： Parallel Scavenge收集器有一个参数-XX:+UseAdaptiveSizePolicy。当这个参数打开之后，就不需要手工指定新生代的大小、Eden与Survivor区的比例、晋升老年代对象年龄等细节参数了，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量，这种调节方式称为GC自适应的调节策略（GC Ergonomics）。
四、Serial Old收集器(jdk1.5) 特性： Serial Old是Serial收集器的老年代版本，它同样是一个单线程收集器，使用标记－整理算法。
应用场景：
Client模式 Serial Old收集器的主要意义也是在于给Client模式下的虚拟机使用。
Server模式 如果在Server模式下，那么它主要还有两大用途：一种用途是在JDK 1.5以及之前的版本中与Parallel Scavenge收集器搭配使用，另一种用途就是作为CMS收集器的后备预案，在并发收集发生Concurrent Mode Failure时使用。</description>
    </item>
    
    <item>
      <title>深入理解Java虚拟机——Java内存模型</title>
      <link>https://pangwawa.github.io/posts/java/java_memory_model/</link>
      <pubDate>Sun, 06 Jan 2019 09:31:45 +0800</pubDate>
      
      <guid>https://pangwawa.github.io/posts/java/java_memory_model/</guid>
      <description>Java内存模型 java堆 线程共享 存放对象的实例
java堆是JVM内存管理最大的一块区域 所有对象实例与数组都要在堆上分配内存。它也是垃圾收集器的主要管理区域。java对可以处于物理上不连续的空间，只要逻辑上是连续的即可。 如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将抛出OutOfMemoryError异常。 为了支持垃圾收集（GC），堆内存通常被分为三块区域:新生代内存(young generation)、老年代内存(old generation,jdk8移除)、永久内存(Permanent Generation for VM Matedata),一个对象被创建以后首先被放到Nursery中的Eden内存中，假设存活期超两个Survivor之后就会被转移到长时内存中(Old Generation)中;永久内存中存放着对象的方法、变量等元数据信息。
虚拟机栈 线程私有 栈中存放一个个栈帧，每个栈帧对应一个方法。一个栈帧包括（局部变量表，操作数栈，指向当前方法所属的类的运行时常量池，方法返回地址和一些额外的附加按信息。）
局部变量表，就是用来存储方法中的局部变量（包括在方法中声明的非静态变量以及函数形参）对于基本数据类型的变量，则直接存储它的值，对于引用类型的变量，则存的是指向对象的引用。局部变量表的大小在编译器就可以确定其大小了，因此在程序执行期间局部变量表的大小是不会改变的。 操作数栈，程序中的所有计算过程都是在借助于操作数栈来完成的。 指向运行时常量池的引用，因为在方法执行的过程中有可能需要用到类中的常量，所以必须要有一个引用指向运行时常量。 方法返回地址，当一个方法执行完毕之后，要返回之前调用它的地方，因此在栈帧中必须保存一个方法返回地址 注意，当线程执行一个方法时，就会随之创建一个对应的栈帧，并将建立的栈帧压栈。当方法执行完毕之后，便会将栈帧出栈。因此可知，线程当前执行的方法所对应的栈帧必定位于Java栈的顶部。在这个区域规定了两种异常状况： 如果线程请求的栈深入大于虚拟机所允许的深度，将抛出StackOverFlowError异常！ 如果虚拟机栈可以动态扩展，当扩展到无法申请内存到足够的内存，就会抛出OutOfMemoryError异常!
本地方法栈 线程私有 和虚拟站的区别是虚拟机栈为虚拟机执行Java方法（字节码）服务，而本地方法栈则为虚拟机使用到的Native方法服务。
程序计数器 线程私有 记录当前线程的程序执行指令的计数器，通过改变这个计数器的值来选取下一条需要执行的字节码指令，各个线程间计数器互相独立
方法区 线程共享 方法区在JVM中也是一个非常重要的区域，它与堆一样，是被线程共享的区域。在方法区中，存储了每个类的信息（包括类的名称、方法信息、字段信息）、静态变量、常量以及编译器编译后的代码等。方法区是堆的一个逻辑部分，为了区分Java堆，它还有一个别名Non-Heap（非堆）。相对而言，GC对于这个区域的收集是很少出现的。当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。
新生代内存、老年代内存和永久代内存 为了支持垃圾收集（GC），堆内存通常被分为三块区域:新生代内存(young generation)、老年代内存(old generation,jdk8移除)、永久内存(Permanent Generation for VM Matedata), 一个对象被创建以后首先被放到Nursery中的Eden内存中，假设存活期超两个Survivor之后就会被转移到长时内存中(Old Generation)中;永久内存中存放着对象的方法、变量等元数据信息。
常见的内存溢出 JDK7和JDK8的JVM内存模型的区别：
1、方法区变化。元数据区取代了永久代，就是JDK8没有了PermSize相关的参数配置了。元空间的本质和永久代类似，都是对JVM规范中方法区的实现。不过元空间与永久代之间最大的区别在于：元数据空间并不在虚拟机中，而是使用本地内存。
2、运行时常量池变化。在近三个JDK版本（1.6、1.7、1.8）中， 运行时常量池（Runtime Constant Pool）的所处区域一直在不断的变化，在JDK1.6时它是方法区的一部分；1.7又把他放到了堆内存中；1.8之后出现了元空间，它又回到了方法区。
内存泄露（Memory Leak）：程序在申请内存后，对象没有被GC所回收，它始终占用内存，内存泄漏的堆积最终会造成内存溢出。
内存溢出（Memory Overflow）：程序运行过程中无法申请到足够的内存而导致的一种错误。内存溢出通常发生于OLD段或Perm段垃圾回收后，仍然无内存空间容纳新的Java对象的情况。通常都是由于内存泄露导致堆栈内存不断增大，从而引发内存溢出。
jmap -histo:live后相当于手动调用了一次GC
这会导致由JVM根据运行情况去自动分配了内存，在物理内存足够的情况下，JVM出于对应用程序性能的考虑并没有调用FGC
那些参数都是啥意思？ -Xmx指定堆内存最大值，这个是最常用的参数，实在懒得理解，光设置这个也凑合了。
-XX:MaxMetaspaceSize指定非堆内存的元空间最大值，这个参数是java8之后才有的，不过现在应该没几个人用更早的版本了吧……对于学习、测试用的小应用，非堆内存基本都占用很小，但是如果不指定，最大值默认1024m，就算Xmx限制了也还会吃很多内存……
-XX:CompressedClassSpaceSize这个是Metaspace的一部分，程序的代码被存储在这里，启动后几乎不会增长，可以根据自己的情况指定一个比较小的值，给Metaspace其他部分留够空间。
其他jvm参数，
如何知道自己java应用的内存占用来决定最佳分配？ jdk路径/bin/jstat -gccapacity pid 根据pid查看某个应用的当前内存和最大内存。可以知道内存占用量的情况，也可以看出来前面的jvm参数配置有没有生效。
jstat还有很多参数，查出来的数值具体是什么意思也请自行搜索深入学习。
如果是在windows上运行，还可以用jdk路径/bin/jconsole.exe查看可视化的内存使用情况。</description>
    </item>
    
  </channel>
</rss>
